{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58dedb2a",
   "metadata": {},
   "source": [
    "# üõ†Ô∏è Notebook: Einf√ºhrung in Gradio\n",
    "\n",
    "Dieses Notebook behandelt die wichtigsten Grundlagen von Gradio.\n",
    "\n",
    "## üìö Quellen\n",
    "\n",
    "- [Gradio Docs](https://gradio.app/docs/)\n",
    "\n",
    "---\n",
    "\n",
    "Viel Erfolg beim Ausprobieren von Gradio! ü§ó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f89111d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "!uv add gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4df0aeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72ad6394-71fb-470b-937c-d1a6159ec288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6.0.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e5c2d5",
   "metadata": {},
   "source": [
    "### Beispiel 1: Einfaches User Interface (Beispiel aus den Folien)\n",
    "\n",
    "In Gradio k√∂nnen wir mit wenigen Zeilen Code eine Benutzeroberfl√§che (UI) f√ºr unsere LLM Anwendungen erstellen.\n",
    "Anders als bei Web-Frameworks wie Flask oder FastAPI, m√ºssen wir uns nicht um die Details der Webentwicklung k√ºmmern, sondern k√∂nnen uns auf die Funktionalit√§t konzentrieren.\n",
    "\n",
    "Die einfachste M√∂glichkeit, eine UI zu erstellen, ist die Verwendung der `gr.Interface` Klasse.\n",
    "`gr.Interface` ben√∂tigt mindestens drei Argumente:\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "- `fn`:  Die Funktion, die aufgerufen wird, wenn der Benutzer die Eingaben sendet.\n",
    "  Die Funktion, um die eine Benutzeroberfl√§che (UI) gebaut wird.\n",
    "\n",
    "- `inputs`:  \n",
    "  Die Gradio-Komponente(n), die als Eingabe verwendet werden.  \n",
    "  üëâ Die Anzahl der Komponenten muss der Anzahl der Argumente deiner Funktion entsprechen.  \n",
    "\n",
    "- `outputs`:  \n",
    "  Die Gradio-Komponente(n), die als Ausgabe verwendet werden.  \n",
    "  üëâ Die Anzahl der Komponenten muss der Anzahl der R√ºckgabewerte deiner Funktion entsprechen.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "696ef50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def greet(name, intensity):\n",
    "    return \"Hello, \" + name + \"!\" * intensity\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=greet,\n",
    "    inputs=[\"text\", \"slider\"],\n",
    "    outputs=[\"text\"],\n",
    ")\n",
    "\n",
    "# Mit share=False wird kein Link generiert, um die App zu √∂ffentlich (!) zu teilen. \n",
    "# Hinweis: Standardm√§√üig ist share=False, was bedeutet, dass kein Link generiert wird, um die App √∂ffentlich zu teilen.\n",
    "demo.launch(share=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a435b72",
   "metadata": {},
   "source": [
    "### Beispiel 2: User Interface mit verschiedenen Komponenten\n",
    "\n",
    "Eine Dokumentation aller Komponenten findest du hier: [Gradio Components](https://www.gradio.app/docs/gradio)\n",
    "\n",
    "\n",
    "\n",
    "**Funktion `sentence_builder`:**\n",
    "Generiert einen englischen Satz aus verschiedenen Eingaben mittels f-String und `join()`.\n",
    "\n",
    "**Interface-Komponenten:**\n",
    "\n",
    "- **Slider**: Zahlenbereich (2-20) mit Standardwert\n",
    "- **Dropdown**: Einfachauswahl f√ºr Tiere\n",
    "- **CheckboxGroup**: Mehrfachauswahl f√ºr L√§nder\n",
    "- **Radio**: Einzelauswahl f√ºr Orte\n",
    "- **Dropdown (multiselect)**: Mehrfachauswahl f√ºr Aktivit√§ten mit Voreinstellung\n",
    "- **Checkbox**: Ja/Nein f√ºr Tageszeit\n",
    "\n",
    "**Key Features**\n",
    "\n",
    "- `info`: Zus√§tzliche Beschreibung unter dem Label\n",
    "- `value`: Standardwerte setzen\n",
    "- `multiselect=True`: Mehrfachauswahl erm√∂glichen\n",
    "- `examples`: Vorgefertigte Testdaten f√ºr schnelle Demo\n",
    "\n",
    "**Output**\n",
    "\n",
    "Beispiel: \"The 4 cats from Japan and Pakistan went to the park where they ate and swam until the morning\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eac56ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Die Reihenfolge der Parameter in der Funktion muss mit der Reihenfolge der Inputs √ºbereinstimmen\n",
    "def sentence_builder(quantity, animal, countries, place, activity_list, morning):\n",
    "    return f\"\"\"The {quantity} {animal}{\"s\" if quantity > 1 else \"\"} from {\" and \".join(countries)} went to the {place} where they {\" and \".join(activity_list)} until the {\"morning\" if morning else \"night\"}\"\"\"\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=sentence_builder,\n",
    "    inputs=[\n",
    "        # Die Info wird unterhalb von Label dargestellt\n",
    "        gr.Slider(2, 20, value=4, label=\"Count\",\n",
    "                  info=\"Choose between 2 and 20\"),\n",
    "        gr.Dropdown([\"cat\", \"dog\", \"bird\"], label=\"Animal\",\n",
    "                    info=\"Will add more animals later!\"),\n",
    "        gr.CheckboxGroup([\"USA\", \"Japan\", \"Pakistan\"],\n",
    "                         label=\"Countries\", info=\"Where are they from?\"),\n",
    "        gr.Radio([\"park\", \"zoo\", \"road\"], label=\"Location\",\n",
    "                 info=\"Where did they go?\"),\n",
    "        gr.Dropdown([\"ran\", \"swam\", \"ate\", \"slept\"],\n",
    "                    # Voreinstellung f√ºr die Dropdown-Auswahl\n",
    "                    value=[\"swam\", \"slept\"],\n",
    "                    multiselect=True,\n",
    "                    label=\"Activity\",\n",
    "                    info=\"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed auctor, nisl eget ultricies aliquam, nunc nisl aliquet nunc, eget aliquam nisl nunc vel nisl.\"\n",
    "                    ),\n",
    "        gr.Checkbox(label=\"Morning\", info=\"Did they do it in the morning?\"),\n",
    "    ],\n",
    "    outputs=gr.Textbox(\n",
    "        label=\"Output\", info=\"This is the generated sentence based on your inputs.\"),  # Ausgabeformat\n",
    "    examples=[\n",
    "        # Mithilfe von Examples k√∂nnen wir vorgefertigte Eingaben bereitstellen, die der Nutzer ausw√§hlen kann um die App zu testen\n",
    "        [2, \"cat\", [\"Japan\", \"Pakistan\"], \"park\", [\"ate\", \"swam\"], True],\n",
    "        [4, \"dog\", [\"Japan\"], \"zoo\", [\"ate\", \"swam\"], False],\n",
    "        [10, \"bird\", [\"USA\", \"Pakistan\"], \"road\", [\"ran\"], False],\n",
    "        [8, \"cat\", [\"Pakistan\"], \"zoo\", [\"ate\"], True],\n",
    "    ]\n",
    ")\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807bcbff",
   "metadata": {},
   "source": [
    "### Beispiel 3: Blocks\n",
    "\n",
    "1. `Blocks`\n",
    "\n",
    "- `gr.Blocks` ist das Container-Layout-System in Gradio, mit dem komplexe Benutzeroberfl√§chen modular aufgebaut werden k√∂nnen.  \n",
    "- Innerhalb eines Blocks lassen sich verschiedene Layout-Elemente wie `Row`, `Column` oder Tabs definieren.  \n",
    "- Man kann auch Themes (z. B. `gr.themes.Citrus()`) zuweisen, um das Design global zu steuern.  \n",
    "- `with` in Python (Kontextmanager): wird als als **Kontextmanager** verwendet, um einen bestimmten G√ºltigkeitsbereich f√ºr Objekte zu er√∂ffnen. In Gradio bedeutet das: Alle Komponenten, die innerhalb von `with gr.Row():` oder `with gr.Column():` geschrieben werden, geh√∂ren automatisch zu diesem Layout. Dadurch spart man sich explizite Zuordnungen und schreibt √ºbersichtlicheren Code, da die Hierarchie durch Einr√ºckung klar erkennbar ist.  \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "2. `Row`\n",
    "\n",
    "- `gr.Row()` ordnet die enthaltenen Komponenten **nebeneinander in einer horizontalen Reihe** an.  \n",
    "- Alle Elemente innerhalb einer Row teilen sich den verf√ºgbaren Platz gleichm√§√üig (sofern keine speziellen Breiten angegeben sind).  \n",
    "- Typisches Beispiel: Mehrere Eingabefelder wie Textboxen oder Zahlenfelder, die nebenl√§ufig erscheinen sollen.  \n",
    "\n",
    "---\n",
    "\n",
    "3. `Column`\n",
    "\n",
    "- `gr.Column()` ordnet die enthaltenen Komponenten **untereinander in einer vertikalen Spalte** an.  \n",
    "- Sie eignet sich, um Inhalte strukturiert √ºbereinander darzustellen, z. B. einen Button und das dazugeh√∂rige Ausgabefeld.  \n",
    "- Man kann `Row` und `Column` auch verschachteln, um flexible Layouts zu gestalten (z. B. eine Zeile mit Spalten, die wiederum Reihen enthalten).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da111d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# Funktion, die ausgef√ºhrt wird, wenn der Button geklickt wird\n",
    "def begruessung(vorname, nachname, alter):\n",
    "    return f\"Hallo, {vorname} {nachname}! Du bist {alter} Jahre alt.\"\n",
    "\n",
    "# Erstellen des Blocks\n",
    "with gr.Blocks() as demo:\n",
    "    # Vertikales Layout\n",
    "    with gr.Row():\n",
    "        vorname_input = gr.Textbox(label=\"Vorname\")\n",
    "        nachname_input = gr.Textbox(label=\"Nachname\")\n",
    "        alter_input = gr.Number(label=\"Alter\")\n",
    "    with gr.Column():\n",
    "        begruessung_button = gr.Button(\"Sag Hallo\")\n",
    "        output_text = gr.Textbox(label=\"Ausgabe\")\n",
    "\n",
    "    # Event: Button klickt -> Funktion ausf√ºhren -> Ergebnis in output_text schreiben (Mehr zu Events direkt darunter)\n",
    "    begruessung_button.click(begruessung, \n",
    "                             inputs=[vorname_input, \n",
    "                                     nachname_input, \n",
    "                                     alter_input], \n",
    "                             outputs=output_text)\n",
    "\n",
    "# demo.launch(theme=gr.themes.Citrus())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9c7122",
   "metadata": {},
   "source": [
    "### Beispiel 4: Events\n",
    "\n",
    "#### A) Click Event\n",
    "\n",
    "üëâ Erkl√§rung: Durch `.click()` wird eine Funktion `fn` aufgerufen. `.click()` wird von `Button`, `ClearButton` und `UploadButton` unterst√ºtzt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06491fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# Funktion, die aufgerufen wird, wenn der Button geklickt wird\n",
    "def greet(name):\n",
    "    return f\"Hallo {name}!\"\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    # Eingabefeld f√ºr den Namen\n",
    "    name = gr.Textbox(label=\"Name eingeben\")\n",
    "    \n",
    "    # Ausgabefeld f√ºr die Antwort\n",
    "    output = gr.Textbox(label=\"Antwort\")\n",
    "    \n",
    "    # Button, der das Event ausl√∂st\n",
    "    btn = gr.Button(\"Gr√º√üen\")\n",
    "    \n",
    "    # Event: Wenn Button geklickt wird (.click),\n",
    "    # dann wird die Funktion greet() ausgef√ºhrt.\n",
    "    # Inputs = \"name\", Outputs = \"output\"\n",
    "    btn.click(fn=greet, inputs=name, outputs=output)\n",
    "\n",
    "# demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94fd5f5",
   "metadata": {},
   "source": [
    "#### B) Submit Event\n",
    "\n",
    "üëâ Erkl√§rung: Durch `.submit()` wird eine Funktion `fn` aufgerufen, sobald der Nutzer Enter dr√ºckt oder ein Formular absendet. `.submit()` wird von `Textbox` und `Chatbot` unterst√ºtzt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "577179f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# Funktion: gibt den Text r√ºckw√§rts zur√ºck\n",
    "def reverse_text(text):\n",
    "    return text[::-1]\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    # Eingabefeld: Nutzer tippt Text und dr√ºckt Enter\n",
    "    inp = gr.Textbox(label=\"Text eingeben und Enter dr√ºcken\")\n",
    "    \n",
    "    # Ausgabe: zeigt den umgedrehten Text\n",
    "    out = gr.Textbox(label=\"Umgekehrter Text\")\n",
    "    \n",
    "    # Event: Wenn der Nutzer Enter dr√ºckt (.submit),\n",
    "    # wird die Funktion reverse_text() ausgef√ºhrt\n",
    "    inp.submit(fn=reverse_text, inputs=inp, outputs=out)\n",
    "\n",
    "# demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c879e5c7",
   "metadata": {},
   "source": [
    "#### C) Change Event\n",
    "\n",
    "üëâ Erkl√§rung: Durch `.change()` wird eine Funktion `fn` aufgerufen, sobald sich der Wert eines Elements √§ndert. `.change()` wird von `Dropdown`, `Checkbox`, `CheckboxGroup`, `Radio`, `Slider`, `Number`, `ColorPicker`, `Image` und `File` unterst√ºtzt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ead4941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# Funktion: beschreibt die gew√§hlte Farbe\n",
    "def describe_color(color):\n",
    "    return f\"Du hast {color} ausgew√§hlt.\"\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    # Dropdown mit drei Auswahlm√∂glichkeiten\n",
    "    dropdown = gr.Dropdown(choices=[\"Rot\", \"Gr√ºn\", \"Blau\"], label=\"Farbe w√§hlen\")\n",
    "    \n",
    "    # Ausgabe: zeigt die Beschreibung\n",
    "    out = gr.Textbox(label=\"Beschreibung\")\n",
    "    \n",
    "    # Event: Wenn die Auswahl im Dropdown ge√§ndert wird (.change),\n",
    "    # wird die Funktion describe_color() ausgef√ºhrt\n",
    "    dropdown.change(fn=describe_color, inputs=dropdown, outputs=out)\n",
    "\n",
    "# demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1df587c",
   "metadata": {},
   "source": [
    "#### D) Input Event\n",
    "\n",
    "üëâ Erkl√§rung: Durch `.input()` wird eine Funktion `fn` w√§hrend der Eingabe im Element aufgerufen (z. B. bei jedem Tastendruck). `.input()` wird von `Textbox`, `Number` und `Slider` unterst√ºtzt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a48e08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# Funktion: berechnet die L√§nge des eingegebenen Textes\n",
    "def live_length(text):\n",
    "    return f\"L√§nge: {len(text)} Zeichen\"\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    # Eingabefeld, wo man live tippt\n",
    "    inp = gr.Textbox(label=\"Gib etwas ein...\")\n",
    "    \n",
    "    # Ausgabe: zeigt sofort die L√§nge des Textes\n",
    "    out = gr.Textbox(label=\"L√§nge\")\n",
    "    \n",
    "    # Event: W√§hrend der Nutzer tippt (.input),\n",
    "    # wird die Funktion live_length() sofort aufgerufen\n",
    "    inp.input(fn=live_length, inputs=inp, outputs=out)\n",
    "\n",
    "# demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c97ea9",
   "metadata": {},
   "source": [
    "#### E) Verkettung mit `.then()\n",
    "\n",
    "üëâ Erkl√§rung: Durch `.then()` wird eine Funktion `fn` aufgerufen, nachdem eine andere Funktion (z.‚ÄØB. durch `.click()` oder `.submit()`) erfolgreich ausgef√ºhrt wurde. `.then()` wird von allen Elementen unterst√ºtzt, die zuvor ein Event wie `.click()`, `.submit()` oder `.input()` ausl√∂sen.\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5977d868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# Funktion 1: Begr√º√üt den Nutzer\n",
    "def greet(name):\n",
    "    return f\"Hallo {name}!\"\n",
    "\n",
    "# Funktion 2: Gibt die L√§nge des Namens zur√ºck\n",
    "def name_length(greeting):\n",
    "    return f\"L√§nge der Begr√º√üung: {len(greeting)} Zeichen\"\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    name = gr.Textbox(label=\"Name eingeben\")\n",
    "    output1 = gr.Textbox(label=\"Begr√º√üung\")\n",
    "    output2 = gr.Textbox(label=\"L√§nge der Begr√º√üung\")\n",
    "    btn = gr.Button(\"Gr√º√üen\")\n",
    "    \n",
    "    # Event: zuerst greet() aufrufen, dann name_length() mit .then()\n",
    "    btn.click(fn=greet, inputs=name, outputs=output1).then(fn=name_length, inputs=output1, outputs=output2)\n",
    "\n",
    "# demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a425d67",
   "metadata": {},
   "source": [
    "### Beispiel 5: Verschalten von Layouts und Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c23ce9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1):\n",
    "            gr.Textbox(label=\"Links 1\")\n",
    "            gr.Textbox(label=\"Links 2\")\n",
    "        with gr.Column(scale=2):\n",
    "            gr.Textbox(label=\"Rechts 1\")\n",
    "            gr.Textbox(label=\"Rechts 2\")\n",
    "\n",
    "# demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc0cf9f",
   "metadata": {},
   "source": [
    "### Beispiel 6: Tabs\n",
    "\n",
    "Tab() ist ein Layoutelement. Innerhalb des Tabs definierte Komponenten sind sichtbar, wenn dieser Tab ausgew√§hlt ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba20a685",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    with gr.Tab(\"Tab 1\"):\n",
    "        gr.Textbox(label=\"Text 1\")\n",
    "        gr.Textbox(label=\"Text 2\")\n",
    "    with gr.Tab(\"Tab 2\"):\n",
    "        gr.Textbox(label=\"Text 1\")\n",
    "        gr.Textbox(label=\"Text 2\")\n",
    "        \n",
    "# demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d5b3f9",
   "metadata": {},
   "source": [
    "### Beispiel 7: Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10bde5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = [\n",
    "    {\"role\": \"user\", \"content\": \"What time is it?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"It's 3 PM.\"},\n",
    "]\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Chatbot(history)\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdd5a99",
   "metadata": {},
   "source": [
    "### Beispiel 8: Chatbot mit Eingabefeld und Button\n",
    "\n",
    "In diesem Beispiel wird ein vollst√§ndiger **Chatbot** implementiert, der mit einem Large Language Model (LLM) kommuniziert. Das Beispiel zeigt mehrere wichtige Konzepte:\n",
    "\n",
    "- **`gr.Chatbot`**: Eine spezielle Komponente zur Darstellung von Chat-Verl√§ufen im typischen Messenger-Stil. Mit `type=\"messages\"` wird das OpenAI-kompatible Nachrichtenformat verwendet (`{\"role\": \"...\", \"content\": \"...\"}`).\n",
    "\n",
    "- **`gr.Row()` und `gr.Column()`**: Erm√∂glichen ein flexibles Layout, hier um das Eingabefeld und den Sende-Button nebeneinander anzuordnen. Der `scale`-Parameter steuert die relative Breite der Spalten.\n",
    "\n",
    "- **`.then()`-Verkettung**: Diese Methode erlaubt es, mehrere Funktionen nacheinander auszuf√ºhren. Hier wird zuerst die Nutzernachricht hinzugef√ºgt (`add_user_message`), und danach automatisch die LLM-Antwort geholt (`get_llm_response`).\n",
    "\n",
    "- **OpenAI-Client**: Die Kommunikation mit dem LLM erfolgt √ºber die OpenAI-kompatible API, wodurch der Code auch mit lokalen LLMs (wie hier via Ollama) funktioniert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20feab21",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_URL = \"http://132.199.138.16:11434/v1\"\n",
    "LLM_MODEL = \"gemma3:12b\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db8be873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "client = openai.OpenAI(\n",
    "    base_url=LLM_URL,\n",
    "    api_key=\"ollama\",\n",
    ")\n",
    "\n",
    "history = [\n",
    "    {\"role\": \"user\", \"content\": \"What time is it?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"It's 3 PM.\"},\n",
    "]\n",
    "\n",
    "\n",
    "def add_user_message(message, chat_history):\n",
    "    \"\"\"F√ºgt sofort die User-Message hinzu\"\"\"\n",
    "    if message.strip():\n",
    "        chat_history.append({\"role\": \"user\", \"content\": message})\n",
    "    return chat_history, \"\"\n",
    "\n",
    "\n",
    "def get_llm_response(chat_history):\n",
    "    \"\"\"Holt die LLM-Antwort und f√ºgt sie hinzu\"\"\"\n",
    "    if not chat_history or chat_history[-1][\"role\"] != \"user\":\n",
    "        return chat_history\n",
    "\n",
    "    # API-Request an das LLM using OpenAI client\n",
    "    response = client.chat.completions.create(\n",
    "        model=LLM_MODEL,\n",
    "        messages=chat_history,\n",
    "        stream=False\n",
    "    )\n",
    "\n",
    "    assistant_reply = response.choices[0].message.content\n",
    "    chat_history.append({\"role\": \"assistant\", \"content\": assistant_reply})\n",
    "\n",
    "    return chat_history\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(value=history)\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=4):\n",
    "            user_input = gr.Textbox(\n",
    "                label=\"User Input\", placeholder=\"Type a message...\")\n",
    "        with gr.Column(scale=1):\n",
    "            send_btn = gr.Button(\"Send\", variant=\"primary\")\n",
    "\n",
    "    # Chain die Funktionen: erst User-Message hinzuf√ºgen, dann LLM-Antwort holen\n",
    "    # .then() in Gradio verkettet zwei Funktionen, sodass die zweite automatisch ausgef√ºhrt wird, nachdem die erste abgeschlossen ist.\n",
    "    # Die Outputs der ersten Funktion werden als Inputs an die zweite Funktion weitergegeben, wodurch eine sequenzielle Abarbeitung entsteht.\n",
    "    send_btn.click(\n",
    "        fn=add_user_message,\n",
    "        inputs=[user_input, chatbot],\n",
    "        outputs=[chatbot, user_input]\n",
    "    ).then(\n",
    "        fn=get_llm_response,\n",
    "        inputs=[chatbot],\n",
    "        outputs=[chatbot]\n",
    "    )\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc75240a",
   "metadata": {},
   "source": [
    "## Aufgabe 1: Gradio-Anwendung zur Bild-Fragebeantwortung\n",
    "\n",
    "\n",
    "In dieser Aufgabe implementierst du eine kleine **Aspect-Based Sentiment Analysis (ABSA)** Anwendung mit Gradio.\n",
    "\n",
    "Ziel ist, dass der Nutzer im UI einen Text und eine Liste von Kategorien eingibt. Die Anwendung soll dann f√ºr jede Kategorie das Sentiment (üòä positiv, üòê neutral, üòû negativ) im Text erkennen und in einer Tabelle im UI anzeigen.\n",
    "\n",
    "---\n",
    "\n",
    "### Schritte\n",
    "\n",
    "1. **Eingaben pr√ºfen**  \n",
    "   - Falls kein Text: Fehlermeldung zur√ºckgeben.  \n",
    "   - Falls keine Kategorie(n): Fehlermeldung zur√ºckgeben.  \n",
    "   - Hinweis: Kategorien sind **kommagetrennt**.\n",
    "\n",
    "2. **Prompt erstellen & Modell aufrufen**  \n",
    "   - Nutze die Funktion `get_user_prompt(text, categories_list)`.  \n",
    "   - Rufe das LLM mit `llm_text_to_json(user_prompt)` auf.  \n",
    "   - Ergebnis ist ein JSON mit `items: [{category, sentiment}]`.\n",
    "\n",
    "3. **Ausgabe formatieren**  \n",
    "   - Erstelle eine Tabelle mit Spalten: **Kategorie**, **Sentiment**.  \n",
    "   - Emojis f√ºr Sentiment nutzen (optional):\n",
    "     - üòä Positiv\n",
    "     - üòê Neutral\n",
    "     - üòû Negativ  \n",
    "   - Falls keine Kategorie erkannt ‚Üí Hinweis ausgeben.\n",
    "\n",
    "4. **UI bauen**  \n",
    "   - Nutze Gradio `Blocks` mit:\n",
    "     - Textbox f√ºr den Text  \n",
    "     - Textbox f√ºr Kategorien  \n",
    "     - Button ‚ÄûSentiment analysieren‚Äú  \n",
    "     - Tabelle mit Ergebnissen  \n",
    "     - HTML f√ºr Fehlermeldungen  \n",
    "     - Beispiele (`gr.Examples`) zum Testen\n",
    "\n",
    "---\n",
    "\n",
    "## üí° Hilfen\n",
    "- Verwende `strip()` und `split(\",\")`, um Kategorien zu bereinigen.  \n",
    "- Nutze `if not ...:` f√ºr Validierungen.  \n",
    "- R√ºckgabewert von `analyze_sentiment_guided`:  \n",
    "  ```python\n",
    "  return table_data, error_message\n",
    "  ```\n",
    "- Denke an den leeren Array-Fall: Keine Kategorie erkannt ‚Üí Hinweis anzeigen.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47af91e5",
   "metadata": {},
   "source": [
    "Folgender Code ist gegeben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1673ce15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from enum import Enum\n",
    "import json\n",
    "\n",
    "\n",
    "class Sentiment(str, Enum):\n",
    "    positive = \"positive\"\n",
    "    neutral = \"neutral\"\n",
    "    negative = \"negative\"\n",
    "\n",
    "\n",
    "class ABSAItem(BaseModel):\n",
    "    category: str\n",
    "    sentiment: Sentiment\n",
    "\n",
    "\n",
    "class ABSAResponse(BaseModel):\n",
    "    items: list[ABSAItem]\n",
    "\n",
    "\n",
    "def get_user_prompt(text, categories_list):\n",
    "    user_prompt = (\n",
    "        f\"Text: {text}\\n\"\n",
    "        f\"Kategorien: {categories_list}\\n\"\n",
    "        \"Gib ein JSON-Objekt mit einem 'items' Array zur√ºck, das Objekte mit {category, sentiment} f√ºr jede Kategorie enth√§lt. \"\n",
    "        \"Das Sentiment soll eines von folgenden sein: positive, neutral, negative. \"\n",
    "        \"WICHTIG: Gib nur Kategorien zur√ºck, zu denen im Text tats√§chlich ein Sentiment ge√§u√üert wird. \"\n",
    "        \"Falls keine Stimmung gegen√ºber den genannten Kategorien im Text ausgedr√ºckt wird, gib ein leeres Array zur√ºck. \"\n",
    "        \"Kategorien ohne erkennbares Sentiment sollen NICHT in der Antwort enthalten sein.\"\n",
    "    )\n",
    "    return user_prompt\n",
    "\n",
    "\n",
    "def llm_text_to_json(user_prompt):\n",
    "    completion = client.chat.completions.parse(\n",
    "        temperature=0,\n",
    "        model=LLM_MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        response_format=ABSAResponse,\n",
    "    )\n",
    "\n",
    "    output = completion.choices[0].message.content\n",
    "\n",
    "    structured_output = json.loads(output)\n",
    "    return structured_output\n",
    "\n",
    "\n",
    "# === Beispiele f√ºr die UI ===\n",
    "examples = [\n",
    "    [\n",
    "        \"Das Essen war lecker, aber der Service war sehr langsam.\",\n",
    "        \"Essen, Service\",\n",
    "    ],\n",
    "    [\n",
    "        \"Das Handy hat eine gro√üartige Kamera, aber der Akku ist schwach.\",\n",
    "        \"Kamera, Akku, Design\",\n",
    "    ],\n",
    "    [\n",
    "        \"Die Lieferung kam p√ºnktlich, aber die Verpackung war besch√§digt.\",\n",
    "        \"Lieferung, Verpackung\",\n",
    "    ],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b2d2534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier kannst du die Gradio-App erstellen..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e661061",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>L√∂sung anzeigen</b></summary>\n",
    "\n",
    "```python\n",
    "def analyze_sentiment_guided(text, categories):\n",
    "    # Zun√§chst pr√ºfen, ob die Eingaben g√ºltig sind\n",
    "    # und entsprechende Fehlermeldungen zur√ºckgeben, wenn nicht.\n",
    "    if not text.strip():\n",
    "        return [], \"<h1>‚ö†Ô∏è Fehler, Bitte einen Text eingeben.</h1>\"\n",
    "    if not categories.strip():\n",
    "        return [], \"<h1>‚ö†Ô∏è Fehler, Bitte mindestens eine Kategorie eingeben.</h1>\"\n",
    "\n",
    "    categories_list = [c.strip() for c in categories.split(\",\") if c.strip()]\n",
    "    if not categories_list:\n",
    "        return [], \"<h1>‚ö†Ô∏è Fehler, Bitte mindestens eine Kategorie eingeben.</h1>\"\n",
    "\n",
    "\n",
    "    # Erstelle den User-Prompt und rufe das LLM auf, um die Sentiment-Analyse durchzuf√ºhren\n",
    "    user_prompt = get_user_prompt(text, categories_list)\n",
    "    structured_output = llm_text_to_json(user_prompt)\n",
    "\n",
    "\n",
    "    # Erstelle Tabellen-Daten\n",
    "    table_data = []\n",
    "    \n",
    "    for item in structured_output[\"items\"]:\n",
    "        if item[\"sentiment\"] == \"positive\":\n",
    "            sentiment_text = \"üòä Positiv\"\n",
    "        elif item[\"sentiment\"] == \"negative\":\n",
    "            sentiment_text = \"üòû Negativ\"\n",
    "        else:\n",
    "            sentiment_text = \"üòê Neutral\"\n",
    "        \n",
    "        table_data.append([item[\"category\"], sentiment_text])\n",
    "\n",
    "    if not table_data:\n",
    "        return [], \"<h1>‚ÑπÔ∏è Hinweis: Keine Kategorie im Text erw√§hnt.</h1>\"\n",
    "\n",
    "    return table_data, \"\"\n",
    "\n",
    "# Update the Gradio interface to use Table output\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## Aspect-Based Sentiment Analysis (ABSA) mit Guided JSON\")\n",
    "    \n",
    "    error_text = gr.HTML(\n",
    "        label=\"Status\",\n",
    "        visible=True\n",
    "    )\n",
    "\n",
    "    with gr.Row():\n",
    "        text_input = gr.Textbox(\n",
    "            label=\"Text eingeben\", placeholder=\"Gib einen Text ein...\", lines=5\n",
    "        )\n",
    "\n",
    "    with gr.Row():\n",
    "        category_list = gr.Textbox(\n",
    "            label=\"Kategorien (kommagetrennt)\", placeholder=\"z.B. Preis, Qualit√§t, Lieferung\"\n",
    "        )\n",
    "\n",
    "    analyze_btn = gr.Button(\"Sentiment analysieren\")\n",
    "    output_table = gr.Dataframe(\n",
    "        headers=[\"Kategorie\", \"Sentiment\"],\n",
    "        datatype=[\"str\", \"str\"],\n",
    "        label=\"ABSA Ergebnis\",\n",
    "    )\n",
    "\n",
    "    analyze_btn.click(\n",
    "        fn=analyze_sentiment_guided,\n",
    "        inputs=[text_input, category_list],\n",
    "        outputs=[output_table, error_text],\n",
    "    )\n",
    "\n",
    "    gr.Examples(\n",
    "        examples=examples,\n",
    "        inputs=[text_input, category_list],\n",
    "        label=\"Beispiele\",\n",
    "    )\n",
    "\n",
    "demo.launch()\n",
    "```\n",
    "\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_nils_hellwig",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
