{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e40f98b0",
   "metadata": {},
   "source": [
    "# üèóÔ∏è Notebook: Einf√ºhrung in strukturierte Outputs & Validierung bei LLMs\n",
    "\n",
    "In diesem Notebook lernen wir, wie man Large Language Models (LLMs) dazu bringt, strukturierte Ausgaben zu erzeugen.\n",
    "\n",
    "## üìö Quellen\n",
    "\n",
    "- [OpenAI: Validating LLM Outputs](https://platform.openai.com/docs/guides/structured-outputs?api-mode=chat)\n",
    "- [Pydantic Dokumentation](https://pydantic.dev/)\n",
    "- [Ollama Structured Outputs](https://ollama.com/blog/structured-outputs)\n",
    "\n",
    "---\n",
    "\n",
    "Viel Erfolg beim Ausprobieren und Validieren! ü§ó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ff304e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importiere die ben√∂tigten Bibliotheken\n",
    "from pydantic import BaseModel, Field\n",
    "from openai import OpenAI\n",
    "from typing import List, Literal, Optional\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6076c2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_URL = \"http://132.199.138.16:11434/v1\"\n",
    "LLM_MODEL = \"gemma3:4b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e645795",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    base_url=LLM_URL,\n",
    "    api_key=\"ollama\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c30007",
   "metadata": {},
   "source": [
    "Im Backend l√§uft ein Gemma3 Modell, das √ºber die OpenAI-kompatible API von Ollama angesprochen wird. **Erinnerung**: Neben Ollama gibt es auch andere Anbieter, die OpenAI-kompatible APIs bereitstellen, z.B. [vLLM](https://docs.vllm.ai/en/v0.8.2/features/structured_outputs.html).\n",
    "\n",
    "**Strukturierte Ausgaben** erm√∂glichen es, die Ausgabe eines Modells auf ein bestimmtes Format zu beschr√§nken, das durch ein **JSON-Schema** definiert wird. Ollama unterst√ºzt aktuell Strukturierte Ausgaben f√ºr das JSON-Format, ebenso wie die Entpunkte von OpenAI selbst f√ºr deren GPT Modelle. VLLM unterst√ºtzt auch Regex, allerdings gibt es noch einige Bugs (Stand Oktober 2025).\n",
    "\n",
    " \n",
    "Anwendungsf√§lle f√ºr strukturierte Ausgaben:\n",
    "\n",
    "- Daten aus Dokumenten extrahieren\n",
    "- Daten aus Bildern extrahieren\n",
    "- Alle Antworten von Sprachmodellen strukturieren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646920bb",
   "metadata": {},
   "source": [
    "### Beispiel 1: Datenmodelle definieren mit Pydantic\n",
    "\n",
    "Im ersten Beispiel definieren wir ein Datenmodell f√ºr Haustiere und lassen das Modell die Informationen aus einem Text extrahieren.\n",
    "Um strukturierte Ausgaben zu erm√∂glichen, definieren wir zwei Klassen mit **Pydantic**. Diese Klassen beschreiben die Struktur der erwarteten Ausgabe.\n",
    "\n",
    "**Pydantic** ist eine Python-Bibliothek zur **Datenvalidierung und -strukturierung**.   Sie erm√∂glicht es, mit **Python-Klassen (Modellen)** klar definierte Datenschemata f√ºr JSON-Objekte zu erstellen, die automatisch:\n",
    "\n",
    "- Typ√ºberpr√ºfungen durchf√ºhren\n",
    "- Daten in das gew√ºnschte Format konvertieren\n",
    "\n",
    "Ein detailliertes Cheat Sheet zu Pydantic findet ihr auf GRIPS.\n",
    "\n",
    "**Ablauf**\n",
    "\n",
    "1. **Datenmodelle definieren**  \n",
    "   Zwei Klassen werden mit `BaseModel` (von **Pydantic**) definiert:\n",
    "   - `Pet`: beschreibt ein einzelnes Haustier mit Attributen wie `name`, `animal`, `age`, `color`, `favorite_toy`.\n",
    "   - `PetList`: enth√§lt eine Liste mehrerer `Pet`-Objekte.\n",
    "\n",
    "2. **Eingabe-Prompt**  \n",
    "   Der Text (`prompt`) beschreibt zwei Haustiere in nat√ºrlicher Sprache.\n",
    "\n",
    "3. **Modellaufruf mit Strukturvorgabe**  \n",
    "   `client.beta.chat.completions.parse()` ruft das Sprachmodell auf und nutzt `response_format=PetList`, um die Ausgabe **automatisch in die definierte JSON-Struktur** zu parsen.\n",
    "\n",
    "4. **Ausgabe**  \n",
    "   Das Modell gibt die erkannten Haustiere als **strukturiertes JSON-Objekt** zur√ºck, das automatisch den Feldern von `PetList` entspricht.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1bdadff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pets': [{'name': 'Luna', 'animal': 'cat', 'age': 5, 'color': 'grey', 'favorite_toy': 'yarn'}, {'name': 'Loki', 'animal': 'cat', 'age': 2, 'color': 'black', 'favorite_toy': 'tennis balls'}]}\n"
     ]
    }
   ],
   "source": [
    "class Pet(BaseModel):\n",
    "    name: str\n",
    "    animal: str\n",
    "    age: int\n",
    "    color: str | None\n",
    "    favorite_toy: str | None\n",
    "\n",
    "\n",
    "class PetList(BaseModel):\n",
    "    pets: list[Pet]\n",
    "\n",
    "\n",
    "prompt = '''\n",
    "I have two pets.\n",
    "A cat named Luna who is 5 years old and loves playing with yarn. She has grey fur.\n",
    "I also have a 2 year old black cat named Loki who loves tennis balls.\n",
    "'''\n",
    "\n",
    "completion = client.chat.completions.parse(\n",
    "    temperature=0,\n",
    "    model=LLM_MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    response_format=PetList,\n",
    ")\n",
    "\n",
    "output = completion.choices[0].message.content\n",
    "\n",
    "# Die LLM-Antwort ist im String-Format. Wir m√ºssen sie in ein Python-Dictionary umwandeln.\n",
    "output_dict = json.loads(output)\n",
    "print(output_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f26f01",
   "metadata": {},
   "source": [
    "### Beispiel 2: Textklassifikation\n",
    "\n",
    "Wir k√∂nnen auch ein einfaches Klassifikationsschema definieren, um Texte zu kategorisieren. In diesem Beispiel klassifizieren wir kurze Texte in die Kategorien \"positive\", \"negative\" oder \"neutral\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d8e3e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Dict: {'sentiment': 'positive'}\n",
      "Stimmung: positive\n"
     ]
    }
   ],
   "source": [
    "class SentimentResult(BaseModel):\n",
    "    sentiment: Literal[\"positive\", \"neutral\", \"negative\"]\n",
    "\n",
    "prompt = f\"Classify the sentiment of this text as positive, neutral, or negative:\\n\\nI love programming in Python!\"\n",
    "\n",
    "completion = client.chat.completions.parse(\n",
    "    temperature=0,\n",
    "    model=LLM_MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    response_format=SentimentResult,\n",
    ")\n",
    "\n",
    "output = completion.choices[0].message.content\n",
    "\n",
    "# Die LLM-Antwort ist im String-Format. Wir m√ºssen sie in ein Python-Dictionary umwandeln.\n",
    "output_dict = json.loads(output)\n",
    "print(f\"Output Dict: {output_dict}\")\n",
    "\n",
    "# Geben wir nur die Stimmung aus\n",
    "print(f\"Stimmung: {output_dict['sentiment']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99d11ac",
   "metadata": {},
   "source": [
    "### Beispiel 3: JSON Schema im Prompt\n",
    "\n",
    "Wir k√∂nnen dem LLM auch das json schema direkt im Prompt √ºbergeben. `json.dumps(json_schema, indent=2)` wandelt das Python-Dictionary in einen JSON-String um, der im Prompt verwendet werden kann. `indent=2` sorgt f√ºr eine lesbare Formatierung mit Einr√ºckungen. 2 bedeutet, dass jede Ebene im JSON um 2 Leerzeichen einger√ºckt wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff24067f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entwickler': [{'name': 'Alice M√ºller', 'programmiersprache': 'python', 'erfahrung_jahre': 8, 'spezialisierung': 'backend'}, {'name': 'Bob Schmidt', 'programmiersprache': 'javascript', 'erfahrung_jahre': 2, 'spezialisierung': 'frontend'}]}\n"
     ]
    }
   ],
   "source": [
    "# Definiere eine Pydantic-Klasse f√ºr einen einzelnen Softwareentwickler\n",
    "class Developer(BaseModel):\n",
    "    name: str  # Name des Entwicklers\n",
    "    programmiersprache: Literal[\"python\", \"java\", \"javascript\", \"csharp\", \"cpp\", \"go\", \"rust\", \"php\"]  # Hauptprogrammiersprache\n",
    "    erfahrung_jahre: int = Field(ge=0, le=50)  # Berufserfahrung in Jahren (0-50)\n",
    "    spezialisierung: Literal[\"frontend\", \"backend\", \"fullstack\", \"data_science\", \"devops\", \"mobile\"]  # Spezialisierungsbereich\n",
    "\n",
    "# Definiere eine Pydantic-Klasse f√ºr eine Liste von genau 4 Entwicklern\n",
    "class DeveloperList(BaseModel):\n",
    "    entwickler: List[Developer] = Field(min_length=2, max_length=2)  # Genau 4 Developer-Objekte\n",
    "\n",
    "# Erzeuge das JSON-Schema aus der DeveloperList-Klasse\n",
    "json_schema = DeveloperList.model_json_schema()\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Generate a JSON array of exactly 2 software developers with the following fields:\n",
    "- name: string\n",
    "- programmiersprache: one of [\"python\", \"java\", \"javascript\", \"csharp\", \"cpp\", \"go\", \"rust\", \"php\"]\n",
    "- erfahrung_jahre: integer between 0 and 50\n",
    "- spezialisierung: one of [\"frontend\", \"backend\", \"fullstack\", \"data_science\", \"devops\", \"mobile\"]      \n",
    "Make sure the output strictly adheres to this JSON schema:\n",
    "{json.dumps(json_schema, indent=2)}\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.parse(\n",
    "    temperature=0,\n",
    "    model=LLM_MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    response_format=DeveloperList,\n",
    ")\n",
    "\n",
    "output = completion.choices[0].message.content\n",
    "\n",
    "# Die LLM-Antwort ist im String-Format. Wir m√ºssen sie in ein Python-Dictionary umwandeln.\n",
    "output_dict = json.loads(output)\n",
    "print(output_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7804f687",
   "metadata": {},
   "source": [
    "### √úbungsaufgabe 1\n",
    "\n",
    "Um die Validierung von JSON-Ausgaben zu √ºben, erstelle ein Prompt, das das LLM anweist, eine strukturierte Antwort im JSON-Format zu liefern.\n",
    "\n",
    "---\n",
    "\n",
    "#### üéØ Aufgabe\n",
    "\n",
    "Definiere ein einfaches JSON-Schema um Dummy-Daten zu **Musikern** zu generieren.\n",
    "\n",
    "#### üé§ Interpret-Schema\n",
    "\n",
    "| Feld     | Beschreibung                                                |\n",
    "| -------- | ----------------------------------------------------------- |\n",
    "| `name`   | Name des Interpreten                                        |\n",
    "| `age`    | Alter (zwischen 18 und 100)                                 |\n",
    "| `genre`  | Musikrichtung aus: **Rock**, **Pop**, **Jazz**, **Klassik** |\n",
    "| `albums` | Liste von Alben                                             |\n",
    "\n",
    "#### üíø Album-Schema\n",
    "\n",
    "| Feld           | Beschreibung                              |\n",
    "| -------------- | ----------------------------------------- |\n",
    "| `title`        | Album-Titel                               |\n",
    "| `release_year` | Erscheinungsjahr (zwischen 1900 und 2023) |\n",
    "| `tracks`       | Liste von Songtiteln                      |\n",
    "\n",
    "---\n",
    "\n",
    "#### üí° Tipp\n",
    "\n",
    "Nutze Pydantic-Klassen mit `Field()`-Validierungen und das `Literal`-Typ-System f√ºr die Genre-Auswahl!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34a6bd4",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>L√∂sung anzeigen</b></summary>\n",
    "\n",
    "```python\n",
    "# Definiere eine Pydantic-Klasse f√ºr ein Album\n",
    "class Album(BaseModel):\n",
    "    title: str\n",
    "    release_year: int = Field(ge=1900, le=2023)\n",
    "    tracks: List[str]\n",
    "\n",
    "# Definiere eine Pydantic-Klasse f√ºr einen Musiker\n",
    "class Musician(BaseModel):\n",
    "    name: str\n",
    "    age: int = Field(ge=18, le=100)\n",
    "    genre: Literal[\"Rock\", \"Pop\", \"Jazz\", \"Klassik\"]\n",
    "    albums: List[Album]\n",
    "\n",
    "# Definiere eine Pydantic-Klasse f√ºr eine Liste von Musikern\n",
    "class MusicianList(BaseModel):\n",
    "    musicians: List[Musician] = Field(min_length=2, max_length=2)\n",
    "\n",
    "# Erzeuge das JSON-Schema aus der MusicianList-Klasse\n",
    "json_schema = MusicianList.model_json_schema()\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Generiere eine Liste von 2 Musikern mit den folgenden Feldern:\n",
    "- name: string\n",
    "- age: integer zwischen 18 und 100\n",
    "- genre: eines von [\"Rock\", \"Pop\", \"Jazz\", \"Klassik\"]\n",
    "- albums: Liste von Alben, jedes Album hat:\n",
    "  - title: string\n",
    "  - release_year: integer zwischen 1900 und 2023\n",
    "  - tracks: Liste von Songtiteln (strings)\n",
    "\n",
    "Gib die Daten als JSON zur√ºck, das streng diesem Schema entspricht:\n",
    "{json.dumps(json_schema, indent=2)}\n",
    "\"\"\"\n",
    "\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    temperature=0,\n",
    "    model=LLM_MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    response_format=MusicianList,\n",
    ")\n",
    "\n",
    "output = completion.choices[0].message.content\n",
    "\n",
    "# Die LLM-Antwort ist im String-Format. Wir m√ºssen sie in ein Python-Dictionary umwandeln.\n",
    "output_dict = json.loads(output)\n",
    "print(json.dumps(output_dict, indent=2, ensure_ascii=False))\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baa4a52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dein Code..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0306b1d2",
   "metadata": {},
   "source": [
    "### Beispiel 4: Guided JSON f√ºr strukturierte Extraktion von Informationen aus Dokumenten\n",
    "Beispiel f√ºr strukturierte Extraktion von Informationen aus einem Bild.\n",
    "\n",
    "Beispiel:\n",
    "\n",
    "<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQ0s5B5TIgNtd8NBG31BBu2v1cCxIZi3AEE2g&s\" alt=\"Structured Extraction Example\" width=\"100\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81aa5afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden wir das Bild und kodieren es in Base64. Base64 ist ein Textformat, das bin√§re Daten (wie Bilder) in eine Textdarstellung umwandelt.\n",
    "import base64\n",
    "with open(\"beispiel_bild.png\", \"rb\") as image_file:\n",
    "    # Datei in Base64 umwandeln\n",
    "    encoded_string = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "# Als Data-URL formatieren. Data-URLs erm√∂glichen es, Bilder direkt in HTML oder JSON einzubetten.\n",
    "data_url = f\"data:image/png;base64,{encoded_string}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8025ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auf dem Bild sehe ich das ber√ºhmte Gem√§lde der Mona Lisa, auch bekannt als La Gioconda. Es ist ein Portr√§t einer Frau, vermutlich Lisa Gherardini, gemalt von Leonardo da Vinci. \n",
      "\n",
      "Hier sind einige Details, die ich sehe:\n",
      "\n",
      "*   **Die Frau:** Sie hat ein sanftes L√§cheln und einen nachdenklichen Blick.\n",
      "*   **Kleidung:** Sie tr√§gt dunkle Kleidung mit einem goldenen Faden.\n",
      "*   **Haltung:** Ihre H√§nde sind gefaltet im Scho√ü.\n",
      "*   **Hintergrund:** Es gibt eine verschwommene Landschaft im Hintergrund.\n",
      "\n",
      "Es ist eines der bekanntesten und meistbesuchten Kunstwerke der Welt.\n"
     ]
    }
   ],
   "source": [
    "# Beginnen wir zun√§chst ohne eine JSON Validierung, um die Ausgabe zu testen.\n",
    "# Das LLM soll zun√§chst in der Lage sein, ein Bild zu analysieren und eine Antwort zu generieren.\n",
    "\n",
    "image_url = \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQ0s5B5TIgNtd8NBG31BBu2v1cCxIZi3AEE2g&s\"\n",
    "\n",
    "prompt = \"Was siehst du auf diesem Bild?\"\n",
    "completion = client.chat.completions.parse(\n",
    "    temperature=0,\n",
    "    model=LLM_MODEL,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": data_url\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0742ce2a",
   "metadata": {},
   "source": [
    "### 4. Guided JSON f√ºr strukturierte Extraktion von Informationen aus Dokumenten\n",
    "\n",
    "Nun werden wir ein komplexeres Beispiel betrachten: die strukturierte Extraktion von Informationen aus einem Rechnungsdokument.\n",
    "\n",
    "#### Ziel der √úbung\n",
    "\n",
    "Wir m√∂chten ein Rechnungsdokument analysieren und die wichtigsten Informationen automatisch extrahieren:\n",
    "- **Liste der Produkte** mit Details\n",
    "- **Gesamtsumme** der Rechnung\n",
    "\n",
    "#### üñºÔ∏è Das Dokument\n",
    "\n",
    "So sieht das zu analysierende Rechnungsdokument aus:\n",
    "\n",
    "<img src=\"https://www.buchhaltungsbutler.de/wp-content/uploads/rechnungsvorlage11-e1692972330525.png\" alt=\"Rechnung Beispiel\" width=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ed56f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"beispiel_rechnung.png\", \"rb\") as image_file:\n",
    "    encoded_string = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "data_url = f\"data:image/png;base64,{encoded_string}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b6da11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvoiceItem(BaseModel):\n",
    "    beschreibung: str = Field(min_length=1, max_length=100)\n",
    "    anzahl: int = Field(ge=0, le=5)\n",
    "    einzelpreis_in_euro: int = Field(ge=0, le=1000)\n",
    "\n",
    "class Invoice(BaseModel):\n",
    "    gesamtbetrag: float = Field(gt=0)\n",
    "    artikel: List[InvoiceItem] = Field(min_length=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92d28f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"gesamtbetrag\": 35.70, \"artikel\": [\n",
      "    {\n",
      "        \"beschreibung\": \"Musterprodukt\",\n",
      "        \"anzahl\": 5,\n",
      "        \"einzelpreis_in_euro\": 300\n",
      "    },\n",
      "    {\n",
      "        \"beschreibung\": \"Musterprodukt\",\n",
      "        \"anzahl\": 3,\n",
      "        \"einzelpreis_in_euro\": 500\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Analysiere die Rechnung auf dem Bild und gib mir die Details als JSON. Die Anzahl an Artikeln entspricht der Anzahl an JSON-Objekten in der Liste: \"\n",
    "completion = client.chat.completions.parse(\n",
    "    temperature=0,\n",
    "    model=LLM_MODEL,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": data_url\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    response_format=Invoice,\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a3dcd9",
   "metadata": {},
   "source": [
    "### √úbungsaufgabe 2\n",
    "\n",
    "Jetzt bist du dran! Du m√∂chtest automatisiert Informationen aus Rechnungen extrahieren. \n",
    "\n",
    "Beispiel:\n",
    "\n",
    "<img src=\"https://images.t-online.de/2021/06/89589144v1/0x0:768x1024/fit-in/1366x0/image.jpg\" alt=\"Rechnung Beispiel\" width=\"400\">\n",
    "\n",
    "Das LLM soll folgende strukturierte Informationen im JSON-Format zur√ºckgeben:\n",
    "\n",
    "* Verk√§uferinformationen (alle Keys optional):\n",
    "  - Name\n",
    "  - Adresse\n",
    "\n",
    "* Summe der Rechnung\n",
    "* Liste der Produkte, jeweils mit:\n",
    "  - Produkt-ID\n",
    "  - Produktname\n",
    "  - Preis in Euro\n",
    "  - Steuergruppe\n",
    "  - Gesamtpreis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f6a3a0",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>L√∂sung anzeigen</b></summary>\n",
    "\n",
    "```python\n",
    "# Definiere eine Pydantic-Klasse f√ºr Verk√§uferinformationen\n",
    "class SellerInfo(BaseModel):\n",
    "    name: Optional[str] = None\n",
    "    address: Optional[str] = None\n",
    "\n",
    "# Definiere eine Pydantic-Klasse f√ºr ein Produkt\n",
    "class Product(BaseModel):\n",
    "    product_id: str\n",
    "    product_name: str\n",
    "    price_euro: float = Field(ge=0)\n",
    "    tax_group: str\n",
    "    total_price: float = Field(ge=0)\n",
    "\n",
    "# Definiere eine Pydantic-Klasse f√ºr die Rechnung\n",
    "class Invoice(BaseModel):\n",
    "    seller: SellerInfo\n",
    "    total_amount: float = Field(ge=0)\n",
    "    products: List[Product] = Field(min_length=1)\n",
    "\n",
    "# Laden wir das Bild und kodieren es in Base64\n",
    "with open(\"beispiel_kassenzettel.png\", \"rb\") as image_file:\n",
    "    encoded_string = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "data_url = f\"data:image/png;base64,{encoded_string}\"\n",
    "\n",
    "prompt = \"Analysiere die Rechnung auf dem Bild und extrahiere die Verk√§uferinformationen, die Gesamtsumme und die Liste der Produkte als JSON.\"\n",
    "\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    temperature=0,\n",
    "    model=LLM_MODEL,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": data_url\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    response_format=Invoice,\n",
    ")\n",
    "\n",
    "output = completion.choices[0].message.content\n",
    "\n",
    "# Die LLM-Antwort ist im String-Format. Wir m√ºssen sie in ein Python-Dictionary umwandeln.\n",
    "output_dict = json.loads(output)\n",
    "print(json.dumps(output_dict, indent=2, ensure_ascii=False))\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1907623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier steht dein Code..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_nils_hellwig",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
