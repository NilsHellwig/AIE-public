{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "336666e5",
   "metadata": {},
   "source": [
    "# Notebook: Einf√ºhrung in NLP f√ºr Python\n",
    "\n",
    "Dieses Notebook behandelt grundlegende Konzepte des NLP (Natural Language Processing) wie Tokenisierung, Stemming und Lemmatisierung. Diese Techniken sind wesentlich f√ºr die Verarbeitung und Analyse von Textdaten.\n",
    "\n",
    "Quelle: https://web.stanford.edu/~jurafsky/slp3/ed3book.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aabe9761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[2mResolved \u001b[1m127 packages\u001b[0m \u001b[2min 1.92s\u001b[0m\u001b[0m                                       \u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m31 packages\u001b[0m \u001b[2min 3.90s\u001b[0m\u001b[0m                                            \n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m31 packages\u001b[0m \u001b[2min 44ms\u001b[0m\u001b[0m                               \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mannotated-types\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mblis\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcatalogue\u001b[0m\u001b[2m==2.0.10\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mclick\u001b[0m\u001b[2m==8.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcloudpathlib\u001b[0m\u001b[2m==0.23.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mconfection\u001b[0m\u001b[2m==0.1.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcymem\u001b[0m\u001b[2m==2.0.11\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangcodes\u001b[0m\u001b[2m==3.5.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlanguage-data\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmarisa-trie\u001b[0m\u001b[2m==1.3.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmarkdown-it-py\u001b[0m\u001b[2m==4.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmdurl\u001b[0m\u001b[2m==0.1.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmurmurhash\u001b[0m\u001b[2m==1.0.13\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.3.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpreshed\u001b[0m\u001b[2m==3.0.10\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpydantic\u001b[0m\u001b[2m==2.12.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpydantic-core\u001b[0m\u001b[2m==2.41.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrich\u001b[0m\u001b[2m==14.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mshellingham\u001b[0m\u001b[2m==1.5.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msmart-open\u001b[0m\u001b[2m==7.4.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mspacy\u001b[0m\u001b[2m==3.8.7\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mspacy-legacy\u001b[0m\u001b[2m==3.0.12\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mspacy-loggers\u001b[0m\u001b[2m==1.0.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msrsly\u001b[0m\u001b[2m==2.5.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mthinc\u001b[0m\u001b[2m==8.3.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtqdm\u001b[0m\u001b[2m==4.67.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyper\u001b[0m\u001b[2m==0.20.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyping-inspection\u001b[0m\u001b[2m==0.4.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwasabi\u001b[0m\u001b[2m==1.1.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mweasel\u001b[0m\u001b[2m==0.4.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwrapt\u001b[0m\u001b[2m==2.0.0\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m130 packages\u001b[0m \u001b[2min 882ms\u001b[0m\u001b[0m                                       \u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m3 packages\u001b[0m \u001b[2min 630ms\u001b[0m\u001b[0m                                             \n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m3 packages\u001b[0m \u001b[2min 5ms\u001b[0m\u001b[0m                                 \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjoblib\u001b[0m\u001b[2m==1.5.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnltk\u001b[0m\u001b[2m==3.9.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mregex\u001b[0m\u001b[2m==2025.10.23\u001b[0m\n",
      "/Users/nils_hellwig/Documents/Seafile/Meine Bibliothek/Lehre/AIE-public/Notebooks/.venv/bin/python: No module named pip\n",
      "/Users/nils_hellwig/Documents/Seafile/Meine Bibliothek/Lehre/AIE-public/Notebooks/.venv/bin/python: No module named pip\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m132 packages\u001b[0m \u001b[2min 708ms\u001b[0m\u001b[0m                                       \u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m2 packages\u001b[0m \u001b[2min 349ms\u001b[0m\u001b[0m                                             \n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m2 packages\u001b[0m \u001b[2min 3ms\u001b[0m\u001b[0m.0                               \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdnspython\u001b[0m\u001b[2m==2.8.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1memail-validator\u001b[0m\u001b[2m==2.3.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# F√ºr dieses Projekt m√ºssen wir zun√§chst die folgenden Pakete installieren:\n",
    "!uv add spacy\n",
    "!uv add nltk\n",
    "!python -m spacy download de_core_news_sm\n",
    "!python -m spacy download en_core_web_sm\n",
    "!uv add email-validator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1d5aff",
   "metadata": {},
   "source": [
    "## Beispiele\n",
    "\n",
    "### Beispiel 1: Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7191ca",
   "metadata": {},
   "source": [
    "Wir haben bereits im Python-Notebook gelernt, wie wir Texte splitten k√∂nnen. Wiederholen wir das kurz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e45b54d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split nach Leerzeichen: ['Hallo', 'Welt!', 'Python', 'ist', 'eine', 'ziemlich', 'coole', 'Programmiersprache.', 'Ich', 'hoffe,', 'Sie', 'm√∂gen', 'sie', 'auch!']\n"
     ]
    }
   ],
   "source": [
    "text = \"Hallo Welt! Python ist eine ziemlich coole Programmiersprache. Ich hoffe, Sie m√∂gen sie auch!\"\n",
    "tokens_spaces = text.split()\n",
    "print(\"Split nach Leerzeichen:\", tokens_spaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acba1bab",
   "metadata": {},
   "source": [
    "Wie wir in der Ausgabe sehen, trennt die einfache `split()`-Methode W√∂rter, aber sie behandelt Satzzeichen nicht korrekt. Zum Beispiel wird \"Welt!\" als ein Token betrachtet, was in vielen NLP-Anwendungen nicht ideal ist. Daher verwenden wir spezialisierte **Tokenizer**, um dieses Problem zu l√∂sen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35e439d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/nils_hellwig/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wir laden NLTK, eine Bibliothek f√ºr nat√ºrliche Sprachverarbeitung\n",
    "import nltk\n",
    "\n",
    "# Punkt-Tokenizer herunterladen, ein Package, dass wir f√ºr die Tokenisierung ben√∂tigen. Punkt enth√§lt Regeln f√ºr die Tokenisierung von W√∂rtern und S√§tzen.\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a42c3807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK Word Tokenize: ['Hallo', 'Welt', '!', 'Python', 'ist', 'eine', 'ziemlich', 'coole', 'Programmiersprache', '.', 'Ich', 'hoffe', ',', 'Sie', 'm√∂gen', 'sie', 'auch', '!']\n"
     ]
    }
   ],
   "source": [
    "# Um die Tokenisierung durchzuf√ºhren, importieren wir die word_tokenize-Funktion aus dem nltk.tokenize Modul.\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Wir verwenden die word_tokenize-Funktion, um den Text in W√∂rter zu zerlegen.\n",
    "tokens_nltk = word_tokenize(text)\n",
    "\n",
    "# Ausgabe der tokenisierten W√∂rter\n",
    "print(\"NLTK Word Tokenize:\", tokens_nltk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9553931",
   "metadata": {},
   "source": [
    "Wir sehen, dass der Tokenizer Satzzeichen korrekt behandelt und jedes Wort sowie Satzzeichen als separate Tokens ausgibt. Des weiteren k√∂nnen wir auch S√§tze tokenisieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2694fc52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Satz-Tokenisierung: ['Hallo Welt!', 'Dies ist ein Test.', 'Hier ist noch ein Satz.']\n"
     ]
    }
   ],
   "source": [
    "# NLTK bietet auch eine Funktion zur Satz-Tokenisierung an.\n",
    "sentences = nltk.sent_tokenize(\"Hallo Welt! Dies ist ein Test. Hier ist noch ein Satz.\")\n",
    "print(\"Satz-Tokenisierung:\", sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8ddc36",
   "metadata": {},
   "source": [
    "### Beispiel 2: Part-of-Speech (POS) Tagging\n",
    "\n",
    "POS-Tagging erm√∂glicht es uns, die grammatikalische Rolle jedes Wortes in einem Satz zu identifizieren. Wir verwenden die `nltk`-Bibliothek, um dies zu demonstrieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e1a780c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK POS-Tagging (Englisch):\n",
      "[('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN'), ('.', '.')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /Users/nils_hellwig/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Definieren wir zun√§chst zwei Beispieltexte, einen auf Englisch und einen auf Deutsch.\n",
    "text_en = \"The quick brown fox jumps over the lazy dog.\"\n",
    "text_de = \"Der schnelle braune Fuchs springt √ºber den faulen Hund.\"\n",
    "\n",
    "# NLTK-Modelle herunterladen. averaged_perceptron_tagger ist ein vortrainiertes Modell f√ºr POS-Tagging.\n",
    "nltk.download(\"averaged_perceptron_tagger_eng\")\n",
    "\n",
    "# Tokenisieren und POS-Tagging (Englisch)\n",
    "tokens_en = nltk.word_tokenize(text_en)\n",
    "pos_tags_en = nltk.pos_tag(tokens_en)\n",
    "print(\"NLTK POS-Tagging (Englisch):\")\n",
    "print(pos_tags_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "77fb683d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "spaCy POS-Tagging (Englisch):\n",
      "The        DET       \n",
      "quick      ADJ       \n",
      "brown      ADJ       \n",
      "fox        NOUN      \n",
      "jumps      VERB      \n",
      "over       ADP       \n",
      "the        DET       \n",
      "lazy       ADJ       \n",
      "dog        NOUN      \n",
      ".          PUNCT     \n",
      "\n",
      "spaCy POS-Tagging (Deutsch):\n",
      "Der        DET       \n",
      "schnelle   ADJ       \n",
      "braune     ADJ       \n",
      "Fuchs      NOUN      \n",
      "springt    VERB      \n",
      "√ºber       ADP       \n",
      "den        DET       \n",
      "faulen     ADJ       \n",
      "Hund       NOUN      \n",
      ".          PUNCT     \n"
     ]
    }
   ],
   "source": [
    "# Auch mit spaCy k√∂nnen wir POS-Tagging durchf√ºhren. SpaCy (https://spacy.io/) ist eine sehr beliebte Bibliothek f√ºr NLP in Python, \n",
    "# da sie viele Tools und vortrainierte Modelle bietet f√ºr verschiedenste Anwendungen.\n",
    "import spacy\n",
    "\n",
    "# Laden wir zun√§chst die vortrainierten Modelle f√ºr Englisch.\n",
    "nlp_en = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Mit nlp_en k√∂nnen wir den Text in eine Liste von Tokens umwandeln.\n",
    "doc_en = nlp_en(text_en)\n",
    "\n",
    "# Tokens besitzen verschiedene Attribute, z.B. den Text und die Wortart (POS).\n",
    "print(\"\\nspaCy POS-Tagging (Englisch):\")\n",
    "for token in doc_en:\n",
    "    print(f\"{token.text:10} {token.pos_:10}\") # :10 sorgt f√ºr eine feste Breite von 10 Zeichen\n",
    "\n",
    "# Deutsches Modell\n",
    "nlp_de = spacy.load(\"de_core_news_sm\")\n",
    "doc_de = nlp_de(text_de)\n",
    "print(\"\\nspaCy POS-Tagging (Deutsch):\")\n",
    "for token in doc_de:\n",
    "    print(f\"{token.text:10} {token.pos_:10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb21251",
   "metadata": {},
   "source": [
    "### Beispiel 3: Lemmatization und Stemming\n",
    "\n",
    "Wie in der Vorlesung besprochen, ist es bei der Verarbeitung nat√ºrlicher Sprache eine Herausforderung, dass es viele verschiedene Formen eines Wortes gibt, diese aber die gleiche Bedeutung haben. Zum Beispiel sind \"running\", \"ran\" und \"runs\" alles Formen des Verbs \"run\". Um diese Herausforderung zu bew√§ltigen, verwenden wir Techniken wie **Lemmatisierung** und **Stemming**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "30918b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The          ‚Üí the\n",
      "striped      ‚Üí striped\n",
      "bats         ‚Üí bat\n",
      "were         ‚Üí be\n",
      "hanging      ‚Üí hang\n",
      "on           ‚Üí on\n",
      "their        ‚Üí their\n",
      "feet         ‚Üí foot\n",
      "and          ‚Üí and\n",
      "ate          ‚Üí eat\n",
      "best         ‚Üí good\n",
      "fishes       ‚Üí fish\n"
     ]
    }
   ],
   "source": [
    "# Beispieltext\n",
    "text = \"The striped bats were hanging on their feet and ate best fishes\"\n",
    "doc = nlp_en(text)\n",
    "\n",
    "# Lemmatization reduziert W√∂rter auf ihre Grundform (Lemma), unter Ber√ºcksichtigung von Wortart, Morphologie und Kontext.\n",
    "# Beispiel: \"ate\" ‚Üí \"eat\", \"feet\" ‚Üí \"foot\"\n",
    "for token in doc:\n",
    "    # Jedes token hat ein Attribut lemma_, das die Grundform des Wortes enth√§lt.\n",
    "    print(f\"{token.text:12} ‚Üí {token.lemma_}\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d2f216fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The          ‚Üí the\n",
      "striped      ‚Üí stripe\n",
      "bats         ‚Üí bat\n",
      "were         ‚Üí were\n",
      "hanging      ‚Üí hang\n",
      "on           ‚Üí on\n",
      "their        ‚Üí their\n",
      "feet         ‚Üí feet\n",
      "and          ‚Üí and\n",
      "ate          ‚Üí ate\n",
      "best         ‚Üí best\n",
      "fishes       ‚Üí fish\n"
     ]
    }
   ],
   "source": [
    "# NLTK bietet au√üerdem eine Schnittstelle f√ºr Stemming an. Wir verwenden den Porter Stemmer, einen der bekanntesten Stemmer (https://de.wikipedia.org/wiki/Porter-Stemmer-Algorithmus)\n",
    "# Stemming k√ºrzt W√∂rter auf einen Wortstamm durch heuristische Regeln.\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "for word in text.split():\n",
    "    print(f\"{word:12} ‚Üí {stemmer.stem(word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4957bd",
   "metadata": {},
   "source": [
    "### Beispiel 4: Regul√§re Ausdr√ºcke\n",
    "\n",
    "Regul√§re Ausdr√ºcke (RegEx) sind ein Werkzeug zur Textverarbeitung. Sie erm√∂glichen es uns, Muster in Texten zu erkennen und zu extrahieren. Hier sind einige Beispiele, wie wir RegEx in Python verwenden k√∂nnen, um spezifische Informationen aus einem Text zu extrahieren.\n",
    "\n",
    "Ich empfehle euch [RegExr.com](https://regexr.com/) zum Testen von regul√§ren Ausdr√ºcken. Au√üerdem wird dort ein guter √úberblick √ºber die RegEx-Syntax gegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "676e4f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speicher gefunden? True\n",
      "Gefundene Zahlen: ['45', '3', '100', '250', '1']\n",
      "Gefundene Speicherplatzangaben: ['GB', 'MB', 'MB', 'GB']\n",
      "Gefundene E-Mail-Adressen: ['mi@ur.de']\n",
      "G√ºltige E-Mail: mi@ur.de\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from email_validator import validate_email, EmailNotValidError\n",
    "\n",
    "text = \"Sie haben noch 45GB Speicher und Ihre E-Mail ist mi@ur.de und sie haben 3 Dateien mit 100MB, 250MB und 1GB.\"\n",
    "\n",
    "# Einfach: Wortsuche mit RegEx\n",
    "pattern_word = r\"\\bSpeicher\\b\"\n",
    "print(\"Speicher gefunden?\", bool(re.search(pattern_word, text)))\n",
    "\n",
    "# Zahlen extrahieren (RegEx)\n",
    "numbers = re.findall(r\"\\d+\", text)\n",
    "print(\"Gefundene Zahlen:\", numbers)\n",
    "\n",
    "# Angaben von Speicherplatz\n",
    "pattern_storage = r\"\\b\\d+\\s*(GB|MB|KB)\\b\"\n",
    "storage_matches = re.findall(pattern_storage, text)\n",
    "print(\"Gefundene Speicherplatzangaben:\", storage_matches)\n",
    "\n",
    "# E-Mail-Adresse mit RegEx validieren\n",
    "pattern_email = r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\"\n",
    "email_matches = re.findall(pattern_email, text)\n",
    "if email_matches:\n",
    "    print(\"Gefundene E-Mail-Adressen:\", email_matches)\n",
    "else:\n",
    "    print(\"Keine g√ºltige E-Mail-Adresse gefunden.\")\n",
    "\n",
    "# E-Mail-Adresse mit externer Library validieren\n",
    "try:\n",
    "    result = validate_email(\"mi@ur.de\")  # findet man z. B. aus dem Text\n",
    "    print(\"G√ºltige E-Mail:\", result.email)\n",
    "except EmailNotValidError as e:\n",
    "    print(\"Ung√ºltige E-Mail:\", e)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Erkl√§rung warum externe Packages sinnvoll sind:\n",
    "#\n",
    "# Komplexe Muster wie E-Mail-Adressen oder internationale Telefonnummern\n",
    "# lassen sich nur sehr schwer mit einfachen regul√§ren Ausdr√ºcken korrekt\n",
    "# und vollst√§ndig erfassen.\n",
    "#\n",
    "# Externe Libraries wie `email_validator` und `phonenumbers` sind\n",
    "# speziell darauf ausgelegt, Standards und viele Sonderf√§lle korrekt zu behandeln.\n",
    "# Sie validieren nicht nur das Format, sondern z.B. bei E-Mails auch die\n",
    "# Domain, bei Telefonnummern L√§ndercodes und Nummernl√§ngen.\n",
    "#\n",
    "# Das macht deinen Code robuster, wartbarer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c18332",
   "metadata": {},
   "source": [
    "### Beispiel 5: Embeddings und Vector Space Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8618b5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosinus-√Ñhnlichkeiten zwischen Wortpaaren:\n",
      "Dimensionen: (1, 96) (1, 96)\n",
      "'cat' vs. 'dog': 0.742\n",
      "Dimensionen: (1, 96) (1, 96)\n",
      "'car' vs. 'bike': 0.766\n",
      "Dimensionen: (1, 96) (1, 96)\n",
      "'cheesecake' vs. 'swimming': 0.299\n",
      "Dimensionen: (1, 96) (1, 96)\n",
      "'death' vs. 'google': 0.275\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import spacy\n",
    "\n",
    "# spaCy Modell laden (englisch, mit Vektoren)\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# W√∂rter f√ºr Vergleich\n",
    "word_pairs = [\n",
    "    (\"cat\", \"dog\"), # Beispiel mit √§hnlichen W√∂rtern\n",
    "    (\"car\", \"bike\"), # Beispiel mit √§hnlichen W√∂rtern\n",
    "    (\"cheesecake\", \"swimming\"), # Beispiel mit un√§hnlichen W√∂rtern\n",
    "    (\"death\", \"google\") # Beispiel mit un√§hnlichen W√∂rtern\n",
    "]\n",
    "\n",
    "print(\"Cosinus-√Ñhnlichkeiten zwischen Wortpaaren:\")\n",
    "\n",
    "for w1, w2 in word_pairs:\n",
    "    # 1. Wandeln wir die W√∂rter in Vektoren.\n",
    "    # Daf√ºr nutzen wir wieder das spaCy Modell und nutzen das Attribut .vector, das den Vektor/Embedding des Wortes zur√ºckgibt.\n",
    "    # 2. Da cosine_similarity 2D-Arrays erwartet, m√ºssen wir die Vektoren noch reshapen in 2D.\n",
    "    # cosine_similarity erwartet 2D-Arrays, da es prinzipiell auch f√ºr Matrizen-Vergleiche genutzt werden kann.\n",
    "    # .reshape(1, -1) sorgt daf√ºr, dass die Vektoren die Form (1, n) bekommen, also eine Zeile und n Spalten. -1 bedeutet, dass die Anzahl der Spalten automatisch bestimmt wird.\n",
    "    vec1 = nlp(w1).vector.reshape(1, -1)\n",
    "    vec2 = nlp(w2).vector.reshape(1, -1)\n",
    "    print(\"Dimensionen:\", vec1.shape, vec2.shape)\n",
    "    \n",
    "    # 3. Berechnen wir die Cosinus-√Ñhnlichkeit mit sklearns cosine_similarity Funktion.\n",
    "    # [0][0] am Ende extrahiert den Skalarwert aus dem 2D-Array, das zur√ºckgegeben wird.\n",
    "    cos_sim = cosine_similarity(vec1, vec2)[0][0]\n",
    "    print(f\"'{w1}' vs. '{w2}': {cos_sim:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d977ec",
   "metadata": {},
   "source": [
    "### üêº Einschub: Pandas Basics ‚Äì Arbeiten mit `sentiment_texts.csv`\n",
    "\n",
    "Da wir f√ºr die nachfolgenden Beispiele eine CSV-Datei mit Textdaten verwenden, hier ein kurzer Einschub zu `pandas`.\n",
    "Gerade, wenn man mit Textdaten arbeitet, sind Daten oft in Tabellenform gespeichert. Ein g√§ngiges Format ist CSV (Comma-Separated Values). In diesem Beispiel verwenden wir die Bibliothek `pandas`, um eine CSV-Datei zu laden und zu analysieren. \n",
    "\n",
    "Wir arbeiten mit der CSV-Datei `sentiment_texts.csv`, die Tweets umfasst und Annotationen f√ºr das Sentiment (positiv, negativ, neutral) enth√§lt. Es handelt sich um Tweets, bei denen Accounts von Politikern der 2021 im Bundestag vertretenen Parteien von Twitter-Nutzern erw√§hnt wurden mit einem `@`-Zeichen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1559e73d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source_account</th>\n",
       "      <th>source_party</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1459496838629839104</td>\n",
       "      <td>Beatrix_vStorch</td>\n",
       "      <td>AFD</td>\n",
       "      <td>@LisaLies12 @Beatrix_vStorch Ich habe NICHT be...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1366816957236977920</td>\n",
       "      <td>cducsubt</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@ChristianHirte @CDU @dieLinke @cducsubt Gewis...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1437742901186993920</td>\n",
       "      <td>_FriedrichMerz</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@PeterBofinger @_FriedrichMerz @handelsblatt @...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1352576248560706048</td>\n",
       "      <td>SWagenknecht</td>\n",
       "      <td>LINKE</td>\n",
       "      <td>@KunzlerManuel @DnielSchmlhofer @Stefan_Hajek ...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1439569370217340928</td>\n",
       "      <td>Alice_Weidel</td>\n",
       "      <td>AFD</td>\n",
       "      <td>@cem_oezdemir @ABaerbock Dachte erst Sie meine...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1868</th>\n",
       "      <td>1411004773126509056</td>\n",
       "      <td>CDU</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@Ruebenhorst @MenschgbMensch @CDU ist das Euer...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1869</th>\n",
       "      <td>1436672257682779904</td>\n",
       "      <td>Markus_Soeder</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@dcremer_ @Markus_Soeder @CSU Ohne g√∂ttliche I...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1870</th>\n",
       "      <td>1464183001588376064</td>\n",
       "      <td>Karl_Lauterbach</td>\n",
       "      <td>SPD</td>\n",
       "      <td>@Karl_Lauterbach das sieht schlecht aus. Da hi...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1871</th>\n",
       "      <td>1389635614975348992</td>\n",
       "      <td>CDU</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@MatthiasRieger3 @EskenSaskia @MEtzold @CDU ja...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1872</th>\n",
       "      <td>1400994841396456960</td>\n",
       "      <td>Markus_Soeder</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@GerdMll42564793 @Markus_Soeder Bestimmt</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1873 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id   source_account source_party  \\\n",
       "0     1459496838629839104  Beatrix_vStorch          AFD   \n",
       "1     1366816957236977920         cducsubt      CDU_CSU   \n",
       "2     1437742901186993920   _FriedrichMerz      CDU_CSU   \n",
       "3     1352576248560706048     SWagenknecht        LINKE   \n",
       "4     1439569370217340928     Alice_Weidel          AFD   \n",
       "...                   ...              ...          ...   \n",
       "1868  1411004773126509056              CDU      CDU_CSU   \n",
       "1869  1436672257682779904    Markus_Soeder      CDU_CSU   \n",
       "1870  1464183001588376064  Karl_Lauterbach          SPD   \n",
       "1871  1389635614975348992              CDU      CDU_CSU   \n",
       "1872  1400994841396456960    Markus_Soeder      CDU_CSU   \n",
       "\n",
       "                                                  tweet sentiment  \n",
       "0     @LisaLies12 @Beatrix_vStorch Ich habe NICHT be...  NEGATIVE  \n",
       "1     @ChristianHirte @CDU @dieLinke @cducsubt Gewis...   NEUTRAL  \n",
       "2     @PeterBofinger @_FriedrichMerz @handelsblatt @...   NEUTRAL  \n",
       "3     @KunzlerManuel @DnielSchmlhofer @Stefan_Hajek ...   NEUTRAL  \n",
       "4     @cem_oezdemir @ABaerbock Dachte erst Sie meine...   NEUTRAL  \n",
       "...                                                 ...       ...  \n",
       "1868  @Ruebenhorst @MenschgbMensch @CDU ist das Euer...  NEGATIVE  \n",
       "1869  @dcremer_ @Markus_Soeder @CSU Ohne g√∂ttliche I...   NEUTRAL  \n",
       "1870  @Karl_Lauterbach das sieht schlecht aus. Da hi...  NEGATIVE  \n",
       "1871  @MatthiasRieger3 @EskenSaskia @MEtzold @CDU ja...   NEUTRAL  \n",
       "1872           @GerdMll42564793 @Markus_Soeder Bestimmt   NEUTRAL  \n",
       "\n",
       "[1873 rows x 5 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importieren der Pandas-Bibliothek\n",
    "import pandas as pd\n",
    "\n",
    "# 1Ô∏è‚É£ CSV-Datei laden: Mit pd.read_csv() k√∂nnen wir Daten aus einer CSV-Datei in ein DataFrame laden.\n",
    "df = pd.read_csv(\"tweets.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0394612f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source_account</th>\n",
       "      <th>source_party</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1459496838629839104</td>\n",
       "      <td>Beatrix_vStorch</td>\n",
       "      <td>AFD</td>\n",
       "      <td>@LisaLies12 @Beatrix_vStorch Ich habe NICHT be...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1366816957236977920</td>\n",
       "      <td>cducsubt</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@ChristianHirte @CDU @dieLinke @cducsubt Gewis...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1437742901186993920</td>\n",
       "      <td>_FriedrichMerz</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@PeterBofinger @_FriedrichMerz @handelsblatt @...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1352576248560706048</td>\n",
       "      <td>SWagenknecht</td>\n",
       "      <td>LINKE</td>\n",
       "      <td>@KunzlerManuel @DnielSchmlhofer @Stefan_Hajek ...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1439569370217340928</td>\n",
       "      <td>Alice_Weidel</td>\n",
       "      <td>AFD</td>\n",
       "      <td>@cem_oezdemir @ABaerbock Dachte erst Sie meine...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id   source_account source_party  \\\n",
       "0  1459496838629839104  Beatrix_vStorch          AFD   \n",
       "1  1366816957236977920         cducsubt      CDU_CSU   \n",
       "2  1437742901186993920   _FriedrichMerz      CDU_CSU   \n",
       "3  1352576248560706048     SWagenknecht        LINKE   \n",
       "4  1439569370217340928     Alice_Weidel          AFD   \n",
       "\n",
       "                                               tweet sentiment  \n",
       "0  @LisaLies12 @Beatrix_vStorch Ich habe NICHT be...  NEGATIVE  \n",
       "1  @ChristianHirte @CDU @dieLinke @cducsubt Gewis...   NEUTRAL  \n",
       "2  @PeterBofinger @_FriedrichMerz @handelsblatt @...   NEUTRAL  \n",
       "3  @KunzlerManuel @DnielSchmlhofer @Stefan_Hajek ...   NEUTRAL  \n",
       "4  @cem_oezdemir @ABaerbock Dachte erst Sie meine...   NEUTRAL  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mit df.head() k√∂nnen wir die ersten 5 Zeilen des DataFrames bequem anzeigen.\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4fc567b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        AFD\n",
       "1    CDU_CSU\n",
       "2    CDU_CSU\n",
       "3      LINKE\n",
       "4        AFD\n",
       "5        FDP\n",
       "6        SPD\n",
       "7    CDU_CSU\n",
       "8        SPD\n",
       "9      LINKE\n",
       "Name: source_party, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wir k√∂nnen auch die Werte einer bestimmten Spalte ausw√§hlen, z.B. \"source_party\":\n",
    "df[\"source_party\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "abd0710a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source_account</th>\n",
       "      <th>source_party</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1347612879810425088</td>\n",
       "      <td>n_roettgen</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@n_roettgen auch mit Blick auf andere Aspekte ...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1471842111062429952</td>\n",
       "      <td>_FriedrichMerz</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@ToshimaDE @CDU @_FriedrichMerz Wie? Sitzt die...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1411032162929872896</td>\n",
       "      <td>ArminLaschet</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@steps0815 @Arndt_Klocke @MaAhl5 @Oliver_Krisc...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1382766358790868992</td>\n",
       "      <td>Karl_Lauterbach</td>\n",
       "      <td>SPD</td>\n",
       "      <td>@Karl_Lauterbach Ach na endlich!! Da kann ich ...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1346511916173304064</td>\n",
       "      <td>_FriedrichMerz</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@BorisNMoellers @_FriedrichMerz Ich √ºbrigens a...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1832</th>\n",
       "      <td>1473352625554963968</td>\n",
       "      <td>fdpbt</td>\n",
       "      <td>FDP</td>\n",
       "      <td>@Patrickweedmob @spdbt @GrueneBundestag @fdpbt...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841</th>\n",
       "      <td>1355126553882063104</td>\n",
       "      <td>Markus_Soeder</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@1xKlaudius @Markus_Soeder Mit Scheuer im Wahl...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1847</th>\n",
       "      <td>1411631133259973120</td>\n",
       "      <td>ArminLaschet</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@RadtkeMdEP 1.) Ein #guterplan #wegenmorgen w√§...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1850</th>\n",
       "      <td>1352647722801757952</td>\n",
       "      <td>ArminLaschet</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>#Herzlichen #Gl√ºckwunsch an alle #nun #offizie...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867</th>\n",
       "      <td>1408741244927365120</td>\n",
       "      <td>Alice_Weidel</td>\n",
       "      <td>AFD</td>\n",
       "      <td>@ASB_Anwohner @Alice_Weidel @Afd_emskirchen Bu...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id   source_account source_party  \\\n",
       "7     1347612879810425088       n_roettgen      CDU_CSU   \n",
       "10    1471842111062429952   _FriedrichMerz      CDU_CSU   \n",
       "25    1411032162929872896     ArminLaschet      CDU_CSU   \n",
       "34    1382766358790868992  Karl_Lauterbach          SPD   \n",
       "43    1346511916173304064   _FriedrichMerz      CDU_CSU   \n",
       "...                   ...              ...          ...   \n",
       "1832  1473352625554963968            fdpbt          FDP   \n",
       "1841  1355126553882063104    Markus_Soeder      CDU_CSU   \n",
       "1847  1411631133259973120     ArminLaschet      CDU_CSU   \n",
       "1850  1352647722801757952     ArminLaschet      CDU_CSU   \n",
       "1867  1408741244927365120     Alice_Weidel          AFD   \n",
       "\n",
       "                                                  tweet sentiment  \n",
       "7     @n_roettgen auch mit Blick auf andere Aspekte ...  POSITIVE  \n",
       "10    @ToshimaDE @CDU @_FriedrichMerz Wie? Sitzt die...  POSITIVE  \n",
       "25    @steps0815 @Arndt_Klocke @MaAhl5 @Oliver_Krisc...  POSITIVE  \n",
       "34    @Karl_Lauterbach Ach na endlich!! Da kann ich ...  POSITIVE  \n",
       "43    @BorisNMoellers @_FriedrichMerz Ich √ºbrigens a...  POSITIVE  \n",
       "...                                                 ...       ...  \n",
       "1832  @Patrickweedmob @spdbt @GrueneBundestag @fdpbt...  POSITIVE  \n",
       "1841  @1xKlaudius @Markus_Soeder Mit Scheuer im Wahl...  POSITIVE  \n",
       "1847  @RadtkeMdEP 1.) Ein #guterplan #wegenmorgen w√§...  POSITIVE  \n",
       "1850  #Herzlichen #Gl√ºckwunsch an alle #nun #offizie...  POSITIVE  \n",
       "1867  @ASB_Anwohner @Alice_Weidel @Afd_emskirchen Bu...  POSITIVE  \n",
       "\n",
       "[120 rows x 5 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Filterm√∂glichkeiten: Mit df[df[\"sentiment\"] == \"POSITIVE\"] k√∂nnen wir nur die Zeilen mit positivem Sentiment anzeigen. \n",
    "\n",
    "df[\"sentiment\"] w√§hlt die Spalte sentiment aus dem DataFrame df aus.\n",
    "Ergebnis: eine Series ‚Äì also eine eindimensionale, beschriftete Datenstruktur.\n",
    "'''\n",
    "df[df[\"sentiment\"] == \"POSITIVE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "022a2ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "NEGATIVE    976\n",
       "NEUTRAL     777\n",
       "POSITIVE    120\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mit .value_counts() k√∂nnen wir die H√§ufigkeit der einzigartigen Werte in der Spalte \"sentiment\" anzeigen.\n",
    "# Wir sehen beim Output, dass die Stimmung nicht ausgewogen ist: Es gibt deutlich mehr negative als positive Tweets, wobei fast so viele neutrale Tweets wie positive Tweets vorhanden sind.\n",
    "df[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fd2d8128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       @LISALIES12 @BEATRIX_VSTORCH ICH HABE NICHT BE...\n",
       "1       @CHRISTIANHIRTE @CDU @DIELINKE @CDUCSUBT GEWIS...\n",
       "2       @PETERBOFINGER @_FRIEDRICHMERZ @HANDELSBLATT @...\n",
       "3       @KUNZLERMANUEL @DNIELSCHMLHOFER @STEFAN_HAJEK ...\n",
       "4       @CEM_OEZDEMIR @ABAERBOCK DACHTE ERST SIE MEINE...\n",
       "                              ...                        \n",
       "1868    @RUEBENHORST @MENSCHGBMENSCH @CDU IST DAS EUER...\n",
       "1869    @DCREMER_ @MARKUS_SOEDER @CSU OHNE G√ñTTLICHE I...\n",
       "1870    @KARL_LAUTERBACH DAS SIEHT SCHLECHT AUS. DA HI...\n",
       "1871    @MATTHIASRIEGER3 @ESKENSASKIA @METZOLD @CDU JA...\n",
       "1872          @GERDMLL42564793 @MARKUS_SOEDER BESTIMMT!!!\n",
       "Name: shouted, Length: 1873, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mit .apply() k√∂nnen wir eine Funktion auf jede Zeile oder Spalte eines DataFrames anwenden.\n",
    "def shout(text):\n",
    "    return text.upper() + \"!!!\"\n",
    "\n",
    "df[\"shouted\"] = df[\"tweet\"].apply(shout)\n",
    "df[\"shouted\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "23bb03c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source_account</th>\n",
       "      <th>source_party</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>shouted</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>1389713588659625984</td>\n",
       "      <td>CDU</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>LG an @CDU und @CSU</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>LG AN @CDU UND @CSU!!!</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319</th>\n",
       "      <td>1377675573435191040</td>\n",
       "      <td>Die_Gruenen</td>\n",
       "      <td>GRUENE</td>\n",
       "      <td>@Die_Gruenen so schwarz.</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>@DIE_GRUENEN SO SCHWARZ.!!!</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1432400536498810880</td>\n",
       "      <td>CDU</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@CDU Was f√ºr ein Unsinn.</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>@CDU WAS F√úR EIN UNSINN.!!!</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>1424771876837024000</td>\n",
       "      <td>Die_Gruenen</td>\n",
       "      <td>GRUENE</td>\n",
       "      <td>@Die_Gruenen Zeit wirds!</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>@DIE_GRUENEN ZEIT WIRDS!!!!</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1409483299207122944</td>\n",
       "      <td>Karl_Lauterbach</td>\n",
       "      <td>SPD</td>\n",
       "      <td>@Karl_Lauterbach Ab wann?</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>@KARL_LAUTERBACH AB WANN?!!!</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>1389137005326618880</td>\n",
       "      <td>SWagenknecht</td>\n",
       "      <td>LINKE</td>\n",
       "      <td>@StimmederVernu9 @DerEchteGrubert @AlfredNeuma...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>@STIMMEDERVERNU9 @DERECHTEGRUBERT @ALFREDNEUMA...</td>\n",
       "      <td>523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>1399462761541911040</td>\n",
       "      <td>c_lindner</td>\n",
       "      <td>FDP</td>\n",
       "      <td>@chris_pyak @holgerkopp @HLiepelt @MartinWalth...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>@CHRIS_PYAK @HOLGERKOPP @HLIEPELT @MARTINWALTH...</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>1442227712869940992</td>\n",
       "      <td>cem_oezdemir</td>\n",
       "      <td>GRUENE</td>\n",
       "      <td>@GGahnt @CartmanTB2 @Andrew1023054 @NurZoabe @...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>@GGAHNT @CARTMANTB2 @ANDREW1023054 @NURZOABE @...</td>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>1345808822544326912</td>\n",
       "      <td>CDU</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@cat_spass @Abtreibpranger @Peacecakex @nelson...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>@CAT_SPASS @ABTREIBPRANGER @PEACECAKEX @NELSON...</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>1376307200797344000</td>\n",
       "      <td>hubertus_heil</td>\n",
       "      <td>SPD</td>\n",
       "      <td>@Detlef66138495 @BVG_Kampagne @goethe_jw @4tti...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>@DETLEF66138495 @BVG_KAMPAGNE @GOETHE_JW @4TTI...</td>\n",
       "      <td>746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1873 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id   source_account source_party  \\\n",
       "1724  1389713588659625984              CDU      CDU_CSU   \n",
       "1319  1377675573435191040      Die_Gruenen       GRUENE   \n",
       "32    1432400536498810880              CDU      CDU_CSU   \n",
       "351   1424771876837024000      Die_Gruenen       GRUENE   \n",
       "189   1409483299207122944  Karl_Lauterbach          SPD   \n",
       "...                   ...              ...          ...   \n",
       "575   1389137005326618880     SWagenknecht        LINKE   \n",
       "1657  1399462761541911040        c_lindner          FDP   \n",
       "635   1442227712869940992     cem_oezdemir       GRUENE   \n",
       "804   1345808822544326912              CDU      CDU_CSU   \n",
       "1361  1376307200797344000    hubertus_heil          SPD   \n",
       "\n",
       "                                                  tweet sentiment  \\\n",
       "1724                                LG an @CDU und @CSU  POSITIVE   \n",
       "1319                           @Die_Gruenen so schwarz.   NEUTRAL   \n",
       "32                             @CDU Was f√ºr ein Unsinn.  NEGATIVE   \n",
       "351                            @Die_Gruenen Zeit wirds!   NEUTRAL   \n",
       "189                           @Karl_Lauterbach Ab wann?   NEUTRAL   \n",
       "...                                                 ...       ...   \n",
       "575   @StimmederVernu9 @DerEchteGrubert @AlfredNeuma...  NEGATIVE   \n",
       "1657  @chris_pyak @holgerkopp @HLiepelt @MartinWalth...  NEGATIVE   \n",
       "635   @GGahnt @CartmanTB2 @Andrew1023054 @NurZoabe @...  NEGATIVE   \n",
       "804   @cat_spass @Abtreibpranger @Peacecakex @nelson...   NEUTRAL   \n",
       "1361  @Detlef66138495 @BVG_Kampagne @goethe_jw @4tti...   NEUTRAL   \n",
       "\n",
       "                                                shouted  text_length  \n",
       "1724                             LG AN @CDU UND @CSU!!!           19  \n",
       "1319                        @DIE_GRUENEN SO SCHWARZ.!!!           24  \n",
       "32                          @CDU WAS F√úR EIN UNSINN.!!!           24  \n",
       "351                         @DIE_GRUENEN ZEIT WIRDS!!!!           24  \n",
       "189                        @KARL_LAUTERBACH AB WANN?!!!           25  \n",
       "...                                                 ...          ...  \n",
       "575   @STIMMEDERVERNU9 @DERECHTEGRUBERT @ALFREDNEUMA...          523  \n",
       "1657  @CHRIS_PYAK @HOLGERKOPP @HLIEPELT @MARTINWALTH...          566  \n",
       "635   @GGAHNT @CARTMANTB2 @ANDREW1023054 @NURZOABE @...          570  \n",
       "804   @CAT_SPASS @ABTREIBPRANGER @PEACECAKEX @NELSON...          655  \n",
       "1361  @DETLEF66138495 @BVG_KAMPAGNE @GOETHE_JW @4TTI...          746  \n",
       "\n",
       "[1873 rows x 7 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mit .sort_values() k√∂nnen wir den DataFrame nach einer bestimmten Spalte sortieren.\n",
    "def text_length(text):\n",
    "    return len(text)\n",
    "\n",
    "df[\"text_length\"] = df[\"tweet\"].apply(text_length)\n",
    "df = df.sort_values(by=\"text_length\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c74524fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "NEGATIVE    26.861680\n",
       "NEUTRAL     19.772201\n",
       "POSITIVE    19.016667\n",
       "Name: word_count, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mit .mean() k√∂nnen wir den Durchschnitt einer Spalte berechnen.\n",
    "def word_count(text):\n",
    "    return len(text.split())\n",
    "\n",
    "df[\"word_count\"] = df[\"tweet\"].apply(word_count)\n",
    "\n",
    "# Mit .groupby() k√∂nnen wir den DataFrame nach einer bestimmten Spalte gruppieren.\n",
    "# df.groupby(\"sentiment\")[\"word_count\"] gibt uns eine SeriesGroupBy-Objekt zur√ºck, das die Wortanzahl f√ºr jede Sentiment-Kategorie gruppiert.\n",
    "# Mit .mean() berechnen wir den Durchschnitt der Wortanzahl f√ºr jede Sentiment-Kategorie.\n",
    "df.groupby(\"sentiment\")[\"word_count\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b0c508ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source_account</th>\n",
       "      <th>source_party</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>shouted</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>1464916983108062976</td>\n",
       "      <td>MiKellner</td>\n",
       "      <td>GRUENE</td>\n",
       "      <td>@MonikaHerrmann1 @MiKellner @ABaerbock Wieder ...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>@MONIKAHERRMANN1 @MIKELLNER @ABAERBOCK WIEDER ...</td>\n",
       "      <td>61</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>1363624003278151936</td>\n",
       "      <td>PaulZiemiak</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@PaulZiemiak @BerlinReporter Keine Aufregung. ...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>@PAULZIEMIAK @BERLINREPORTER KEINE AUFREGUNG. ...</td>\n",
       "      <td>98</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1781</th>\n",
       "      <td>1362817043549069056</td>\n",
       "      <td>CDU</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@GirkeHanjo @BerlinReporter @MIT_bund @christo...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>@GIRKEHANJO @BERLINREPORTER @MIT_BUND @CHRISTO...</td>\n",
       "      <td>107</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id source_account source_party  \\\n",
       "872   1464916983108062976      MiKellner       GRUENE   \n",
       "1725  1363624003278151936    PaulZiemiak      CDU_CSU   \n",
       "1781  1362817043549069056            CDU      CDU_CSU   \n",
       "\n",
       "                                                  tweet sentiment  \\\n",
       "872   @MonikaHerrmann1 @MiKellner @ABaerbock Wieder ...   NEUTRAL   \n",
       "1725  @PaulZiemiak @BerlinReporter Keine Aufregung. ...  NEGATIVE   \n",
       "1781  @GirkeHanjo @BerlinReporter @MIT_bund @christo...  POSITIVE   \n",
       "\n",
       "                                                shouted  text_length  \\\n",
       "872   @MONIKAHERRMANN1 @MIKELLNER @ABAERBOCK WIEDER ...           61   \n",
       "1725  @PAULZIEMIAK @BERLINREPORTER KEINE AUFREGUNG. ...           98   \n",
       "1781  @GIRKEHANJO @BERLINREPORTER @MIT_BUND @CHRISTO...          107   \n",
       "\n",
       "      word_count  \n",
       "872            7  \n",
       "1725          10  \n",
       "1781          13  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def has_berlin(text):\n",
    "    return \"Berlin\" in text\n",
    "\n",
    "# Zeilen filtern\n",
    "df_berlin = df[df[\"tweet\"].apply(has_berlin)]\n",
    "df_berlin.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2394153b",
   "metadata": {},
   "source": [
    "### üî¢ Einschub: NumPy Basics ‚Äì Arbeiten mit Arrays\n",
    "\n",
    "NumPy (Numerical Python) ist die grundlegende Bibliothek f√ºr wissenschaftliches Rechnen in Python. Es bietet ein m√§chtiges N-dimensionales Array-Objekt und Funktionen f√ºr deren Bearbeitung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f2006801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy Array: [1 2 3 4 5]\n",
      "Typ: <class 'numpy.ndarray'>\n",
      "Shape (Form): (5,)\n",
      "Data Type: int64\n"
     ]
    }
   ],
   "source": [
    "# Importieren der NumPy-Bibliothek\n",
    "import numpy as np\n",
    "\n",
    "# 1Ô∏è‚É£ Arrays erstellen: Mit np.array() k√∂nnen wir Listen in NumPy Arrays umwandeln.\n",
    "numbers = [1, 2, 3, 4, 5]\n",
    "arr = np.array(numbers)\n",
    "print(\"NumPy Array:\", arr)\n",
    "print(\"Typ:\", type(arr))\n",
    "print(\"Shape (Form):\", arr.shape)\n",
    "print(\"Data Type:\", arr.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2ac6faee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D Array:\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "Shape: (3, 3)\n",
      "\n",
      "Zeros Array:\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "\n",
      "Ones Array:\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# 2Ô∏è‚É£ Zweidimensionale Arrays: Mit np.array() k√∂nnen wir auch 2D-Arrays (Matrizen) erstellen.\n",
    "matrix = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(\"2D Array:\")\n",
    "print(matrix)\n",
    "print(\"Shape:\", matrix.shape)  # (3, 3) bedeutet 3 Zeilen, 3 Spalten\n",
    "\n",
    "# Arrays mit bestimmten Werten erstellen\n",
    "zeros = np.zeros((2, 3))  # 2x3 Array mit Nullen\n",
    "ones = np.ones((2, 3))    # 2x3 Array mit Einsen\n",
    "print(\"\\nZeros Array:\")\n",
    "print(zeros)\n",
    "print(\"\\nOnes Array:\")\n",
    "print(ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d3e17e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Array: [10 20 30 40 50]\n",
      "Erstes Element: 10\n",
      "Letztes Element: 50\n",
      "Slice [1:4]: [20 30 40]\n",
      "\n",
      "2D Array:\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "Element [0,0]: 1\n",
      "Element [1,2]: 6\n",
      "Erste Zeile: [1 2 3]\n",
      "Erste Spalte: [1 4 7]\n"
     ]
    }
   ],
   "source": [
    "# 3Ô∏è‚É£ Array-Indexierung und Slicing: √Ñhnlich wie bei Python-Listen\n",
    "arr = np.array([10, 20, 30, 40, 50])\n",
    "print(\"Original Array:\", arr)\n",
    "print(\"Erstes Element:\", arr[0])      # Index 0\n",
    "print(\"Letztes Element:\", arr[-1])    # Index -1\n",
    "print(\"Slice [1:4]:\", arr[1:4])       # Elemente von Index 1 bis 3\n",
    "\n",
    "# 2D Array Indexierung\n",
    "matrix = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(\"\\n2D Array:\")\n",
    "print(matrix)\n",
    "print(\"Element [0,0]:\", matrix[0, 0])  # Erste Zeile, erste Spalte\n",
    "print(\"Element [1,2]:\", matrix[1, 2])  # Zweite Zeile, dritte Spalte\n",
    "print(\"Erste Zeile:\", matrix[0, :])    # Ganze erste Zeile\n",
    "print(\"Erste Spalte:\", matrix[:, 0])   # Ganze erste Spalte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "534bf291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array 1: [1 2 3 4]\n",
      "Array 2: [10 20 30 40]\n",
      "Addition: [11 22 33 44]\n",
      "Subtraktion: [ -9 -18 -27 -36]\n",
      "Multiplikation: [ 10  40  90 160]\n",
      "Division: [10. 10. 10. 10.]\n",
      "\n",
      "Array * 2: [2 4 6 8]\n",
      "Array + 10: [11 12 13 14]\n"
     ]
    }
   ],
   "source": [
    "# 4Ô∏è‚É£ Mathematische Operationen: NumPy macht Berechnungen sehr effizient\n",
    "arr1 = np.array([1, 2, 3, 4])\n",
    "arr2 = np.array([10, 20, 30, 40])\n",
    "\n",
    "print(\"Array 1:\", arr1)\n",
    "print(\"Array 2:\", arr2)\n",
    "\n",
    "# Element-weise Operationen\n",
    "print(\"Addition:\", arr1 + arr2)\n",
    "print(\"Subtraktion:\", arr1 - arr2)\n",
    "print(\"Multiplikation:\", arr1 * arr2)\n",
    "print(\"Division:\", arr2 / arr1)\n",
    "\n",
    "# Operationen mit Skalaren\n",
    "print(\"\\nArray * 2:\", arr1 * 2)\n",
    "print(\"Array + 10:\", arr1 + 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0c0db0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: [1 5 2 8 3 7 4 6]\n",
      "Summe: 36\n",
      "Mittelwert: 4.5\n",
      "Median: 4.5\n",
      "Standardabweichung: 2.29128784747792\n",
      "Minimum: 1\n",
      "Maximum: 8\n",
      "Index des Minimums: 0\n",
      "Index des Maximums: 3\n",
      "Sortiert: [1 2 3 4 5 6 7 8]\n"
     ]
    }
   ],
   "source": [
    "# 5Ô∏è‚É£ N√ºtzliche NumPy-Funktionen f√ºr statistische Berechnungen\n",
    "data = np.array([1, 5, 2, 8, 3, 7, 4, 6])\n",
    "print(\"Data:\", data)\n",
    "\n",
    "print(\"Summe:\", np.sum(data))\n",
    "print(\"Mittelwert:\", np.mean(data))\n",
    "print(\"Median:\", np.median(data))\n",
    "print(\"Standardabweichung:\", np.std(data))\n",
    "print(\"Minimum:\", np.min(data))\n",
    "print(\"Maximum:\", np.max(data))\n",
    "\n",
    "# Index des Minimums/Maximums\n",
    "print(\"Index des Minimums:\", np.argmin(data))\n",
    "print(\"Index des Maximums:\", np.argmax(data))\n",
    "\n",
    "# Array sortieren\n",
    "print(\"Sortiert:\", np.sort(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "78db9189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Array: [1 2 3 4 5 6]\n",
      "Shape: (6,)\n",
      "\n",
      "Reshape zu 2x3:\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "Shape: (2, 3)\n",
      "\n",
      "Reshape zu 3x2:\n",
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n",
      "\n",
      "Auto-Reshape (-1, 2):\n",
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n",
      "Shape: (3, 2)\n"
     ]
    }
   ],
   "source": [
    "# 6Ô∏è‚É£ Array-Reshaping: Die Form von Arrays √§ndern\n",
    "arr = np.array([1, 2, 3, 4, 5, 6])\n",
    "print(\"Original Array:\", arr)\n",
    "print(\"Shape:\", arr.shape)\n",
    "\n",
    "# Zu 2x3 Matrix umformen\n",
    "reshaped = arr.reshape(2, 3)\n",
    "print(\"\\nReshape zu 2x3:\")\n",
    "print(reshaped)\n",
    "print(\"Shape:\", reshaped.shape)\n",
    "\n",
    "# Zu 3x2 Matrix umformen\n",
    "reshaped2 = arr.reshape(3, 2)\n",
    "print(\"\\nReshape zu 3x2:\")\n",
    "print(reshaped2)\n",
    "\n",
    "# Automatische Dimensionsbestimmung mit -1\n",
    "auto_reshape = arr.reshape(-1, 2)  # -1 bedeutet: bestimme automatisch\n",
    "print(\"\\nAuto-Reshape (-1, 2):\")\n",
    "print(auto_reshape)\n",
    "print(\"Shape:\", auto_reshape.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29931ef",
   "metadata": {},
   "source": [
    "## üë©üèº‚Äçüíª Aufgaben "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "92b7df56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Aufgabe: Gebe f√ºr die ersten 3 Tweets die Tokens als List mit print() aus.\n",
    "\n",
    "# Hier Code einf√ºgen...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c027790",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>L√∂sung anzeigen</b></summary>\n",
    "\n",
    "```python\n",
    "for tweet in df[\"tweet\"].head(3):\n",
    "    tokens = tweet.split(\" \")\n",
    "    print(tokens)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f20450ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Aufgabe: Geben sie f√ºr die ersten 3 Tweets die POS-Tags als List mit print() aus.\n",
    "# Beispiel: \"Ich habe Lust auf Pizza.\" -> [(\"Ich\", \"PRON\"), (\"habe\", \"VERB\"), (\"Lust\", \"NOUN\"), (\"auf\", \"ADP\"), (\"Pizza\", \"NOUN\")]\n",
    "import spacy\n",
    "nlp = spacy.load(\"de_core_news_sm\")  # Deutsches Modell laden\n",
    "\n",
    "# Hier Code einf√ºgen...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4599355a",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>L√∂sung anzeigen</b></summary>\n",
    "\n",
    "```python\n",
    "for tweet in df[\"tweet\"].head(3):\n",
    "    doc = nlp(tweet)\n",
    "    pos_tags = [(token.text, token.pos_) for token in doc]\n",
    "    print(pos_tags)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e4a29c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Aufgabe: Geben sie f√ºr die ersten 3 Tweets die Lemmas als List mit print() aus.\n",
    "# Beispiel: \"Ich habe Lust auf Pizza.\" -> [(\"Ich\", \"ich\"), (\"habe\", \"haben\"), (\"Lust\", \"Lust\"), (\"auf\", \"auf\"), (\"Pizza\", \"Pizza\")]\n",
    "\n",
    "# Hier Code einf√ºgen...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9fd4a4",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>L√∂sung anzeigen</b></summary>\n",
    "\n",
    "```python\n",
    "for tweet in df[\"tweet\"].head(3):\n",
    "    doc = nlp(tweet)\n",
    "    lemmas = [(token.text, token.lemma_) for token in doc]\n",
    "    print(lemmas)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3cce81dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# 4.1 Aufgabe: Erstellen sie einen regul√§ren Ausdruck, der alle Hashtags in einem Tweet findet. Nutzen Sie gerne ein Cheatsheet: https://web.mit.edu/hackl/www/lab/turkshop/slides/regex-cheatsheet.pdf\n",
    "text = \"Loving the new features in #Python3! #programming #NLP is fun. Visit us at https://example.com #AI\"\n",
    "\n",
    "# Ihre L√∂sung hier..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e71a8d6",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>L√∂sung anzeigen</b></summary>\n",
    "\n",
    "```python\n",
    "pattern_hashtag = r\"#\\w+\"\n",
    "hashtags = re.findall(pattern_hashtag, text)\n",
    "print(\"Gefundene Hashtags:\", hashtags)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "99b8a073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 Aufgabe: Der Vorname Maier. Erstellen sie einen regul√§ren Ausdruck, der alle m√∂glichen Schreibweisen des Vornamens \"Maier\" findet, z.B. \"Maier\", \"Meyer\", \"Meier\", \"Mayer\", \"Mayr\".\n",
    "text = \"Meyer, Maier, Meier, Mair, Meir, Mayr, Meyr\"\n",
    "\n",
    "# Ihre L√∂sung hier..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0a7261",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>L√∂sung anzeigen</b></summary>\n",
    "\n",
    "```python\n",
    "pattern_maier_variants = r\"\\bM[ae][iy]?[ae]?[iy]?r\\b\"\n",
    "maier_variants = re.findall(pattern_maier_variants, text)\n",
    "print(\"Gefundene Varianten von 'Maier':\", maier_variants)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "308dc4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 Wie lassen sich Datumsangaben in einem regul√§ren Ausdruck zusammenfassen?\n",
    "text = \"1. Januar 1901 29. Februar 2099, 02. M√§rz 1234, 1. Oktober 2015\"\n",
    "\n",
    "# Ihre L√∂sung hier..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643ae4e7",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>L√∂sung anzeigen</b></summary>\n",
    "\n",
    "```python\n",
    "pattern_dates = r\"\\b\\d{1,2}\\. (?:Januar|Februar|M√§rz|April|Mai|Juni|Juli|August|September|Oktober|November|Dezember) \\d{4}\\b\"\n",
    "dates = re.findall(pattern_dates, text)\n",
    "print(\"Gefundene Datumsangaben:\", dates)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_nils_hellwig",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
