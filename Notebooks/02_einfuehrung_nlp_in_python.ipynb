{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "336666e5",
   "metadata": {},
   "source": [
    "# Einführung in NLP für Python\n",
    "\n",
    "Dieses Notebook behandelt grundlegende Konzepte des NLP (Natural Language Processing) wie Tokenisierung, Stemming und Lemmatisierung. Diese Techniken sind entscheidend für die Verarbeitung natürlicher Sprache.\n",
    "\n",
    "Quelle: https://web.stanford.edu/~jurafsky/slp3/ed3book.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "aabe9761",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "# Für dieses Projekt müssen wir zunächst die folgenden Pakete installieren:\n",
    "!pip install spacy\n",
    "!pip install nltk\n",
    "!python -m spacy download de_core_news_sm\n",
    "!python -m spacy download en_core_web_sm\n",
    "!pip install email-validator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1d5aff",
   "metadata": {},
   "source": [
    "## Beispiele\n",
    "\n",
    "### Beispiel 1: Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7191ca",
   "metadata": {},
   "source": [
    "Wir haben bereits im Python-Notebook gelernt, wie wir Texte splitten können. Wiederholen wir das kurz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e45b54d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split nach Leerzeichen: ['Hallo', 'Welt!', 'Python', 'ist', 'eine', 'ziemlich', 'coole', 'Programmiersprache.', 'Ich', 'hoffe,', 'Sie', 'mögen', 'sie', 'auch!']\n"
     ]
    }
   ],
   "source": [
    "text = \"Hallo Welt! Python ist eine ziemlich coole Programmiersprache. Ich hoffe, Sie mögen sie auch!\"\n",
    "tokens_spaces = text.split()\n",
    "print(\"Split nach Leerzeichen:\", tokens_spaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acba1bab",
   "metadata": {},
   "source": [
    "Wie wir in der Ausgabe sehen, trennt die einfache `split()`-Methode Wörter, aber sie behandelt Satzzeichen nicht korrekt. Zum Beispiel wird \"Welt!\" als ein Token betrachtet, was in vielen NLP-Anwendungen nicht ideal ist. Daher verwenden wir spezialisierte **Tokenizer**, um dieses Problem zu lösen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "35e439d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/nils_hellwig/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wir laden NLTK, eine Bibliothek für natürliche Sprachverarbeitung\n",
    "import nltk\n",
    "\n",
    "# Punkt-Tokenizer herunterladen, ein Package, dass wir für die Tokenisierung benötigen. Punkt enthält Regeln für die Tokenisierung von Wörtern und Sätzen.\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a42c3807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK Word Tokenize: ['Hallo', 'Welt', '!', 'Python', 'ist', 'eine', 'ziemlich', 'coole', 'Programmiersprache', '.', 'Ich', 'hoffe', ',', 'Sie', 'mögen', 'sie', 'auch', '!']\n"
     ]
    }
   ],
   "source": [
    "# Um die Tokenisierung durchzuführen, importieren wir die word_tokenize-Funktion aus dem nltk.tokenize Modul.\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Wir verwenden die word_tokenize-Funktion, um den Text in Wörter zu zerlegen.\n",
    "tokens_nltk = word_tokenize(text)\n",
    "\n",
    "# Ausgabe der tokenisierten Wörter\n",
    "print(\"NLTK Word Tokenize:\", tokens_nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2694fc52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Satz-Tokenisierung: ['Hallo Welt!', 'Dies ist ein Test.', 'Hier ist noch ein Satz.']\n"
     ]
    }
   ],
   "source": [
    "# NLTK bietet auch eine Funktion zur Satz-Tokenisierung an.\n",
    "sentences = nltk.sent_tokenize(\"Hallo Welt! Dies ist ein Test. Hier ist noch ein Satz.\")\n",
    "print(\"Satz-Tokenisierung:\", sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8ddc36",
   "metadata": {},
   "source": [
    "### Beispiel 2: Part-of-Speech (POS) Tagging\n",
    "\n",
    "POS-Tagging ermöglicht es uns, die grammatikalische Rolle jedes Wortes in einem Satz zu identifizieren. Wir verwenden die `nltk`-Bibliothek, um dies zu demonstrieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e1a780c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK POS-Tagging (Englisch):\n",
      "[('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN'), ('.', '.')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /Users/nils_hellwig/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Definieren wir zunächst zwei Beispieltexte, einen auf Englisch und einen auf Deutsch.\n",
    "text_en = \"The quick brown fox jumps over the lazy dog.\"\n",
    "text_de = \"Der schnelle braune Fuchs springt über den faulen Hund.\"\n",
    "\n",
    "# NLTK-Modelle herunterladen. averaged_perceptron_tagger ist ein vortrainiertes Modell für POS-Tagging.\n",
    "nltk.download(\"averaged_perceptron_tagger_eng\")\n",
    "\n",
    "# Tokenisieren und POS-Tagging (Englisch)\n",
    "tokens_en = nltk.word_tokenize(text_en)\n",
    "pos_tags_en = nltk.pos_tag(tokens_en)\n",
    "print(\"NLTK POS-Tagging (Englisch):\")\n",
    "print(pos_tags_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "77fb683d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "spaCy POS-Tagging (Englisch):\n",
      "The        DET        DT        \n",
      "quick      ADJ        JJ        \n",
      "brown      ADJ        JJ        \n",
      "fox        NOUN       NN        \n",
      "jumps      VERB       VBZ       \n",
      "over       ADP        IN        \n",
      "the        DET        DT        \n",
      "lazy       ADJ        JJ        \n",
      "dog        NOUN       NN        \n",
      ".          PUNCT      .         \n",
      "\n",
      "spaCy POS-Tagging (Deutsch):\n",
      "Der        DET        ART       \n",
      "schnelle   ADJ        ADJA      \n",
      "braune     ADJ        ADJA      \n",
      "Fuchs      NOUN       NN        \n",
      "springt    VERB       VVFIN     \n",
      "über       ADP        APPR      \n",
      "den        DET        ART       \n",
      "faulen     ADJ        ADJA      \n",
      "Hund       NOUN       NN        \n",
      ".          PUNCT      $.        \n",
      "\n",
      "spaCy POS-Tagging (Deutsch):\n",
      "Der        DET        ART       \n",
      "schnelle   ADJ        ADJA      \n",
      "braune     ADJ        ADJA      \n",
      "Fuchs      NOUN       NN        \n",
      "springt    VERB       VVFIN     \n",
      "über       ADP        APPR      \n",
      "den        DET        ART       \n",
      "faulen     ADJ        ADJA      \n",
      "Hund       NOUN       NN        \n",
      ".          PUNCT      $.        \n"
     ]
    }
   ],
   "source": [
    "# Auch mit spaCy können wir POS-Tagging durchführen. SpaCy (https://spacy.io/) ist eine sehr beliebte Bibliothek für NLP in Python, \n",
    "# da sie viele Tools und vortrainierte Modelle bietet für verschiedenste Anwendungen.\n",
    "import spacy\n",
    "\n",
    "# Laden wir zunächst die vortrainierten Modelle für Englisch.\n",
    "nlp_en = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Mit nlp_en können wir den Text in eine Liste von Tokens umwandeln.\n",
    "doc_en = nlp_en(text_en)\n",
    "\n",
    "# Tokens besitzen verschiedene Attribute, z.B. den Text und die Wortart (POS).\n",
    "print(\"\\nspaCy POS-Tagging (Englisch):\")\n",
    "for token in doc_en:\n",
    "    print(f\"{token.text:10} {token.pos_:10} {token.tag_:10}\") # :10 sorgt für eine feste Breite von 10 Zeichen\n",
    "\n",
    "# Deutsches Modell\n",
    "nlp_de = spacy.load(\"de_core_news_sm\")\n",
    "doc_de = nlp_de(text_de)\n",
    "print(\"\\nspaCy POS-Tagging (Deutsch):\")\n",
    "for token in doc_de:\n",
    "    print(f\"{token.text:10} {token.pos_:10} {token.tag_:10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb21251",
   "metadata": {},
   "source": [
    "### Beispiel 3: Lemmatization und Stemming\n",
    "\n",
    "Wie in der Vorlesung besprochen, ist es bei der Verarbeitung natürlicher Sprache eine Herausforderung, dass es viele verschiedene Formen eines Wortes gibt, diese aber die gleiche Bedeutung haben. Zum Beispiel sind \"running\", \"ran\" und \"runs\" alles Formen des Verbs \"run\". Um diese Herausforderung zu bewältigen, verwenden wir Techniken wie **Lemmatisierung** und **Stemming**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "30918b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The          → The\n",
      "striped      → Striped\n",
      "bats         → Bat\n",
      "were         → were\n",
      "hanging      → hanging\n",
      "on           → --\n",
      "their        → their\n",
      "feet         → feet\n",
      "and          → And\n",
      "ate          → ate\n",
      "best         → Best\n",
      "fishes       → fish\n"
     ]
    }
   ],
   "source": [
    "# Beispieltext\n",
    "text = \"The striped bats were hanging on their feet and ate best fishes\"\n",
    "doc = nlp(text)\n",
    "\n",
    "# Lemmatization reduziert Wörter auf ihre Grundform (Lemma), unter Berücksichtigung von Wortart, Morphologie und Kontext.\n",
    "# Beispiel: \"ate\" → \"eat\", \"feet\" → \"foot\"\n",
    "for token in doc:\n",
    "    # Jedes token hat ein Attribut lemma_, das die Grundform des Wortes enthält.\n",
    "    print(f\"{token.text:12} → {token.lemma_}\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d2f216fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The          → the\n",
      "striped      → stripe\n",
      "bats         → bat\n",
      "were         → were\n",
      "hanging      → hang\n",
      "on           → on\n",
      "their        → their\n",
      "feet         → feet\n",
      "and          → and\n",
      "ate          → ate\n",
      "best         → best\n",
      "fishes       → fish\n"
     ]
    }
   ],
   "source": [
    "# NLTK bietet eine Schnittstelle für Stemming an. Wir verwenden den Porter Stemmer, einen der bekanntesten Stemmer (https://de.wikipedia.org/wiki/Porter-Stemmer-Algorithmus)\n",
    "# Stemming kürzt Wörter auf einen Wortstamm durch heuristische Regeln.\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "for word in text.split():\n",
    "    print(f\"{word:12} → {stemmer.stem(word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4957bd",
   "metadata": {},
   "source": [
    "### Beispiel 4: Reguläre Ausdrücke\n",
    "\n",
    "Reguläre Ausdrücke (RegEx) sind ein Werkzeug zur Textverarbeitung. Sie ermöglichen es uns, Muster in Texten zu erkennen und zu extrahieren. Hier sind einige Beispiele, wie wir RegEx in Python verwenden können, um spezifische Informationen aus einem Text zu extrahieren.\n",
    "\n",
    "Ich empfehle euch [RegExr.com](https://regexr.com/) zum Testen von regulären Ausdrücken. Außerdem wird dort ein guter Überblick über die RegEx-Syntax gegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "676e4f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speicher gefunden? True\n",
      "Gefundene Zahlen: ['45', '3', '100', '250', '1']\n",
      "Gefundene Speicherplatzangaben: ['GB', 'MB', 'MB', 'GB']\n",
      "Gefundene E-Mail-Adressen: ['mi@ur.de']\n",
      "Gültige E-Mail: mi@ur.de\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from email_validator import validate_email, EmailNotValidError\n",
    "\n",
    "text = \"Sie haben noch 45GB Speicher und Ihre E-Mail ist mi@ur.de und sie haben 3 Dateien mit 100MB, 250MB und 1GB.\"\n",
    "\n",
    "# Einfach: Wortsuche mit RegEx\n",
    "pattern_word = r\"\\bSpeicher\\b\"\n",
    "print(\"Speicher gefunden?\", bool(re.search(pattern_word, text)))\n",
    "\n",
    "# Zahlen extrahieren (RegEx)\n",
    "numbers = re.findall(r\"\\d+\", text)\n",
    "print(\"Gefundene Zahlen:\", numbers)\n",
    "\n",
    "# Angaben von Speicherplatz\n",
    "pattern_storage = r\"\\b\\d+\\s*(GB|MB|KB)\\b\"\n",
    "storage_matches = re.findall(pattern_storage, text)\n",
    "print(\"Gefundene Speicherplatzangaben:\", storage_matches)\n",
    "\n",
    "# E-Mail-Adresse mit RegEx validieren\n",
    "pattern_email = r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\"\n",
    "email_matches = re.findall(pattern_email, text)\n",
    "if email_matches:\n",
    "    print(\"Gefundene E-Mail-Adressen:\", email_matches)\n",
    "else:\n",
    "    print(\"Keine gültige E-Mail-Adresse gefunden.\")\n",
    "\n",
    "# E-Mail-Adresse mit externer Library validieren\n",
    "try:\n",
    "    result = validate_email(\"mi@ur.de\")  # findet man z. B. aus dem Text\n",
    "    print(\"Gültige E-Mail:\", result.email)\n",
    "except EmailNotValidError as e:\n",
    "    print(\"Ungültige E-Mail:\", e)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Erklärung warum externe Packages sinnvoll sind:\n",
    "#\n",
    "# Komplexe Muster wie E-Mail-Adressen oder internationale Telefonnummern\n",
    "# lassen sich nur sehr schwer mit einfachen regulären Ausdrücken korrekt\n",
    "# und vollständig erfassen.\n",
    "#\n",
    "# Externe Libraries wie `email_validator` und `phonenumbers` sind\n",
    "# speziell darauf ausgelegt, Standards und viele Sonderfälle korrekt zu behandeln.\n",
    "# Sie validieren nicht nur das Format, sondern z.B. bei E-Mails auch die\n",
    "# Domain, bei Telefonnummern Ländercodes und Nummernlängen.\n",
    "#\n",
    "# Das macht deinen Code robuster, wartbarer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c18332",
   "metadata": {},
   "source": [
    "### Beispiel 5: Embeddings und Vector Space Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8618b5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosinus-Ähnlichkeiten zwischen Wortpaaren:\n",
      "Dimensionen: (1, 96) (1, 96)\n",
      "'cat' vs. 'dog': 0.742\n",
      "Dimensionen: (1, 96) (1, 96)\n",
      "'car' vs. 'bike': 0.766\n",
      "Dimensionen: (1, 96) (1, 96)\n",
      "'cheesecake' vs. 'swimming': 0.299\n",
      "Dimensionen: (1, 96) (1, 96)\n",
      "'death' vs. 'google': 0.275\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import spacy\n",
    "\n",
    "# spaCy Modell laden (englisch, mit Vektoren)\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Wörter für Vergleich\n",
    "word_pairs = [\n",
    "    (\"cat\", \"dog\"), # Beispiel mit ähnlichen Wörtern\n",
    "    (\"car\", \"bike\"), # Beispiel mit ähnlichen Wörtern\n",
    "    (\"cheesecake\", \"swimming\"), # Beispiel mit unähnlichen Wörtern\n",
    "    (\"death\", \"google\") # Beispiel mit unähnlichen Wörtern\n",
    "]\n",
    "\n",
    "print(\"Cosinus-Ähnlichkeiten zwischen Wortpaaren:\")\n",
    "\n",
    "for w1, w2 in word_pairs:\n",
    "    # 1. Wandeln wir die Wörter in Vektoren.\n",
    "    # Dafür nutzen wir wieder das spaCy Modell und nutzen das Attribut .vector, das den Vektor/Embedding des Wortes zurückgibt.\n",
    "    # 2. Da cosine_similarity 2D-Arrays erwartet, müssen wir die Vektoren noch reshapen in 2D.\n",
    "    # cosine_similarity erwartet 2D-Arrays, da es prinzipiell auch für Matrizen-Vergleiche genutzt werden kann.\n",
    "    # .reshape(1, -1) sorgt dafür, dass die Vektoren die Form (1, n) bekommen, also eine Zeile und n Spalten. -1 bedeutet, dass die Anzahl der Spalten automatisch bestimmt wird.\n",
    "    vec1 = nlp(w1).vector.reshape(1, -1)\n",
    "    vec2 = nlp(w2).vector.reshape(1, -1)\n",
    "    print(\"Dimensionen:\", vec1.shape, vec2.shape)\n",
    "    \n",
    "    # 3. Berechnen wir die Cosinus-Ähnlichkeit mit sklearns cosine_similarity Funktion.\n",
    "    # [0][0] am Ende extrahiert den Skalarwert aus dem 2D-Array, das zurückgegeben wird.\n",
    "    cos_sim = cosine_similarity(vec1, vec2)[0][0]\n",
    "    print(f\"'{w1}' vs. '{w2}': {cos_sim:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d977ec",
   "metadata": {},
   "source": [
    "### 🐼 Einschub: Pandas Basics – Arbeiten mit `sentiment_texts.csv`\n",
    "\n",
    "Da wir für die nachfolgenden Beispiele eine CSV-Datei mit Textdaten verwenden, hier ein kurzer Einschub zu `pandas`.\n",
    "Gerade, wenn man mit Textdaten arbeitet, sind Daten oft in Tabellenform gespeichert. Ein gängiges Format ist CSV (Comma-Separated Values). In diesem Beispiel verwenden wir die Bibliothek `pandas`, um eine CSV-Datei zu laden und zu analysieren. \n",
    "\n",
    "Wir arbeiten mit der CSV-Datei `sentiment_texts.csv`, die Tweets umfasst und Annotationen für das Sentiment (positiv, negativ, neutral) enthält. Es handelt sich um Tweets, bei denen Accounts von Politikern der 2021 im Bundestag vertretenen Parteien von Twitter-Nutzern erwähnt wurden mit einem `@`-Zeichen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1559e73d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source_account</th>\n",
       "      <th>source_party</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1459496838629839104</td>\n",
       "      <td>Beatrix_vStorch</td>\n",
       "      <td>AFD</td>\n",
       "      <td>@LisaLies12 @Beatrix_vStorch Ich habe NICHT be...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1366816957236977920</td>\n",
       "      <td>cducsubt</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@ChristianHirte @CDU @dieLinke @cducsubt Gewis...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1437742901186993920</td>\n",
       "      <td>_FriedrichMerz</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@PeterBofinger @_FriedrichMerz @handelsblatt @...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1352576248560706048</td>\n",
       "      <td>SWagenknecht</td>\n",
       "      <td>LINKE</td>\n",
       "      <td>@KunzlerManuel @DnielSchmlhofer @Stefan_Hajek ...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1439569370217340928</td>\n",
       "      <td>Alice_Weidel</td>\n",
       "      <td>AFD</td>\n",
       "      <td>@cem_oezdemir @ABaerbock Dachte erst Sie meine...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1868</th>\n",
       "      <td>1411004773126509056</td>\n",
       "      <td>CDU</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@Ruebenhorst @MenschgbMensch @CDU ist das Euer...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1869</th>\n",
       "      <td>1436672257682779904</td>\n",
       "      <td>Markus_Soeder</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@dcremer_ @Markus_Soeder @CSU Ohne göttliche I...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1870</th>\n",
       "      <td>1464183001588376064</td>\n",
       "      <td>Karl_Lauterbach</td>\n",
       "      <td>SPD</td>\n",
       "      <td>@Karl_Lauterbach das sieht schlecht aus. Da hi...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1871</th>\n",
       "      <td>1389635614975348992</td>\n",
       "      <td>CDU</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@MatthiasRieger3 @EskenSaskia @MEtzold @CDU ja...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1872</th>\n",
       "      <td>1400994841396456960</td>\n",
       "      <td>Markus_Soeder</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@GerdMll42564793 @Markus_Soeder Bestimmt</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1873 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id   source_account source_party  \\\n",
       "0     1459496838629839104  Beatrix_vStorch          AFD   \n",
       "1     1366816957236977920         cducsubt      CDU_CSU   \n",
       "2     1437742901186993920   _FriedrichMerz      CDU_CSU   \n",
       "3     1352576248560706048     SWagenknecht        LINKE   \n",
       "4     1439569370217340928     Alice_Weidel          AFD   \n",
       "...                   ...              ...          ...   \n",
       "1868  1411004773126509056              CDU      CDU_CSU   \n",
       "1869  1436672257682779904    Markus_Soeder      CDU_CSU   \n",
       "1870  1464183001588376064  Karl_Lauterbach          SPD   \n",
       "1871  1389635614975348992              CDU      CDU_CSU   \n",
       "1872  1400994841396456960    Markus_Soeder      CDU_CSU   \n",
       "\n",
       "                                                  tweet sentiment  \n",
       "0     @LisaLies12 @Beatrix_vStorch Ich habe NICHT be...  NEGATIVE  \n",
       "1     @ChristianHirte @CDU @dieLinke @cducsubt Gewis...   NEUTRAL  \n",
       "2     @PeterBofinger @_FriedrichMerz @handelsblatt @...   NEUTRAL  \n",
       "3     @KunzlerManuel @DnielSchmlhofer @Stefan_Hajek ...   NEUTRAL  \n",
       "4     @cem_oezdemir @ABaerbock Dachte erst Sie meine...   NEUTRAL  \n",
       "...                                                 ...       ...  \n",
       "1868  @Ruebenhorst @MenschgbMensch @CDU ist das Euer...  NEGATIVE  \n",
       "1869  @dcremer_ @Markus_Soeder @CSU Ohne göttliche I...   NEUTRAL  \n",
       "1870  @Karl_Lauterbach das sieht schlecht aus. Da hi...  NEGATIVE  \n",
       "1871  @MatthiasRieger3 @EskenSaskia @MEtzold @CDU ja...   NEUTRAL  \n",
       "1872           @GerdMll42564793 @Markus_Soeder Bestimmt   NEUTRAL  \n",
       "\n",
       "[1873 rows x 5 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importieren der Pandas-Bibliothek\n",
    "import pandas as pd\n",
    "\n",
    "# 1️⃣ CSV-Datei laden: Mit pd.read_csv() können wir Daten aus einer CSV-Datei in ein DataFrame laden.\n",
    "df = pd.read_csv(\"tweets.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0394612f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source_account</th>\n",
       "      <th>source_party</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1459496838629839104</td>\n",
       "      <td>Beatrix_vStorch</td>\n",
       "      <td>AFD</td>\n",
       "      <td>@LisaLies12 @Beatrix_vStorch Ich habe NICHT be...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1366816957236977920</td>\n",
       "      <td>cducsubt</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@ChristianHirte @CDU @dieLinke @cducsubt Gewis...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1437742901186993920</td>\n",
       "      <td>_FriedrichMerz</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@PeterBofinger @_FriedrichMerz @handelsblatt @...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1352576248560706048</td>\n",
       "      <td>SWagenknecht</td>\n",
       "      <td>LINKE</td>\n",
       "      <td>@KunzlerManuel @DnielSchmlhofer @Stefan_Hajek ...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1439569370217340928</td>\n",
       "      <td>Alice_Weidel</td>\n",
       "      <td>AFD</td>\n",
       "      <td>@cem_oezdemir @ABaerbock Dachte erst Sie meine...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id   source_account source_party  \\\n",
       "0  1459496838629839104  Beatrix_vStorch          AFD   \n",
       "1  1366816957236977920         cducsubt      CDU_CSU   \n",
       "2  1437742901186993920   _FriedrichMerz      CDU_CSU   \n",
       "3  1352576248560706048     SWagenknecht        LINKE   \n",
       "4  1439569370217340928     Alice_Weidel          AFD   \n",
       "\n",
       "                                               tweet sentiment  \n",
       "0  @LisaLies12 @Beatrix_vStorch Ich habe NICHT be...  NEGATIVE  \n",
       "1  @ChristianHirte @CDU @dieLinke @cducsubt Gewis...   NEUTRAL  \n",
       "2  @PeterBofinger @_FriedrichMerz @handelsblatt @...   NEUTRAL  \n",
       "3  @KunzlerManuel @DnielSchmlhofer @Stefan_Hajek ...   NEUTRAL  \n",
       "4  @cem_oezdemir @ABaerbock Dachte erst Sie meine...   NEUTRAL  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mit df.head() können wir die ersten 5 Zeilen des DataFrames bequem anzeigen.\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4fc567b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        AFD\n",
       "1    CDU_CSU\n",
       "2    CDU_CSU\n",
       "3      LINKE\n",
       "4        AFD\n",
       "5        FDP\n",
       "6        SPD\n",
       "7    CDU_CSU\n",
       "8        SPD\n",
       "9      LINKE\n",
       "Name: source_party, dtype: object"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wir können auch die Werte einer bestimmten Spalte auswählen, z.B. \"source_party\":\n",
    "df[\"source_party\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "abd0710a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source_account</th>\n",
       "      <th>source_party</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1347612879810425088</td>\n",
       "      <td>n_roettgen</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@n_roettgen auch mit Blick auf andere Aspekte ...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1471842111062429952</td>\n",
       "      <td>_FriedrichMerz</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@ToshimaDE @CDU @_FriedrichMerz Wie? Sitzt die...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1411032162929872896</td>\n",
       "      <td>ArminLaschet</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@steps0815 @Arndt_Klocke @MaAhl5 @Oliver_Krisc...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1382766358790868992</td>\n",
       "      <td>Karl_Lauterbach</td>\n",
       "      <td>SPD</td>\n",
       "      <td>@Karl_Lauterbach Ach na endlich!! Da kann ich ...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1346511916173304064</td>\n",
       "      <td>_FriedrichMerz</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@BorisNMoellers @_FriedrichMerz Ich übrigens a...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1832</th>\n",
       "      <td>1473352625554963968</td>\n",
       "      <td>fdpbt</td>\n",
       "      <td>FDP</td>\n",
       "      <td>@Patrickweedmob @spdbt @GrueneBundestag @fdpbt...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841</th>\n",
       "      <td>1355126553882063104</td>\n",
       "      <td>Markus_Soeder</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@1xKlaudius @Markus_Soeder Mit Scheuer im Wahl...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1847</th>\n",
       "      <td>1411631133259973120</td>\n",
       "      <td>ArminLaschet</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@RadtkeMdEP 1.) Ein #guterplan #wegenmorgen wä...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1850</th>\n",
       "      <td>1352647722801757952</td>\n",
       "      <td>ArminLaschet</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>#Herzlichen #Glückwunsch an alle #nun #offizie...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867</th>\n",
       "      <td>1408741244927365120</td>\n",
       "      <td>Alice_Weidel</td>\n",
       "      <td>AFD</td>\n",
       "      <td>@ASB_Anwohner @Alice_Weidel @Afd_emskirchen Bu...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id   source_account source_party  \\\n",
       "7     1347612879810425088       n_roettgen      CDU_CSU   \n",
       "10    1471842111062429952   _FriedrichMerz      CDU_CSU   \n",
       "25    1411032162929872896     ArminLaschet      CDU_CSU   \n",
       "34    1382766358790868992  Karl_Lauterbach          SPD   \n",
       "43    1346511916173304064   _FriedrichMerz      CDU_CSU   \n",
       "...                   ...              ...          ...   \n",
       "1832  1473352625554963968            fdpbt          FDP   \n",
       "1841  1355126553882063104    Markus_Soeder      CDU_CSU   \n",
       "1847  1411631133259973120     ArminLaschet      CDU_CSU   \n",
       "1850  1352647722801757952     ArminLaschet      CDU_CSU   \n",
       "1867  1408741244927365120     Alice_Weidel          AFD   \n",
       "\n",
       "                                                  tweet sentiment  \n",
       "7     @n_roettgen auch mit Blick auf andere Aspekte ...  POSITIVE  \n",
       "10    @ToshimaDE @CDU @_FriedrichMerz Wie? Sitzt die...  POSITIVE  \n",
       "25    @steps0815 @Arndt_Klocke @MaAhl5 @Oliver_Krisc...  POSITIVE  \n",
       "34    @Karl_Lauterbach Ach na endlich!! Da kann ich ...  POSITIVE  \n",
       "43    @BorisNMoellers @_FriedrichMerz Ich übrigens a...  POSITIVE  \n",
       "...                                                 ...       ...  \n",
       "1832  @Patrickweedmob @spdbt @GrueneBundestag @fdpbt...  POSITIVE  \n",
       "1841  @1xKlaudius @Markus_Soeder Mit Scheuer im Wahl...  POSITIVE  \n",
       "1847  @RadtkeMdEP 1.) Ein #guterplan #wegenmorgen wä...  POSITIVE  \n",
       "1850  #Herzlichen #Glückwunsch an alle #nun #offizie...  POSITIVE  \n",
       "1867  @ASB_Anwohner @Alice_Weidel @Afd_emskirchen Bu...  POSITIVE  \n",
       "\n",
       "[120 rows x 5 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Filtermöglichkeiten: Mit df[df[\"sentiment\"] == \"POSITIVE\"] können wir nur die Zeilen mit positivem Sentiment anzeigen. \n",
    "\n",
    "df[\"sentiment\"] wählt die Spalte sentiment aus dem DataFrame df aus.\n",
    "Ergebnis: eine Series – also eine eindimensionale, beschriftete Datenstruktur.\n",
    "'''\n",
    "df[df[\"sentiment\"] == \"POSITIVE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "022a2ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "NEGATIVE    976\n",
       "NEUTRAL     777\n",
       "POSITIVE    120\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mit .value_counts() können wir die Häufigkeit der einzigartigen Werte in der Spalte \"sentiment\" anzeigen.\n",
    "# Wir sehen beim Output, dass die Stimmung nicht ausgewogen ist: Es gibt deutlich mehr negative als positive Tweets, wobei fast so viele neutrale Tweets wie positive Tweets vorhanden sind.\n",
    "df[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fd2d8128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       @LISALIES12 @BEATRIX_VSTORCH ICH HABE NICHT BE...\n",
       "1       @CHRISTIANHIRTE @CDU @DIELINKE @CDUCSUBT GEWIS...\n",
       "2       @PETERBOFINGER @_FRIEDRICHMERZ @HANDELSBLATT @...\n",
       "3       @KUNZLERMANUEL @DNIELSCHMLHOFER @STEFAN_HAJEK ...\n",
       "4       @CEM_OEZDEMIR @ABAERBOCK DACHTE ERST SIE MEINE...\n",
       "                              ...                        \n",
       "1868    @RUEBENHORST @MENSCHGBMENSCH @CDU IST DAS EUER...\n",
       "1869    @DCREMER_ @MARKUS_SOEDER @CSU OHNE GÖTTLICHE I...\n",
       "1870    @KARL_LAUTERBACH DAS SIEHT SCHLECHT AUS. DA HI...\n",
       "1871    @MATTHIASRIEGER3 @ESKENSASKIA @METZOLD @CDU JA...\n",
       "1872          @GERDMLL42564793 @MARKUS_SOEDER BESTIMMT!!!\n",
       "Name: shouted, Length: 1873, dtype: object"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mit .apply() können wir eine Funktion auf jede Zeile oder Spalte eines DataFrames anwenden.\n",
    "def shout(text):\n",
    "    return text.upper() + \"!!!\"\n",
    "\n",
    "df[\"shouted\"] = df[\"tweet\"].apply(shout)\n",
    "df[\"shouted\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "23bb03c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source_account</th>\n",
       "      <th>source_party</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>shouted</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>1389713588659625984</td>\n",
       "      <td>CDU</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>LG an @CDU und @CSU</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>LG AN @CDU UND @CSU!!!</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319</th>\n",
       "      <td>1377675573435191040</td>\n",
       "      <td>Die_Gruenen</td>\n",
       "      <td>GRUENE</td>\n",
       "      <td>@Die_Gruenen so schwarz.</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>@DIE_GRUENEN SO SCHWARZ.!!!</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1432400536498810880</td>\n",
       "      <td>CDU</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@CDU Was für ein Unsinn.</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>@CDU WAS FÜR EIN UNSINN.!!!</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>1424771876837024000</td>\n",
       "      <td>Die_Gruenen</td>\n",
       "      <td>GRUENE</td>\n",
       "      <td>@Die_Gruenen Zeit wirds!</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>@DIE_GRUENEN ZEIT WIRDS!!!!</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1409483299207122944</td>\n",
       "      <td>Karl_Lauterbach</td>\n",
       "      <td>SPD</td>\n",
       "      <td>@Karl_Lauterbach Ab wann?</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>@KARL_LAUTERBACH AB WANN?!!!</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>1389137005326618880</td>\n",
       "      <td>SWagenknecht</td>\n",
       "      <td>LINKE</td>\n",
       "      <td>@StimmederVernu9 @DerEchteGrubert @AlfredNeuma...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>@STIMMEDERVERNU9 @DERECHTEGRUBERT @ALFREDNEUMA...</td>\n",
       "      <td>523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>1399462761541911040</td>\n",
       "      <td>c_lindner</td>\n",
       "      <td>FDP</td>\n",
       "      <td>@chris_pyak @holgerkopp @HLiepelt @MartinWalth...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>@CHRIS_PYAK @HOLGERKOPP @HLIEPELT @MARTINWALTH...</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>1442227712869940992</td>\n",
       "      <td>cem_oezdemir</td>\n",
       "      <td>GRUENE</td>\n",
       "      <td>@GGahnt @CartmanTB2 @Andrew1023054 @NurZoabe @...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>@GGAHNT @CARTMANTB2 @ANDREW1023054 @NURZOABE @...</td>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>1345808822544326912</td>\n",
       "      <td>CDU</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@cat_spass @Abtreibpranger @Peacecakex @nelson...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>@CAT_SPASS @ABTREIBPRANGER @PEACECAKEX @NELSON...</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>1376307200797344000</td>\n",
       "      <td>hubertus_heil</td>\n",
       "      <td>SPD</td>\n",
       "      <td>@Detlef66138495 @BVG_Kampagne @goethe_jw @4tti...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>@DETLEF66138495 @BVG_KAMPAGNE @GOETHE_JW @4TTI...</td>\n",
       "      <td>746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1873 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id   source_account source_party  \\\n",
       "1724  1389713588659625984              CDU      CDU_CSU   \n",
       "1319  1377675573435191040      Die_Gruenen       GRUENE   \n",
       "32    1432400536498810880              CDU      CDU_CSU   \n",
       "351   1424771876837024000      Die_Gruenen       GRUENE   \n",
       "189   1409483299207122944  Karl_Lauterbach          SPD   \n",
       "...                   ...              ...          ...   \n",
       "575   1389137005326618880     SWagenknecht        LINKE   \n",
       "1657  1399462761541911040        c_lindner          FDP   \n",
       "635   1442227712869940992     cem_oezdemir       GRUENE   \n",
       "804   1345808822544326912              CDU      CDU_CSU   \n",
       "1361  1376307200797344000    hubertus_heil          SPD   \n",
       "\n",
       "                                                  tweet sentiment  \\\n",
       "1724                                LG an @CDU und @CSU  POSITIVE   \n",
       "1319                           @Die_Gruenen so schwarz.   NEUTRAL   \n",
       "32                             @CDU Was für ein Unsinn.  NEGATIVE   \n",
       "351                            @Die_Gruenen Zeit wirds!   NEUTRAL   \n",
       "189                           @Karl_Lauterbach Ab wann?   NEUTRAL   \n",
       "...                                                 ...       ...   \n",
       "575   @StimmederVernu9 @DerEchteGrubert @AlfredNeuma...  NEGATIVE   \n",
       "1657  @chris_pyak @holgerkopp @HLiepelt @MartinWalth...  NEGATIVE   \n",
       "635   @GGahnt @CartmanTB2 @Andrew1023054 @NurZoabe @...  NEGATIVE   \n",
       "804   @cat_spass @Abtreibpranger @Peacecakex @nelson...   NEUTRAL   \n",
       "1361  @Detlef66138495 @BVG_Kampagne @goethe_jw @4tti...   NEUTRAL   \n",
       "\n",
       "                                                shouted  text_length  \n",
       "1724                             LG AN @CDU UND @CSU!!!           19  \n",
       "1319                        @DIE_GRUENEN SO SCHWARZ.!!!           24  \n",
       "32                          @CDU WAS FÜR EIN UNSINN.!!!           24  \n",
       "351                         @DIE_GRUENEN ZEIT WIRDS!!!!           24  \n",
       "189                        @KARL_LAUTERBACH AB WANN?!!!           25  \n",
       "...                                                 ...          ...  \n",
       "575   @STIMMEDERVERNU9 @DERECHTEGRUBERT @ALFREDNEUMA...          523  \n",
       "1657  @CHRIS_PYAK @HOLGERKOPP @HLIEPELT @MARTINWALTH...          566  \n",
       "635   @GGAHNT @CARTMANTB2 @ANDREW1023054 @NURZOABE @...          570  \n",
       "804   @CAT_SPASS @ABTREIBPRANGER @PEACECAKEX @NELSON...          655  \n",
       "1361  @DETLEF66138495 @BVG_KAMPAGNE @GOETHE_JW @4TTI...          746  \n",
       "\n",
       "[1873 rows x 7 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mit .sort_values() können wir den DataFrame nach einer bestimmten Spalte sortieren.\n",
    "def text_length(text):\n",
    "    return len(text)\n",
    "\n",
    "df[\"text_length\"] = df[\"tweet\"].apply(text_length)\n",
    "df = df.sort_values(by=\"text_length\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c74524fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "NEGATIVE    26.861680\n",
       "NEUTRAL     19.772201\n",
       "POSITIVE    19.016667\n",
       "Name: word_count, dtype: float64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mit .mean() können wir den Durchschnitt einer Spalte berechnen.\n",
    "def word_count(text):\n",
    "    return len(text.split())\n",
    "\n",
    "df[\"word_count\"] = df[\"tweet\"].apply(word_count)\n",
    "\n",
    "# Mit .groupby() können wir den DataFrame nach einer bestimmten Spalte gruppieren.\n",
    "# df.groupby(\"sentiment\")[\"word_count\"] gibt uns eine SeriesGroupBy-Objekt zurück, das die Wortanzahl für jede Sentiment-Kategorie gruppiert.\n",
    "# Mit .mean() berechnen wir den Durchschnitt der Wortanzahl für jede Sentiment-Kategorie.\n",
    "df.groupby(\"sentiment\")[\"word_count\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b0c508ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source_account</th>\n",
       "      <th>source_party</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>shouted</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>1464916983108062976</td>\n",
       "      <td>MiKellner</td>\n",
       "      <td>GRUENE</td>\n",
       "      <td>@MonikaHerrmann1 @MiKellner @ABaerbock Wieder ...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>@MONIKAHERRMANN1 @MIKELLNER @ABAERBOCK WIEDER ...</td>\n",
       "      <td>61</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>1363624003278151936</td>\n",
       "      <td>PaulZiemiak</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@PaulZiemiak @BerlinReporter Keine Aufregung. ...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>@PAULZIEMIAK @BERLINREPORTER KEINE AUFREGUNG. ...</td>\n",
       "      <td>98</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1781</th>\n",
       "      <td>1362817043549069056</td>\n",
       "      <td>CDU</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@GirkeHanjo @BerlinReporter @MIT_bund @christo...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>@GIRKEHANJO @BERLINREPORTER @MIT_BUND @CHRISTO...</td>\n",
       "      <td>107</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id source_account source_party  \\\n",
       "872   1464916983108062976      MiKellner       GRUENE   \n",
       "1725  1363624003278151936    PaulZiemiak      CDU_CSU   \n",
       "1781  1362817043549069056            CDU      CDU_CSU   \n",
       "\n",
       "                                                  tweet sentiment  \\\n",
       "872   @MonikaHerrmann1 @MiKellner @ABaerbock Wieder ...   NEUTRAL   \n",
       "1725  @PaulZiemiak @BerlinReporter Keine Aufregung. ...  NEGATIVE   \n",
       "1781  @GirkeHanjo @BerlinReporter @MIT_bund @christo...  POSITIVE   \n",
       "\n",
       "                                                shouted  text_length  \\\n",
       "872   @MONIKAHERRMANN1 @MIKELLNER @ABAERBOCK WIEDER ...           61   \n",
       "1725  @PAULZIEMIAK @BERLINREPORTER KEINE AUFREGUNG. ...           98   \n",
       "1781  @GIRKEHANJO @BERLINREPORTER @MIT_BUND @CHRISTO...          107   \n",
       "\n",
       "      word_count  \n",
       "872            7  \n",
       "1725          10  \n",
       "1781          13  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def has_berlin(text):\n",
    "    return \"Berlin\" in text\n",
    "\n",
    "# Zeilen filtern\n",
    "df_berlin = df[df[\"tweet\"].apply(has_berlin)]\n",
    "df_berlin.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2394153b",
   "metadata": {},
   "source": [
    "### 🔢 Einschub: NumPy Basics – Arbeiten mit Arrays\n",
    "\n",
    "NumPy (Numerical Python) ist die grundlegende Bibliothek für wissenschaftliches Rechnen in Python. Es bietet ein mächtiges N-dimensionales Array-Objekt und Funktionen für deren Bearbeitung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f2006801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy Array: [1 2 3 4 5]\n",
      "Typ: <class 'numpy.ndarray'>\n",
      "Shape (Form): (5,)\n",
      "Data Type: int64\n"
     ]
    }
   ],
   "source": [
    "# Importieren der NumPy-Bibliothek\n",
    "import numpy as np\n",
    "\n",
    "# 1️⃣ Arrays erstellen: Mit np.array() können wir Listen in NumPy Arrays umwandeln.\n",
    "numbers = [1, 2, 3, 4, 5]\n",
    "arr = np.array(numbers)\n",
    "print(\"NumPy Array:\", arr)\n",
    "print(\"Typ:\", type(arr))\n",
    "print(\"Shape (Form):\", arr.shape)\n",
    "print(\"Data Type:\", arr.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2ac6faee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D Array:\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "Shape: (3, 3)\n",
      "\n",
      "Zeros Array:\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "\n",
      "Ones Array:\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# 2️⃣ Zweidimensionale Arrays: Mit np.array() können wir auch 2D-Arrays (Matrizen) erstellen.\n",
    "matrix = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(\"2D Array:\")\n",
    "print(matrix)\n",
    "print(\"Shape:\", matrix.shape)  # (3, 3) bedeutet 3 Zeilen, 3 Spalten\n",
    "\n",
    "# Arrays mit bestimmten Werten erstellen\n",
    "zeros = np.zeros((2, 3))  # 2x3 Array mit Nullen\n",
    "ones = np.ones((2, 3))    # 2x3 Array mit Einsen\n",
    "print(\"\\nZeros Array:\")\n",
    "print(zeros)\n",
    "print(\"\\nOnes Array:\")\n",
    "print(ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d3e17e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Array: [10 20 30 40 50]\n",
      "Erstes Element: 10\n",
      "Letztes Element: 50\n",
      "Slice [1:4]: [20 30 40]\n",
      "\n",
      "2D Array:\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "Element [0,0]: 1\n",
      "Element [1,2]: 6\n",
      "Erste Zeile: [1 2 3]\n",
      "Erste Spalte: [1 4 7]\n"
     ]
    }
   ],
   "source": [
    "# 3️⃣ Array-Indexierung und Slicing: Ähnlich wie bei Python-Listen\n",
    "arr = np.array([10, 20, 30, 40, 50])\n",
    "print(\"Original Array:\", arr)\n",
    "print(\"Erstes Element:\", arr[0])      # Index 0\n",
    "print(\"Letztes Element:\", arr[-1])    # Index -1\n",
    "print(\"Slice [1:4]:\", arr[1:4])       # Elemente von Index 1 bis 3\n",
    "\n",
    "# 2D Array Indexierung\n",
    "matrix = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(\"\\n2D Array:\")\n",
    "print(matrix)\n",
    "print(\"Element [0,0]:\", matrix[0, 0])  # Erste Zeile, erste Spalte\n",
    "print(\"Element [1,2]:\", matrix[1, 2])  # Zweite Zeile, dritte Spalte\n",
    "print(\"Erste Zeile:\", matrix[0, :])    # Ganze erste Zeile\n",
    "print(\"Erste Spalte:\", matrix[:, 0])   # Ganze erste Spalte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "534bf291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array 1: [1 2 3 4]\n",
      "Array 2: [10 20 30 40]\n",
      "Addition: [11 22 33 44]\n",
      "Subtraktion: [ -9 -18 -27 -36]\n",
      "Multiplikation: [ 10  40  90 160]\n",
      "Division: [10. 10. 10. 10.]\n",
      "\n",
      "Array * 2: [2 4 6 8]\n",
      "Array + 10: [11 12 13 14]\n"
     ]
    }
   ],
   "source": [
    "# 4️⃣ Mathematische Operationen: NumPy macht Berechnungen sehr effizient\n",
    "arr1 = np.array([1, 2, 3, 4])\n",
    "arr2 = np.array([10, 20, 30, 40])\n",
    "\n",
    "print(\"Array 1:\", arr1)\n",
    "print(\"Array 2:\", arr2)\n",
    "\n",
    "# Element-weise Operationen\n",
    "print(\"Addition:\", arr1 + arr2)\n",
    "print(\"Subtraktion:\", arr1 - arr2)\n",
    "print(\"Multiplikation:\", arr1 * arr2)\n",
    "print(\"Division:\", arr2 / arr1)\n",
    "\n",
    "# Operationen mit Skalaren\n",
    "print(\"\\nArray * 2:\", arr1 * 2)\n",
    "print(\"Array + 10:\", arr1 + 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0c0db0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: [1 5 2 8 3 7 4 6]\n",
      "Summe: 36\n",
      "Mittelwert: 4.5\n",
      "Median: 4.5\n",
      "Standardabweichung: 2.29128784747792\n",
      "Minimum: 1\n",
      "Maximum: 8\n",
      "Index des Minimums: 0\n",
      "Index des Maximums: 3\n",
      "Sortiert: [1 2 3 4 5 6 7 8]\n"
     ]
    }
   ],
   "source": [
    "# 5️⃣ Nützliche NumPy-Funktionen für statistische Berechnungen\n",
    "data = np.array([1, 5, 2, 8, 3, 7, 4, 6])\n",
    "print(\"Data:\", data)\n",
    "\n",
    "print(\"Summe:\", np.sum(data))\n",
    "print(\"Mittelwert:\", np.mean(data))\n",
    "print(\"Median:\", np.median(data))\n",
    "print(\"Standardabweichung:\", np.std(data))\n",
    "print(\"Minimum:\", np.min(data))\n",
    "print(\"Maximum:\", np.max(data))\n",
    "\n",
    "# Index des Minimums/Maximums\n",
    "print(\"Index des Minimums:\", np.argmin(data))\n",
    "print(\"Index des Maximums:\", np.argmax(data))\n",
    "\n",
    "# Array sortieren\n",
    "print(\"Sortiert:\", np.sort(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "78db9189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Array: [1 2 3 4 5 6]\n",
      "Shape: (6,)\n",
      "\n",
      "Reshape zu 2x3:\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "Shape: (2, 3)\n",
      "\n",
      "Reshape zu 3x2:\n",
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n",
      "\n",
      "Auto-Reshape (-1, 2):\n",
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n",
      "Shape: (3, 2)\n"
     ]
    }
   ],
   "source": [
    "# 6️⃣ Array-Reshaping: Die Form von Arrays ändern\n",
    "arr = np.array([1, 2, 3, 4, 5, 6])\n",
    "print(\"Original Array:\", arr)\n",
    "print(\"Shape:\", arr.shape)\n",
    "\n",
    "# Zu 2x3 Matrix umformen\n",
    "reshaped = arr.reshape(2, 3)\n",
    "print(\"\\nReshape zu 2x3:\")\n",
    "print(reshaped)\n",
    "print(\"Shape:\", reshaped.shape)\n",
    "\n",
    "# Zu 3x2 Matrix umformen\n",
    "reshaped2 = arr.reshape(3, 2)\n",
    "print(\"\\nReshape zu 3x2:\")\n",
    "print(reshaped2)\n",
    "\n",
    "# Automatische Dimensionsbestimmung mit -1\n",
    "auto_reshape = arr.reshape(-1, 2)  # -1 bedeutet: bestimme automatisch\n",
    "print(\"\\nAuto-Reshape (-1, 2):\")\n",
    "print(auto_reshape)\n",
    "print(\"Shape:\", auto_reshape.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29931ef",
   "metadata": {},
   "source": [
    "## 👩🏼‍💻 Aufgaben "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "92b7df56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Aufgabe: Gebe für die ersten 3 Tweets die Tokens als List mit print() aus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c027790",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung anzeigen</b></summary>\n",
    "\n",
    "```python\n",
    "for tweet in df[\"tweet\"].head(3):\n",
    "    tokens = tweet.split(\" \")\n",
    "    print(tokens)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f20450ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Aufgabe: Geben sie für die ersten 3 Tweets die POS-Tags als List mit print() aus.\n",
    "# Beispiel: \"Ich habe Lust auf Pizza.\" -> [(\"Ich\", \"PRON\"), (\"habe\", \"VERB\"), (\"Lust\", \"NOUN\"), (\"auf\", \"ADP\"), (\"Pizza\", \"NOUN\")]\n",
    "import spacy\n",
    "nlp = spacy.load(\"de_core_news_sm\")  # Deutsches Modell laden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4599355a",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung anzeigen</b></summary>\n",
    "\n",
    "```python\n",
    "for tweet in df[\"tweet\"].head(3):\n",
    "    doc = nlp(tweet)\n",
    "    pos_tags = [(token.text, token.pos_) for token in doc]\n",
    "    print(pos_tags)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e4a29c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Aufgabe: Geben sie für die ersten 3 Tweets die Lemmas als List mit print() aus.\n",
    "# Beispiel: \"Ich habe Lust auf Pizza.\" -> [(\"Ich\", \"ich\"), (\"habe\", \"haben\"), (\"Lust\", \"Lust\"), (\"auf\", \"auf\"), (\"Pizza\", \"Pizza\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9fd4a4",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung anzeigen</b></summary>\n",
    "\n",
    "```python\n",
    "for tweet in df[\"tweet\"].head(3):\n",
    "    doc = nlp(tweet)\n",
    "    lemmas = [(token.text, token.lemma_) for token in doc]\n",
    "    print(lemmas)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740de475",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5046c372",
   "metadata": {},
   "source": [
    "## Aufgabe 4 / Was ist TF-IDF?\n",
    "\n",
    "**TF-IDF** steht für **Term Frequency – Inverse Document Frequency**.  \n",
    "Es ist ein Verfahren aus der Textanalyse, um herauszufinden, wie wichtig ein Wort in einem Text ist – nicht nur innerhalb dieses Textes, sondern auch im Vergleich zu allen anderen Texten in einer Sammlung (z. B. Tweets).\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Term Frequency (TF)\n",
    "Die **Term Frequency** misst, wie oft ein Wort \\( w \\) in einem Dokument \\( d \\) vorkommt, im Verhältnis zur Gesamtlänge des Dokuments.\n",
    "\n",
    "$$\n",
    "TF(w, d) = \\frac{\\text{Anzahl der Vorkommen von } w \\text{ in } d}{\\text{Gesamtanzahl der Wörter in } d}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Inverse Document Frequency (IDF)\n",
    "Die **Inverse Document Frequency** misst, wie selten ein Wort in allen Dokumenten ist.  \n",
    "Sei \\( N \\) die Gesamtanzahl der Dokumente und \\( df(w) \\) die Anzahl der Dokumente, in denen das Wort \\( w \\) vorkommt:\n",
    "\n",
    "$$\n",
    "IDF(w) = \\log \\left( \\frac{N}{1 + df(w)} \\right)\n",
    "$$\n",
    "\n",
    "(Das **+1** im Nenner verhindert eine Division durch Null.)\n",
    "\n",
    "👉 **Warum der Logarithmus?**  \n",
    "Ohne den Logarithmus würden sehr seltene Wörter extrem hohe Werte bekommen.  \n",
    "Der Logarithmus **glättet** diesen Effekt:  \n",
    "- Häufige Wörter bleiben nahe bei 0  \n",
    "- Sehr seltene Wörter bekommen höhere Werte, aber nicht unendlich groß\n",
    "\n",
    "---\n",
    "\n",
    "### 3. TF-IDF\n",
    "Die Kombination ergibt den endgültigen Wert:\n",
    "\n",
    "$$\n",
    "TF\\text{-}IDF(w, d) = TF(w, d) \\times IDF(w)\n",
    "$$\n",
    "\n",
    "- Wörter, die **häufig in einem Dokument** vorkommen (hoher TF)  \n",
    "  und **selten in anderen Dokumenten** (hoher IDF) haben einen großen TF-IDF-Wert.  \n",
    "- Häufige Wörter wie „ist“ oder „der“ haben dagegen niedrige Werte, weil ihr IDF gering ist.\n",
    "\n",
    "---\n",
    "\n",
    "So kann man Texte in Zahlenform umwandeln und mit diesen Vektoren z. B. **Ähnlichkeiten** zwischen Tweets berechnen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09bf4a0",
   "metadata": {},
   "source": [
    "### Aufgabe\n",
    "\n",
    "Gegeben ist eine Liste von Tweets (`tweets`) und ein einzelner Text (`text`).  \n",
    "Finde die **10 Tweets**, die dem gegebenen Text am ähnlichsten sind, basierend auf **TF-IDF und Kosinus-Ähnlichkeit**.  \n",
    "\n",
    "Zugegeben, die Aufgabe ist etwas komplexer, versucht sie schrittweise zu lösen und zweifelt nicht, unten einen Blick in die Lösung zu werfen 😉.\n",
    "\n",
    "**Tipps:**\n",
    "- Schreibe eine Funktion `tokenize()` zum Aufteilen der Texte in Wörter.  \n",
    "- Berechne TF und IDF für alle Tweets, erstelle TF-IDF-Vektoren.  \n",
    "- Verwende `cosine_similarity` von `sklearn.metrics.pairwise` für die Ähnlichkeit.  \n",
    "- `np.array(...).reshape(1, -1)` wandelt einen 1D-Vektor in 2D um.  \n",
    "- `np.argsort(similarities)[::-1]` sortiert die Tweets nach Ähnlichkeit absteigend.  \n",
    "- Gib die Tweets zusammen mit dem Ähnlichkeitswert aus.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f67da728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# math ist eine eingebaute Python-Bibliothek, die mathematische Funktionen bereitstellt.\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# convert df[\"tweet\"] to a list of strings\n",
    "tweets = df[\"tweet\"].tolist()\n",
    "\n",
    "# Text, zu dem wir ähnliche Tweets finden wollen\n",
    "text = \"Corona und Impfstoff\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "6416d012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Tokenisieren ---\n",
    "\n",
    "# --- 2. TF berechnen ---\n",
    "\n",
    "# --- 3. IDF berechnen ---\n",
    "\n",
    "# --- 4. TF-IDF Vektor erstellen ---\n",
    "\n",
    "# --- 5. Ähnlichkeit berechnen ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab260e5",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung anzeigen</b></summary>\n",
    "\n",
    "```python\n",
    "# --- 1. Tokenisieren ---\n",
    "def tokenize(s):\n",
    "    return s.lower().split()\n",
    "\n",
    "tokenized_tweets = [tokenize(t) for t in tweets]\n",
    "tokenized_text = tokenize(text)\n",
    "\n",
    "# --- 2. TF berechnen ---\n",
    "def term_frequency(words):\n",
    "    tf = {}\n",
    "    total = len(words)\n",
    "    for w in words:\n",
    "        tf[w] = tf.get(w, 0) + 1\n",
    "    for w in tf:\n",
    "        tf[w] /= total\n",
    "    return tf\n",
    "\n",
    "tf_tweets = [term_frequency(t) for t in tokenized_tweets]\n",
    "tf_text = term_frequency(tokenized_text)\n",
    "\n",
    "# --- 3. IDF berechnen ---\n",
    "N = len(tweets)\n",
    "all_words = set([w for tweet in tokenized_tweets for w in tweet])\n",
    "\n",
    "idf = {}\n",
    "for w in all_words:\n",
    "    # Nun zählen wir, in wie vielen Dokumenten (Tweets) das Wort vorkommt\n",
    "    doc_f = 0\n",
    "    for t in tokenized_tweets:\n",
    "        if w in t:\n",
    "            doc_f += 1\n",
    "    # Für ein Wort w berechnen wir den IDF-Wert basierend auf der Anzahl der Dokumente N und der Anzahl der Dokumente, in denen das Wort vorkommt (doc_f).\n",
    "    idf[w] = math.log(N / (1 + doc_f))\n",
    "\n",
    "# --- 4. TF-IDF Vektor erstellen ---\n",
    "def tfidf_vector(tf, idf):\n",
    "    vector = []\n",
    "    for w in sorted(idf.keys()): \n",
    "        tf_value = tf.get(w, 0)  # TF-Wert für das Wort (0 falls nicht vorhanden)\n",
    "        idf_value = idf[w]       # IDF-Wert für das Wort\n",
    "        tfidf_value = tf_value * idf_value\n",
    "        vector.append(tfidf_value)\n",
    "    return vector\n",
    "\n",
    "tfidf_tweets = [tfidf_vector(tf, idf) for tf in tf_tweets]\n",
    "tfidf_text = tfidf_vector(tf_text, idf)\n",
    "\n",
    "# --- 5. Ähnlichkeit berechnen ---\n",
    "# Convert to numpy arrays and reshape for cosine_similarity\n",
    "tfidf_text_reshaped = np.array(tfidf_text).reshape(1, -1)\n",
    "tfidf_tweets_array = np.array(tfidf_tweets) # tfidf_tweets_array.shape ist (anzahl_tweets, anzahl an einzigartigen Wörtern)\n",
    "\n",
    "# Erklärung: Numpy ist eine Bibliothek für effiziente mathematische Operationen mit Arrays.\n",
    "# Die reshape(1, -1) Operation wandelt den 1D-Vektor in eine 2D-Matrix um:\n",
    "# - Die \"1\" bedeutet: eine Zeile\n",
    "# - Das \"-1\" bedeutet: \"automatisch berechnen\" für die Anzahl der Spalten\n",
    "# cosine_similarity erwartet 2D-Arrays als Eingabe, daher die Umformung.\n",
    "\n",
    "similarities = cosine_similarity(tfidf_text_reshaped, tfidf_tweets_array)[0]\n",
    "\n",
    "# Ergebnisse anzeigen\n",
    "# Sortiere tweets nach ähnlichkeit (höchste zuerst) und zeige die top 10\n",
    "# [::-1] kehrt die Reihenfolge um\n",
    "# Jetzt sind die Indizes vom größten zum kleinsten Wert, also absteigend sortiert.\n",
    "sorted_indices = np.argsort(similarities)[::-1]\n",
    "for i in sorted_indices[:10]:\n",
    "    print(f\"Ähnlichkeit: {similarities[i]:.3f} -> {tweets[i]}\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_nils_hellwig",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
