{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "336666e5",
   "metadata": {},
   "source": [
    "# Notebook: Einführung in NLP für Python\n",
    "\n",
    "Dieses Notebook behandelt grundlegende Konzepte des NLP (Natural Language Processing) wie Tokenisierung, Stemming und Lemmatisierung. Diese Techniken sind wesentlich für die Verarbeitung und Analyse von Textdaten.\n",
    "\n",
    "Quelle: https://web.stanford.edu/~jurafsky/slp3/ed3book.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aabe9761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[2mResolved \u001b[1m127 packages\u001b[0m \u001b[2min 1.92s\u001b[0m\u001b[0m                                       \u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m31 packages\u001b[0m \u001b[2min 3.90s\u001b[0m\u001b[0m                                            \n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m31 packages\u001b[0m \u001b[2min 44ms\u001b[0m\u001b[0m                               \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mannotated-types\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mblis\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcatalogue\u001b[0m\u001b[2m==2.0.10\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mclick\u001b[0m\u001b[2m==8.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcloudpathlib\u001b[0m\u001b[2m==0.23.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mconfection\u001b[0m\u001b[2m==0.1.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcymem\u001b[0m\u001b[2m==2.0.11\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangcodes\u001b[0m\u001b[2m==3.5.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlanguage-data\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmarisa-trie\u001b[0m\u001b[2m==1.3.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmarkdown-it-py\u001b[0m\u001b[2m==4.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmdurl\u001b[0m\u001b[2m==0.1.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmurmurhash\u001b[0m\u001b[2m==1.0.13\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.3.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpreshed\u001b[0m\u001b[2m==3.0.10\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpydantic\u001b[0m\u001b[2m==2.12.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpydantic-core\u001b[0m\u001b[2m==2.41.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrich\u001b[0m\u001b[2m==14.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mshellingham\u001b[0m\u001b[2m==1.5.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msmart-open\u001b[0m\u001b[2m==7.4.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mspacy\u001b[0m\u001b[2m==3.8.7\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mspacy-legacy\u001b[0m\u001b[2m==3.0.12\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mspacy-loggers\u001b[0m\u001b[2m==1.0.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msrsly\u001b[0m\u001b[2m==2.5.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mthinc\u001b[0m\u001b[2m==8.3.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtqdm\u001b[0m\u001b[2m==4.67.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyper\u001b[0m\u001b[2m==0.20.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyping-inspection\u001b[0m\u001b[2m==0.4.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwasabi\u001b[0m\u001b[2m==1.1.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mweasel\u001b[0m\u001b[2m==0.4.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwrapt\u001b[0m\u001b[2m==2.0.0\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m130 packages\u001b[0m \u001b[2min 882ms\u001b[0m\u001b[0m                                       \u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m3 packages\u001b[0m \u001b[2min 630ms\u001b[0m\u001b[0m                                             \n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m3 packages\u001b[0m \u001b[2min 5ms\u001b[0m\u001b[0m                                 \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjoblib\u001b[0m\u001b[2m==1.5.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnltk\u001b[0m\u001b[2m==3.9.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mregex\u001b[0m\u001b[2m==2025.10.23\u001b[0m\n",
      "/Users/nils_hellwig/Documents/Seafile/Meine Bibliothek/Lehre/AIE-public/Notebooks/.venv/bin/python: No module named pip\n",
      "/Users/nils_hellwig/Documents/Seafile/Meine Bibliothek/Lehre/AIE-public/Notebooks/.venv/bin/python: No module named pip\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m132 packages\u001b[0m \u001b[2min 708ms\u001b[0m\u001b[0m                                       \u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m2 packages\u001b[0m \u001b[2min 349ms\u001b[0m\u001b[0m                                             \n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m2 packages\u001b[0m \u001b[2min 3ms\u001b[0m\u001b[0m.0                               \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdnspython\u001b[0m\u001b[2m==2.8.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1memail-validator\u001b[0m\u001b[2m==2.3.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Für dieses Projekt müssen wir zunächst die folgenden Pakete installieren:\n",
    "!uv add spacy\n",
    "!uv add nltk\n",
    "!python -m spacy download de_core_news_sm\n",
    "!python -m spacy download en_core_web_sm\n",
    "!uv add email-validator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1d5aff",
   "metadata": {},
   "source": [
    "## Beispiele\n",
    "\n",
    "### Beispiel 1: Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7191ca",
   "metadata": {},
   "source": [
    "Wir haben bereits im Python-Notebook gelernt, wie wir Texte splitten können. Wiederholen wir das kurz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e45b54d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split nach Leerzeichen: ['Hallo', 'Welt!', 'Python', 'ist', 'eine', 'ziemlich', 'coole', 'Programmiersprache.', 'Ich', 'hoffe,', 'Sie', 'mögen', 'sie', 'auch!']\n"
     ]
    }
   ],
   "source": [
    "text = \"Hallo Welt! Python ist eine ziemlich coole Programmiersprache. Ich hoffe, Sie mögen sie auch!\"\n",
    "tokens_spaces = text.split()\n",
    "print(\"Split nach Leerzeichen:\", tokens_spaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acba1bab",
   "metadata": {},
   "source": [
    "Wie wir in der Ausgabe sehen, trennt die einfache `split()`-Methode Wörter, aber sie behandelt Satzzeichen nicht korrekt. Zum Beispiel wird \"Welt!\" als ein Token betrachtet, was in vielen NLP-Anwendungen nicht ideal ist. Daher verwenden wir spezialisierte **Tokenizer**, um dieses Problem zu lösen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35e439d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/nils_hellwig/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wir laden NLTK, eine Bibliothek für natürliche Sprachverarbeitung\n",
    "import nltk\n",
    "\n",
    "# Punkt-Tokenizer herunterladen, ein Package, dass wir für die Tokenisierung benötigen. Punkt enthält Regeln für die Tokenisierung von Wörtern und Sätzen.\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a42c3807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK Word Tokenize: ['Hallo', 'Welt', '!', 'Python', 'ist', 'eine', 'ziemlich', 'coole', 'Programmiersprache', '.', 'Ich', 'hoffe', ',', 'Sie', 'mögen', 'sie', 'auch', '!']\n"
     ]
    }
   ],
   "source": [
    "# Um die Tokenisierung durchzuführen, importieren wir die word_tokenize-Funktion aus dem nltk.tokenize Modul.\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Wir verwenden die word_tokenize-Funktion, um den Text in Wörter zu zerlegen.\n",
    "tokens_nltk = word_tokenize(text)\n",
    "\n",
    "# Ausgabe der tokenisierten Wörter\n",
    "print(\"NLTK Word Tokenize:\", tokens_nltk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9553931",
   "metadata": {},
   "source": [
    "Wir sehen, dass der Tokenizer Satzzeichen korrekt behandelt und jedes Wort sowie Satzzeichen als separate Tokens ausgibt. Des weiteren können wir auch Sätze tokenisieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2694fc52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Satz-Tokenisierung: ['Hallo Welt!', 'Dies ist ein Test.', 'Hier ist noch ein Satz.']\n"
     ]
    }
   ],
   "source": [
    "# NLTK bietet auch eine Funktion zur Satz-Tokenisierung an.\n",
    "sentences = nltk.sent_tokenize(\"Hallo Welt! Dies ist ein Test. Hier ist noch ein Satz.\")\n",
    "print(\"Satz-Tokenisierung:\", sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8ddc36",
   "metadata": {},
   "source": [
    "### Beispiel 2: Part-of-Speech (POS) Tagging\n",
    "\n",
    "POS-Tagging ermöglicht es uns, die grammatikalische Rolle jedes Wortes in einem Satz zu identifizieren. Wir verwenden die `nltk`-Bibliothek, um dies zu demonstrieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e1a780c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK POS-Tagging (Englisch):\n",
      "[('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN'), ('.', '.')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /Users/nils_hellwig/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Definieren wir zunächst zwei Beispieltexte, einen auf Englisch und einen auf Deutsch.\n",
    "text_en = \"The quick brown fox jumps over the lazy dog.\"\n",
    "text_de = \"Der schnelle braune Fuchs springt über den faulen Hund.\"\n",
    "\n",
    "# NLTK-Modelle herunterladen. averaged_perceptron_tagger ist ein vortrainiertes Modell für POS-Tagging.\n",
    "nltk.download(\"averaged_perceptron_tagger_eng\")\n",
    "\n",
    "# Tokenisieren und POS-Tagging (Englisch)\n",
    "tokens_en = nltk.word_tokenize(text_en)\n",
    "pos_tags_en = nltk.pos_tag(tokens_en)\n",
    "print(\"NLTK POS-Tagging (Englisch):\")\n",
    "print(pos_tags_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "77fb683d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "spaCy POS-Tagging (Englisch):\n",
      "The        DET       \n",
      "quick      ADJ       \n",
      "brown      ADJ       \n",
      "fox        NOUN      \n",
      "jumps      VERB      \n",
      "over       ADP       \n",
      "the        DET       \n",
      "lazy       ADJ       \n",
      "dog        NOUN      \n",
      ".          PUNCT     \n",
      "\n",
      "spaCy POS-Tagging (Deutsch):\n",
      "Der        DET       \n",
      "schnelle   ADJ       \n",
      "braune     ADJ       \n",
      "Fuchs      NOUN      \n",
      "springt    VERB      \n",
      "über       ADP       \n",
      "den        DET       \n",
      "faulen     ADJ       \n",
      "Hund       NOUN      \n",
      ".          PUNCT     \n"
     ]
    }
   ],
   "source": [
    "# Auch mit spaCy können wir POS-Tagging durchführen. SpaCy (https://spacy.io/) ist eine sehr beliebte Bibliothek für NLP in Python, \n",
    "# da sie viele Tools und vortrainierte Modelle bietet für verschiedenste Anwendungen.\n",
    "import spacy\n",
    "\n",
    "# Laden wir zunächst die vortrainierten Modelle für Englisch.\n",
    "nlp_en = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Mit nlp_en können wir den Text in eine Liste von Tokens umwandeln.\n",
    "doc_en = nlp_en(text_en)\n",
    "\n",
    "# Tokens besitzen verschiedene Attribute, z.B. den Text und die Wortart (POS).\n",
    "print(\"\\nspaCy POS-Tagging (Englisch):\")\n",
    "for token in doc_en:\n",
    "    print(f\"{token.text:10} {token.pos_:10}\") # :10 sorgt für eine feste Breite von 10 Zeichen\n",
    "\n",
    "# Deutsches Modell\n",
    "nlp_de = spacy.load(\"de_core_news_sm\")\n",
    "doc_de = nlp_de(text_de)\n",
    "print(\"\\nspaCy POS-Tagging (Deutsch):\")\n",
    "for token in doc_de:\n",
    "    print(f\"{token.text:10} {token.pos_:10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb21251",
   "metadata": {},
   "source": [
    "### Beispiel 3: Lemmatization und Stemming\n",
    "\n",
    "Wie in der Vorlesung besprochen, ist es bei der Verarbeitung natürlicher Sprache eine Herausforderung, dass es viele verschiedene Formen eines Wortes gibt, diese aber die gleiche Bedeutung haben. Zum Beispiel sind \"running\", \"ran\" und \"runs\" alles Formen des Verbs \"run\". Um diese Herausforderung zu bewältigen, verwenden wir Techniken wie **Lemmatisierung** und **Stemming**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "30918b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The          → the\n",
      "striped      → striped\n",
      "bats         → bat\n",
      "were         → be\n",
      "hanging      → hang\n",
      "on           → on\n",
      "their        → their\n",
      "feet         → foot\n",
      "and          → and\n",
      "ate          → eat\n",
      "best         → good\n",
      "fishes       → fish\n"
     ]
    }
   ],
   "source": [
    "# Beispieltext\n",
    "text = \"The striped bats were hanging on their feet and ate best fishes\"\n",
    "doc = nlp_en(text)\n",
    "\n",
    "# Lemmatization reduziert Wörter auf ihre Grundform (Lemma), unter Berücksichtigung von Wortart, Morphologie und Kontext.\n",
    "# Beispiel: \"ate\" → \"eat\", \"feet\" → \"foot\"\n",
    "for token in doc:\n",
    "    # Jedes token hat ein Attribut lemma_, das die Grundform des Wortes enthält.\n",
    "    print(f\"{token.text:12} → {token.lemma_}\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d2f216fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The          → the\n",
      "striped      → stripe\n",
      "bats         → bat\n",
      "were         → were\n",
      "hanging      → hang\n",
      "on           → on\n",
      "their        → their\n",
      "feet         → feet\n",
      "and          → and\n",
      "ate          → ate\n",
      "best         → best\n",
      "fishes       → fish\n"
     ]
    }
   ],
   "source": [
    "# NLTK bietet außerdem eine Schnittstelle für Stemming an. Wir verwenden den Porter Stemmer, einen der bekanntesten Stemmer (https://de.wikipedia.org/wiki/Porter-Stemmer-Algorithmus)\n",
    "# Stemming kürzt Wörter auf einen Wortstamm durch heuristische Regeln.\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "for word in text.split():\n",
    "    print(f\"{word:12} → {stemmer.stem(word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4957bd",
   "metadata": {},
   "source": [
    "### Beispiel 4: Reguläre Ausdrücke\n",
    "\n",
    "Reguläre Ausdrücke (RegEx) sind ein Werkzeug zur Textverarbeitung. Sie ermöglichen es uns, Muster in Texten zu erkennen und zu extrahieren. Hier sind einige Beispiele, wie wir RegEx in Python verwenden können, um spezifische Informationen aus einem Text zu extrahieren.\n",
    "\n",
    "Ich empfehle euch [RegExr.com](https://regexr.com/) zum Testen von regulären Ausdrücken. Außerdem wird dort ein guter Überblick über die RegEx-Syntax gegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "676e4f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speicher gefunden? True\n",
      "Gefundene Zahlen: ['45', '3', '100', '250', '1']\n",
      "Gefundene Speicherplatzangaben: ['GB', 'MB', 'MB', 'GB']\n",
      "Gefundene E-Mail-Adressen: ['mi@ur.de']\n",
      "Gültige E-Mail: mi@ur.de\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from email_validator import validate_email, EmailNotValidError\n",
    "\n",
    "text = \"Sie haben noch 45GB Speicher und Ihre E-Mail ist mi@ur.de und sie haben 3 Dateien mit 100MB, 250MB und 1GB.\"\n",
    "\n",
    "# Einfach: Wortsuche mit RegEx\n",
    "pattern_word = r\"\\bSpeicher\\b\"\n",
    "print(\"Speicher gefunden?\", bool(re.search(pattern_word, text)))\n",
    "\n",
    "# Zahlen extrahieren (RegEx)\n",
    "numbers = re.findall(r\"\\d+\", text)\n",
    "print(\"Gefundene Zahlen:\", numbers)\n",
    "\n",
    "# Angaben von Speicherplatz\n",
    "pattern_storage = r\"\\b\\d+\\s*(GB|MB|KB)\\b\"\n",
    "storage_matches = re.findall(pattern_storage, text)\n",
    "print(\"Gefundene Speicherplatzangaben:\", storage_matches)\n",
    "\n",
    "# E-Mail-Adresse mit RegEx validieren\n",
    "pattern_email = r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\"\n",
    "email_matches = re.findall(pattern_email, text)\n",
    "if email_matches:\n",
    "    print(\"Gefundene E-Mail-Adressen:\", email_matches)\n",
    "else:\n",
    "    print(\"Keine gültige E-Mail-Adresse gefunden.\")\n",
    "\n",
    "# E-Mail-Adresse mit externer Library validieren\n",
    "try:\n",
    "    result = validate_email(\"mi@ur.de\")  # findet man z. B. aus dem Text\n",
    "    print(\"Gültige E-Mail:\", result.email)\n",
    "except EmailNotValidError as e:\n",
    "    print(\"Ungültige E-Mail:\", e)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Erklärung warum externe Packages sinnvoll sind:\n",
    "#\n",
    "# Komplexe Muster wie E-Mail-Adressen oder internationale Telefonnummern\n",
    "# lassen sich nur sehr schwer mit einfachen regulären Ausdrücken korrekt\n",
    "# und vollständig erfassen.\n",
    "#\n",
    "# Externe Libraries wie `email_validator` und `phonenumbers` sind\n",
    "# speziell darauf ausgelegt, Standards und viele Sonderfälle korrekt zu behandeln.\n",
    "# Sie validieren nicht nur das Format, sondern z.B. bei E-Mails auch die\n",
    "# Domain, bei Telefonnummern Ländercodes und Nummernlängen.\n",
    "#\n",
    "# Das macht deinen Code robuster, wartbarer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c18332",
   "metadata": {},
   "source": [
    "### Beispiel 5: Embeddings und Vector Space Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8618b5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosinus-Ähnlichkeiten zwischen Wortpaaren:\n",
      "Dimensionen: (1, 96) (1, 96)\n",
      "'cat' vs. 'dog': 0.742\n",
      "Dimensionen: (1, 96) (1, 96)\n",
      "'car' vs. 'bike': 0.766\n",
      "Dimensionen: (1, 96) (1, 96)\n",
      "'cheesecake' vs. 'swimming': 0.299\n",
      "Dimensionen: (1, 96) (1, 96)\n",
      "'death' vs. 'google': 0.275\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import spacy\n",
    "\n",
    "# spaCy Modell laden (englisch, mit Vektoren)\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Wörter für Vergleich\n",
    "word_pairs = [\n",
    "    (\"cat\", \"dog\"), # Beispiel mit ähnlichen Wörtern\n",
    "    (\"car\", \"bike\"), # Beispiel mit ähnlichen Wörtern\n",
    "    (\"cheesecake\", \"swimming\"), # Beispiel mit unähnlichen Wörtern\n",
    "    (\"death\", \"google\") # Beispiel mit unähnlichen Wörtern\n",
    "]\n",
    "\n",
    "print(\"Cosinus-Ähnlichkeiten zwischen Wortpaaren:\")\n",
    "\n",
    "for w1, w2 in word_pairs:\n",
    "    # 1. Wandeln wir die Wörter in Vektoren.\n",
    "    # Dafür nutzen wir wieder das spaCy Modell und nutzen das Attribut .vector, das den Vektor/Embedding des Wortes zurückgibt.\n",
    "    # 2. Da cosine_similarity 2D-Arrays erwartet, müssen wir die Vektoren noch reshapen in 2D.\n",
    "    # cosine_similarity erwartet 2D-Arrays, da es prinzipiell auch für Matrizen-Vergleiche genutzt werden kann.\n",
    "    # .reshape(1, -1) sorgt dafür, dass die Vektoren die Form (1, n) bekommen, also eine Zeile und n Spalten. -1 bedeutet, dass die Anzahl der Spalten automatisch bestimmt wird.\n",
    "    vec1 = nlp(w1).vector.reshape(1, -1)\n",
    "    vec2 = nlp(w2).vector.reshape(1, -1)\n",
    "    print(\"Dimensionen:\", vec1.shape, vec2.shape)\n",
    "    \n",
    "    # 3. Berechnen wir die Cosinus-Ähnlichkeit mit sklearns cosine_similarity Funktion.\n",
    "    # [0][0] am Ende extrahiert den Skalarwert aus dem 2D-Array, das zurückgegeben wird.\n",
    "    cos_sim = cosine_similarity(vec1, vec2)[0][0]\n",
    "    print(f\"'{w1}' vs. '{w2}': {cos_sim:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d977ec",
   "metadata": {},
   "source": [
    "### 🐼 Einschub: Pandas Basics – Arbeiten mit `sentiment_texts.csv`\n",
    "\n",
    "Da wir für die nachfolgenden Beispiele eine CSV-Datei mit Textdaten verwenden, hier ein kurzer Einschub zu `pandas`.\n",
    "Gerade, wenn man mit Textdaten arbeitet, sind Daten oft in Tabellenform gespeichert. Ein gängiges Format ist CSV (Comma-Separated Values). In diesem Beispiel verwenden wir die Bibliothek `pandas`, um eine CSV-Datei zu laden und zu analysieren. \n",
    "\n",
    "Wir arbeiten mit der CSV-Datei `sentiment_texts.csv`, die Tweets umfasst und Annotationen für das Sentiment (positiv, negativ, neutral) enthält. Es handelt sich um Tweets, bei denen Accounts von Politikern der 2021 im Bundestag vertretenen Parteien von Twitter-Nutzern erwähnt wurden mit einem `@`-Zeichen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1559e73d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source_account</th>\n",
       "      <th>source_party</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1459496838629839104</td>\n",
       "      <td>Beatrix_vStorch</td>\n",
       "      <td>AFD</td>\n",
       "      <td>@LisaLies12 @Beatrix_vStorch Ich habe NICHT be...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1366816957236977920</td>\n",
       "      <td>cducsubt</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@ChristianHirte @CDU @dieLinke @cducsubt Gewis...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1437742901186993920</td>\n",
       "      <td>_FriedrichMerz</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@PeterBofinger @_FriedrichMerz @handelsblatt @...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1352576248560706048</td>\n",
       "      <td>SWagenknecht</td>\n",
       "      <td>LINKE</td>\n",
       "      <td>@KunzlerManuel @DnielSchmlhofer @Stefan_Hajek ...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1439569370217340928</td>\n",
       "      <td>Alice_Weidel</td>\n",
       "      <td>AFD</td>\n",
       "      <td>@cem_oezdemir @ABaerbock Dachte erst Sie meine...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1868</th>\n",
       "      <td>1411004773126509056</td>\n",
       "      <td>CDU</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@Ruebenhorst @MenschgbMensch @CDU ist das Euer...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1869</th>\n",
       "      <td>1436672257682779904</td>\n",
       "      <td>Markus_Soeder</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@dcremer_ @Markus_Soeder @CSU Ohne göttliche I...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1870</th>\n",
       "      <td>1464183001588376064</td>\n",
       "      <td>Karl_Lauterbach</td>\n",
       "      <td>SPD</td>\n",
       "      <td>@Karl_Lauterbach das sieht schlecht aus. Da hi...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1871</th>\n",
       "      <td>1389635614975348992</td>\n",
       "      <td>CDU</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@MatthiasRieger3 @EskenSaskia @MEtzold @CDU ja...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1872</th>\n",
       "      <td>1400994841396456960</td>\n",
       "      <td>Markus_Soeder</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@GerdMll42564793 @Markus_Soeder Bestimmt</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1873 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id   source_account source_party  \\\n",
       "0     1459496838629839104  Beatrix_vStorch          AFD   \n",
       "1     1366816957236977920         cducsubt      CDU_CSU   \n",
       "2     1437742901186993920   _FriedrichMerz      CDU_CSU   \n",
       "3     1352576248560706048     SWagenknecht        LINKE   \n",
       "4     1439569370217340928     Alice_Weidel          AFD   \n",
       "...                   ...              ...          ...   \n",
       "1868  1411004773126509056              CDU      CDU_CSU   \n",
       "1869  1436672257682779904    Markus_Soeder      CDU_CSU   \n",
       "1870  1464183001588376064  Karl_Lauterbach          SPD   \n",
       "1871  1389635614975348992              CDU      CDU_CSU   \n",
       "1872  1400994841396456960    Markus_Soeder      CDU_CSU   \n",
       "\n",
       "                                                  tweet sentiment  \n",
       "0     @LisaLies12 @Beatrix_vStorch Ich habe NICHT be...  NEGATIVE  \n",
       "1     @ChristianHirte @CDU @dieLinke @cducsubt Gewis...   NEUTRAL  \n",
       "2     @PeterBofinger @_FriedrichMerz @handelsblatt @...   NEUTRAL  \n",
       "3     @KunzlerManuel @DnielSchmlhofer @Stefan_Hajek ...   NEUTRAL  \n",
       "4     @cem_oezdemir @ABaerbock Dachte erst Sie meine...   NEUTRAL  \n",
       "...                                                 ...       ...  \n",
       "1868  @Ruebenhorst @MenschgbMensch @CDU ist das Euer...  NEGATIVE  \n",
       "1869  @dcremer_ @Markus_Soeder @CSU Ohne göttliche I...   NEUTRAL  \n",
       "1870  @Karl_Lauterbach das sieht schlecht aus. Da hi...  NEGATIVE  \n",
       "1871  @MatthiasRieger3 @EskenSaskia @MEtzold @CDU ja...   NEUTRAL  \n",
       "1872           @GerdMll42564793 @Markus_Soeder Bestimmt   NEUTRAL  \n",
       "\n",
       "[1873 rows x 5 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importieren der Pandas-Bibliothek\n",
    "import pandas as pd\n",
    "\n",
    "# 1️⃣ CSV-Datei laden: Mit pd.read_csv() können wir Daten aus einer CSV-Datei in ein DataFrame laden.\n",
    "df = pd.read_csv(\"tweets.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0394612f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source_account</th>\n",
       "      <th>source_party</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1459496838629839104</td>\n",
       "      <td>Beatrix_vStorch</td>\n",
       "      <td>AFD</td>\n",
       "      <td>@LisaLies12 @Beatrix_vStorch Ich habe NICHT be...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1366816957236977920</td>\n",
       "      <td>cducsubt</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@ChristianHirte @CDU @dieLinke @cducsubt Gewis...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1437742901186993920</td>\n",
       "      <td>_FriedrichMerz</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@PeterBofinger @_FriedrichMerz @handelsblatt @...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1352576248560706048</td>\n",
       "      <td>SWagenknecht</td>\n",
       "      <td>LINKE</td>\n",
       "      <td>@KunzlerManuel @DnielSchmlhofer @Stefan_Hajek ...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1439569370217340928</td>\n",
       "      <td>Alice_Weidel</td>\n",
       "      <td>AFD</td>\n",
       "      <td>@cem_oezdemir @ABaerbock Dachte erst Sie meine...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id   source_account source_party  \\\n",
       "0  1459496838629839104  Beatrix_vStorch          AFD   \n",
       "1  1366816957236977920         cducsubt      CDU_CSU   \n",
       "2  1437742901186993920   _FriedrichMerz      CDU_CSU   \n",
       "3  1352576248560706048     SWagenknecht        LINKE   \n",
       "4  1439569370217340928     Alice_Weidel          AFD   \n",
       "\n",
       "                                               tweet sentiment  \n",
       "0  @LisaLies12 @Beatrix_vStorch Ich habe NICHT be...  NEGATIVE  \n",
       "1  @ChristianHirte @CDU @dieLinke @cducsubt Gewis...   NEUTRAL  \n",
       "2  @PeterBofinger @_FriedrichMerz @handelsblatt @...   NEUTRAL  \n",
       "3  @KunzlerManuel @DnielSchmlhofer @Stefan_Hajek ...   NEUTRAL  \n",
       "4  @cem_oezdemir @ABaerbock Dachte erst Sie meine...   NEUTRAL  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mit df.head() können wir die ersten 5 Zeilen des DataFrames bequem anzeigen.\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4fc567b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        AFD\n",
       "1    CDU_CSU\n",
       "2    CDU_CSU\n",
       "3      LINKE\n",
       "4        AFD\n",
       "5        FDP\n",
       "6        SPD\n",
       "7    CDU_CSU\n",
       "8        SPD\n",
       "9      LINKE\n",
       "Name: source_party, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wir können auch die Werte einer bestimmten Spalte auswählen, z.B. \"source_party\":\n",
    "df[\"source_party\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "abd0710a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source_account</th>\n",
       "      <th>source_party</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1347612879810425088</td>\n",
       "      <td>n_roettgen</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@n_roettgen auch mit Blick auf andere Aspekte ...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1471842111062429952</td>\n",
       "      <td>_FriedrichMerz</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@ToshimaDE @CDU @_FriedrichMerz Wie? Sitzt die...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1411032162929872896</td>\n",
       "      <td>ArminLaschet</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@steps0815 @Arndt_Klocke @MaAhl5 @Oliver_Krisc...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1382766358790868992</td>\n",
       "      <td>Karl_Lauterbach</td>\n",
       "      <td>SPD</td>\n",
       "      <td>@Karl_Lauterbach Ach na endlich!! Da kann ich ...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1346511916173304064</td>\n",
       "      <td>_FriedrichMerz</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@BorisNMoellers @_FriedrichMerz Ich übrigens a...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1832</th>\n",
       "      <td>1473352625554963968</td>\n",
       "      <td>fdpbt</td>\n",
       "      <td>FDP</td>\n",
       "      <td>@Patrickweedmob @spdbt @GrueneBundestag @fdpbt...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841</th>\n",
       "      <td>1355126553882063104</td>\n",
       "      <td>Markus_Soeder</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@1xKlaudius @Markus_Soeder Mit Scheuer im Wahl...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1847</th>\n",
       "      <td>1411631133259973120</td>\n",
       "      <td>ArminLaschet</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@RadtkeMdEP 1.) Ein #guterplan #wegenmorgen wä...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1850</th>\n",
       "      <td>1352647722801757952</td>\n",
       "      <td>ArminLaschet</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>#Herzlichen #Glückwunsch an alle #nun #offizie...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867</th>\n",
       "      <td>1408741244927365120</td>\n",
       "      <td>Alice_Weidel</td>\n",
       "      <td>AFD</td>\n",
       "      <td>@ASB_Anwohner @Alice_Weidel @Afd_emskirchen Bu...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id   source_account source_party  \\\n",
       "7     1347612879810425088       n_roettgen      CDU_CSU   \n",
       "10    1471842111062429952   _FriedrichMerz      CDU_CSU   \n",
       "25    1411032162929872896     ArminLaschet      CDU_CSU   \n",
       "34    1382766358790868992  Karl_Lauterbach          SPD   \n",
       "43    1346511916173304064   _FriedrichMerz      CDU_CSU   \n",
       "...                   ...              ...          ...   \n",
       "1832  1473352625554963968            fdpbt          FDP   \n",
       "1841  1355126553882063104    Markus_Soeder      CDU_CSU   \n",
       "1847  1411631133259973120     ArminLaschet      CDU_CSU   \n",
       "1850  1352647722801757952     ArminLaschet      CDU_CSU   \n",
       "1867  1408741244927365120     Alice_Weidel          AFD   \n",
       "\n",
       "                                                  tweet sentiment  \n",
       "7     @n_roettgen auch mit Blick auf andere Aspekte ...  POSITIVE  \n",
       "10    @ToshimaDE @CDU @_FriedrichMerz Wie? Sitzt die...  POSITIVE  \n",
       "25    @steps0815 @Arndt_Klocke @MaAhl5 @Oliver_Krisc...  POSITIVE  \n",
       "34    @Karl_Lauterbach Ach na endlich!! Da kann ich ...  POSITIVE  \n",
       "43    @BorisNMoellers @_FriedrichMerz Ich übrigens a...  POSITIVE  \n",
       "...                                                 ...       ...  \n",
       "1832  @Patrickweedmob @spdbt @GrueneBundestag @fdpbt...  POSITIVE  \n",
       "1841  @1xKlaudius @Markus_Soeder Mit Scheuer im Wahl...  POSITIVE  \n",
       "1847  @RadtkeMdEP 1.) Ein #guterplan #wegenmorgen wä...  POSITIVE  \n",
       "1850  #Herzlichen #Glückwunsch an alle #nun #offizie...  POSITIVE  \n",
       "1867  @ASB_Anwohner @Alice_Weidel @Afd_emskirchen Bu...  POSITIVE  \n",
       "\n",
       "[120 rows x 5 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Filtermöglichkeiten: Mit df[df[\"sentiment\"] == \"POSITIVE\"] können wir nur die Zeilen mit positivem Sentiment anzeigen. \n",
    "\n",
    "df[\"sentiment\"] wählt die Spalte sentiment aus dem DataFrame df aus.\n",
    "Ergebnis: eine Series – also eine eindimensionale, beschriftete Datenstruktur.\n",
    "'''\n",
    "df[df[\"sentiment\"] == \"POSITIVE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "022a2ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "NEGATIVE    976\n",
       "NEUTRAL     777\n",
       "POSITIVE    120\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mit .value_counts() können wir die Häufigkeit der einzigartigen Werte in der Spalte \"sentiment\" anzeigen.\n",
    "# Wir sehen beim Output, dass die Stimmung nicht ausgewogen ist: Es gibt deutlich mehr negative als positive Tweets, wobei fast so viele neutrale Tweets wie positive Tweets vorhanden sind.\n",
    "df[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fd2d8128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       @LISALIES12 @BEATRIX_VSTORCH ICH HABE NICHT BE...\n",
       "1       @CHRISTIANHIRTE @CDU @DIELINKE @CDUCSUBT GEWIS...\n",
       "2       @PETERBOFINGER @_FRIEDRICHMERZ @HANDELSBLATT @...\n",
       "3       @KUNZLERMANUEL @DNIELSCHMLHOFER @STEFAN_HAJEK ...\n",
       "4       @CEM_OEZDEMIR @ABAERBOCK DACHTE ERST SIE MEINE...\n",
       "                              ...                        \n",
       "1868    @RUEBENHORST @MENSCHGBMENSCH @CDU IST DAS EUER...\n",
       "1869    @DCREMER_ @MARKUS_SOEDER @CSU OHNE GÖTTLICHE I...\n",
       "1870    @KARL_LAUTERBACH DAS SIEHT SCHLECHT AUS. DA HI...\n",
       "1871    @MATTHIASRIEGER3 @ESKENSASKIA @METZOLD @CDU JA...\n",
       "1872          @GERDMLL42564793 @MARKUS_SOEDER BESTIMMT!!!\n",
       "Name: shouted, Length: 1873, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mit .apply() können wir eine Funktion auf jede Zeile oder Spalte eines DataFrames anwenden.\n",
    "def shout(text):\n",
    "    return text.upper() + \"!!!\"\n",
    "\n",
    "df[\"shouted\"] = df[\"tweet\"].apply(shout)\n",
    "df[\"shouted\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "23bb03c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source_account</th>\n",
       "      <th>source_party</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>shouted</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>1389713588659625984</td>\n",
       "      <td>CDU</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>LG an @CDU und @CSU</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>LG AN @CDU UND @CSU!!!</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319</th>\n",
       "      <td>1377675573435191040</td>\n",
       "      <td>Die_Gruenen</td>\n",
       "      <td>GRUENE</td>\n",
       "      <td>@Die_Gruenen so schwarz.</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>@DIE_GRUENEN SO SCHWARZ.!!!</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1432400536498810880</td>\n",
       "      <td>CDU</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@CDU Was für ein Unsinn.</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>@CDU WAS FÜR EIN UNSINN.!!!</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>1424771876837024000</td>\n",
       "      <td>Die_Gruenen</td>\n",
       "      <td>GRUENE</td>\n",
       "      <td>@Die_Gruenen Zeit wirds!</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>@DIE_GRUENEN ZEIT WIRDS!!!!</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1409483299207122944</td>\n",
       "      <td>Karl_Lauterbach</td>\n",
       "      <td>SPD</td>\n",
       "      <td>@Karl_Lauterbach Ab wann?</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>@KARL_LAUTERBACH AB WANN?!!!</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>1389137005326618880</td>\n",
       "      <td>SWagenknecht</td>\n",
       "      <td>LINKE</td>\n",
       "      <td>@StimmederVernu9 @DerEchteGrubert @AlfredNeuma...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>@STIMMEDERVERNU9 @DERECHTEGRUBERT @ALFREDNEUMA...</td>\n",
       "      <td>523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>1399462761541911040</td>\n",
       "      <td>c_lindner</td>\n",
       "      <td>FDP</td>\n",
       "      <td>@chris_pyak @holgerkopp @HLiepelt @MartinWalth...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>@CHRIS_PYAK @HOLGERKOPP @HLIEPELT @MARTINWALTH...</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>1442227712869940992</td>\n",
       "      <td>cem_oezdemir</td>\n",
       "      <td>GRUENE</td>\n",
       "      <td>@GGahnt @CartmanTB2 @Andrew1023054 @NurZoabe @...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>@GGAHNT @CARTMANTB2 @ANDREW1023054 @NURZOABE @...</td>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>1345808822544326912</td>\n",
       "      <td>CDU</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@cat_spass @Abtreibpranger @Peacecakex @nelson...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>@CAT_SPASS @ABTREIBPRANGER @PEACECAKEX @NELSON...</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>1376307200797344000</td>\n",
       "      <td>hubertus_heil</td>\n",
       "      <td>SPD</td>\n",
       "      <td>@Detlef66138495 @BVG_Kampagne @goethe_jw @4tti...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>@DETLEF66138495 @BVG_KAMPAGNE @GOETHE_JW @4TTI...</td>\n",
       "      <td>746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1873 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id   source_account source_party  \\\n",
       "1724  1389713588659625984              CDU      CDU_CSU   \n",
       "1319  1377675573435191040      Die_Gruenen       GRUENE   \n",
       "32    1432400536498810880              CDU      CDU_CSU   \n",
       "351   1424771876837024000      Die_Gruenen       GRUENE   \n",
       "189   1409483299207122944  Karl_Lauterbach          SPD   \n",
       "...                   ...              ...          ...   \n",
       "575   1389137005326618880     SWagenknecht        LINKE   \n",
       "1657  1399462761541911040        c_lindner          FDP   \n",
       "635   1442227712869940992     cem_oezdemir       GRUENE   \n",
       "804   1345808822544326912              CDU      CDU_CSU   \n",
       "1361  1376307200797344000    hubertus_heil          SPD   \n",
       "\n",
       "                                                  tweet sentiment  \\\n",
       "1724                                LG an @CDU und @CSU  POSITIVE   \n",
       "1319                           @Die_Gruenen so schwarz.   NEUTRAL   \n",
       "32                             @CDU Was für ein Unsinn.  NEGATIVE   \n",
       "351                            @Die_Gruenen Zeit wirds!   NEUTRAL   \n",
       "189                           @Karl_Lauterbach Ab wann?   NEUTRAL   \n",
       "...                                                 ...       ...   \n",
       "575   @StimmederVernu9 @DerEchteGrubert @AlfredNeuma...  NEGATIVE   \n",
       "1657  @chris_pyak @holgerkopp @HLiepelt @MartinWalth...  NEGATIVE   \n",
       "635   @GGahnt @CartmanTB2 @Andrew1023054 @NurZoabe @...  NEGATIVE   \n",
       "804   @cat_spass @Abtreibpranger @Peacecakex @nelson...   NEUTRAL   \n",
       "1361  @Detlef66138495 @BVG_Kampagne @goethe_jw @4tti...   NEUTRAL   \n",
       "\n",
       "                                                shouted  text_length  \n",
       "1724                             LG AN @CDU UND @CSU!!!           19  \n",
       "1319                        @DIE_GRUENEN SO SCHWARZ.!!!           24  \n",
       "32                          @CDU WAS FÜR EIN UNSINN.!!!           24  \n",
       "351                         @DIE_GRUENEN ZEIT WIRDS!!!!           24  \n",
       "189                        @KARL_LAUTERBACH AB WANN?!!!           25  \n",
       "...                                                 ...          ...  \n",
       "575   @STIMMEDERVERNU9 @DERECHTEGRUBERT @ALFREDNEUMA...          523  \n",
       "1657  @CHRIS_PYAK @HOLGERKOPP @HLIEPELT @MARTINWALTH...          566  \n",
       "635   @GGAHNT @CARTMANTB2 @ANDREW1023054 @NURZOABE @...          570  \n",
       "804   @CAT_SPASS @ABTREIBPRANGER @PEACECAKEX @NELSON...          655  \n",
       "1361  @DETLEF66138495 @BVG_KAMPAGNE @GOETHE_JW @4TTI...          746  \n",
       "\n",
       "[1873 rows x 7 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mit .sort_values() können wir den DataFrame nach einer bestimmten Spalte sortieren.\n",
    "def text_length(text):\n",
    "    return len(text)\n",
    "\n",
    "df[\"text_length\"] = df[\"tweet\"].apply(text_length)\n",
    "df = df.sort_values(by=\"text_length\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c74524fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "NEGATIVE    26.861680\n",
       "NEUTRAL     19.772201\n",
       "POSITIVE    19.016667\n",
       "Name: word_count, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mit .mean() können wir den Durchschnitt einer Spalte berechnen.\n",
    "def word_count(text):\n",
    "    return len(text.split())\n",
    "\n",
    "df[\"word_count\"] = df[\"tweet\"].apply(word_count)\n",
    "\n",
    "# Mit .groupby() können wir den DataFrame nach einer bestimmten Spalte gruppieren.\n",
    "# df.groupby(\"sentiment\")[\"word_count\"] gibt uns eine SeriesGroupBy-Objekt zurück, das die Wortanzahl für jede Sentiment-Kategorie gruppiert.\n",
    "# Mit .mean() berechnen wir den Durchschnitt der Wortanzahl für jede Sentiment-Kategorie.\n",
    "df.groupby(\"sentiment\")[\"word_count\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b0c508ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source_account</th>\n",
       "      <th>source_party</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>shouted</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>1464916983108062976</td>\n",
       "      <td>MiKellner</td>\n",
       "      <td>GRUENE</td>\n",
       "      <td>@MonikaHerrmann1 @MiKellner @ABaerbock Wieder ...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>@MONIKAHERRMANN1 @MIKELLNER @ABAERBOCK WIEDER ...</td>\n",
       "      <td>61</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>1363624003278151936</td>\n",
       "      <td>PaulZiemiak</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@PaulZiemiak @BerlinReporter Keine Aufregung. ...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>@PAULZIEMIAK @BERLINREPORTER KEINE AUFREGUNG. ...</td>\n",
       "      <td>98</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1781</th>\n",
       "      <td>1362817043549069056</td>\n",
       "      <td>CDU</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@GirkeHanjo @BerlinReporter @MIT_bund @christo...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>@GIRKEHANJO @BERLINREPORTER @MIT_BUND @CHRISTO...</td>\n",
       "      <td>107</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id source_account source_party  \\\n",
       "872   1464916983108062976      MiKellner       GRUENE   \n",
       "1725  1363624003278151936    PaulZiemiak      CDU_CSU   \n",
       "1781  1362817043549069056            CDU      CDU_CSU   \n",
       "\n",
       "                                                  tweet sentiment  \\\n",
       "872   @MonikaHerrmann1 @MiKellner @ABaerbock Wieder ...   NEUTRAL   \n",
       "1725  @PaulZiemiak @BerlinReporter Keine Aufregung. ...  NEGATIVE   \n",
       "1781  @GirkeHanjo @BerlinReporter @MIT_bund @christo...  POSITIVE   \n",
       "\n",
       "                                                shouted  text_length  \\\n",
       "872   @MONIKAHERRMANN1 @MIKELLNER @ABAERBOCK WIEDER ...           61   \n",
       "1725  @PAULZIEMIAK @BERLINREPORTER KEINE AUFREGUNG. ...           98   \n",
       "1781  @GIRKEHANJO @BERLINREPORTER @MIT_BUND @CHRISTO...          107   \n",
       "\n",
       "      word_count  \n",
       "872            7  \n",
       "1725          10  \n",
       "1781          13  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def has_berlin(text):\n",
    "    return \"Berlin\" in text\n",
    "\n",
    "# Zeilen filtern\n",
    "df_berlin = df[df[\"tweet\"].apply(has_berlin)]\n",
    "df_berlin.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2394153b",
   "metadata": {},
   "source": [
    "### 🔢 Einschub: NumPy Basics – Arbeiten mit Arrays\n",
    "\n",
    "NumPy (Numerical Python) ist die grundlegende Bibliothek für wissenschaftliches Rechnen in Python. Es bietet ein mächtiges N-dimensionales Array-Objekt und Funktionen für deren Bearbeitung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f2006801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy Array: [1 2 3 4 5]\n",
      "Typ: <class 'numpy.ndarray'>\n",
      "Shape (Form): (5,)\n",
      "Data Type: int64\n"
     ]
    }
   ],
   "source": [
    "# Importieren der NumPy-Bibliothek\n",
    "import numpy as np\n",
    "\n",
    "# 1️⃣ Arrays erstellen: Mit np.array() können wir Listen in NumPy Arrays umwandeln.\n",
    "numbers = [1, 2, 3, 4, 5]\n",
    "arr = np.array(numbers)\n",
    "print(\"NumPy Array:\", arr)\n",
    "print(\"Typ:\", type(arr))\n",
    "print(\"Shape (Form):\", arr.shape)\n",
    "print(\"Data Type:\", arr.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2ac6faee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D Array:\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "Shape: (3, 3)\n",
      "\n",
      "Zeros Array:\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "\n",
      "Ones Array:\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# 2️⃣ Zweidimensionale Arrays: Mit np.array() können wir auch 2D-Arrays (Matrizen) erstellen.\n",
    "matrix = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(\"2D Array:\")\n",
    "print(matrix)\n",
    "print(\"Shape:\", matrix.shape)  # (3, 3) bedeutet 3 Zeilen, 3 Spalten\n",
    "\n",
    "# Arrays mit bestimmten Werten erstellen\n",
    "zeros = np.zeros((2, 3))  # 2x3 Array mit Nullen\n",
    "ones = np.ones((2, 3))    # 2x3 Array mit Einsen\n",
    "print(\"\\nZeros Array:\")\n",
    "print(zeros)\n",
    "print(\"\\nOnes Array:\")\n",
    "print(ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d3e17e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Array: [10 20 30 40 50]\n",
      "Erstes Element: 10\n",
      "Letztes Element: 50\n",
      "Slice [1:4]: [20 30 40]\n",
      "\n",
      "2D Array:\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "Element [0,0]: 1\n",
      "Element [1,2]: 6\n",
      "Erste Zeile: [1 2 3]\n",
      "Erste Spalte: [1 4 7]\n"
     ]
    }
   ],
   "source": [
    "# 3️⃣ Array-Indexierung und Slicing: Ähnlich wie bei Python-Listen\n",
    "arr = np.array([10, 20, 30, 40, 50])\n",
    "print(\"Original Array:\", arr)\n",
    "print(\"Erstes Element:\", arr[0])      # Index 0\n",
    "print(\"Letztes Element:\", arr[-1])    # Index -1\n",
    "print(\"Slice [1:4]:\", arr[1:4])       # Elemente von Index 1 bis 3\n",
    "\n",
    "# 2D Array Indexierung\n",
    "matrix = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(\"\\n2D Array:\")\n",
    "print(matrix)\n",
    "print(\"Element [0,0]:\", matrix[0, 0])  # Erste Zeile, erste Spalte\n",
    "print(\"Element [1,2]:\", matrix[1, 2])  # Zweite Zeile, dritte Spalte\n",
    "print(\"Erste Zeile:\", matrix[0, :])    # Ganze erste Zeile\n",
    "print(\"Erste Spalte:\", matrix[:, 0])   # Ganze erste Spalte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "534bf291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array 1: [1 2 3 4]\n",
      "Array 2: [10 20 30 40]\n",
      "Addition: [11 22 33 44]\n",
      "Subtraktion: [ -9 -18 -27 -36]\n",
      "Multiplikation: [ 10  40  90 160]\n",
      "Division: [10. 10. 10. 10.]\n",
      "\n",
      "Array * 2: [2 4 6 8]\n",
      "Array + 10: [11 12 13 14]\n"
     ]
    }
   ],
   "source": [
    "# 4️⃣ Mathematische Operationen: NumPy macht Berechnungen sehr effizient\n",
    "arr1 = np.array([1, 2, 3, 4])\n",
    "arr2 = np.array([10, 20, 30, 40])\n",
    "\n",
    "print(\"Array 1:\", arr1)\n",
    "print(\"Array 2:\", arr2)\n",
    "\n",
    "# Element-weise Operationen\n",
    "print(\"Addition:\", arr1 + arr2)\n",
    "print(\"Subtraktion:\", arr1 - arr2)\n",
    "print(\"Multiplikation:\", arr1 * arr2)\n",
    "print(\"Division:\", arr2 / arr1)\n",
    "\n",
    "# Operationen mit Skalaren\n",
    "print(\"\\nArray * 2:\", arr1 * 2)\n",
    "print(\"Array + 10:\", arr1 + 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0c0db0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: [1 5 2 8 3 7 4 6]\n",
      "Summe: 36\n",
      "Mittelwert: 4.5\n",
      "Median: 4.5\n",
      "Standardabweichung: 2.29128784747792\n",
      "Minimum: 1\n",
      "Maximum: 8\n",
      "Index des Minimums: 0\n",
      "Index des Maximums: 3\n",
      "Sortiert: [1 2 3 4 5 6 7 8]\n"
     ]
    }
   ],
   "source": [
    "# 5️⃣ Nützliche NumPy-Funktionen für statistische Berechnungen\n",
    "data = np.array([1, 5, 2, 8, 3, 7, 4, 6])\n",
    "print(\"Data:\", data)\n",
    "\n",
    "print(\"Summe:\", np.sum(data))\n",
    "print(\"Mittelwert:\", np.mean(data))\n",
    "print(\"Median:\", np.median(data))\n",
    "print(\"Standardabweichung:\", np.std(data))\n",
    "print(\"Minimum:\", np.min(data))\n",
    "print(\"Maximum:\", np.max(data))\n",
    "\n",
    "# Index des Minimums/Maximums\n",
    "print(\"Index des Minimums:\", np.argmin(data))\n",
    "print(\"Index des Maximums:\", np.argmax(data))\n",
    "\n",
    "# Array sortieren\n",
    "print(\"Sortiert:\", np.sort(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "78db9189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Array: [1 2 3 4 5 6]\n",
      "Shape: (6,)\n",
      "\n",
      "Reshape zu 2x3:\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "Shape: (2, 3)\n",
      "\n",
      "Reshape zu 3x2:\n",
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n",
      "\n",
      "Auto-Reshape (-1, 2):\n",
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n",
      "Shape: (3, 2)\n"
     ]
    }
   ],
   "source": [
    "# 6️⃣ Array-Reshaping: Die Form von Arrays ändern\n",
    "arr = np.array([1, 2, 3, 4, 5, 6])\n",
    "print(\"Original Array:\", arr)\n",
    "print(\"Shape:\", arr.shape)\n",
    "\n",
    "# Zu 2x3 Matrix umformen\n",
    "reshaped = arr.reshape(2, 3)\n",
    "print(\"\\nReshape zu 2x3:\")\n",
    "print(reshaped)\n",
    "print(\"Shape:\", reshaped.shape)\n",
    "\n",
    "# Zu 3x2 Matrix umformen\n",
    "reshaped2 = arr.reshape(3, 2)\n",
    "print(\"\\nReshape zu 3x2:\")\n",
    "print(reshaped2)\n",
    "\n",
    "# Automatische Dimensionsbestimmung mit -1\n",
    "auto_reshape = arr.reshape(-1, 2)  # -1 bedeutet: bestimme automatisch\n",
    "print(\"\\nAuto-Reshape (-1, 2):\")\n",
    "print(auto_reshape)\n",
    "print(\"Shape:\", auto_reshape.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29931ef",
   "metadata": {},
   "source": [
    "## 👩🏼‍💻 Aufgaben "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "92b7df56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Aufgabe: Gebe für die ersten 3 Tweets die Tokens als List mit print() aus.\n",
    "\n",
    "# Hier Code einfügen...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c027790",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung anzeigen</b></summary>\n",
    "\n",
    "```python\n",
    "for tweet in df[\"tweet\"].head(3):\n",
    "    tokens = tweet.split(\" \")\n",
    "    print(tokens)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f20450ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Aufgabe: Geben sie für die ersten 3 Tweets die POS-Tags als List mit print() aus.\n",
    "# Beispiel: \"Ich habe Lust auf Pizza.\" -> [(\"Ich\", \"PRON\"), (\"habe\", \"VERB\"), (\"Lust\", \"NOUN\"), (\"auf\", \"ADP\"), (\"Pizza\", \"NOUN\")]\n",
    "import spacy\n",
    "nlp = spacy.load(\"de_core_news_sm\")  # Deutsches Modell laden\n",
    "\n",
    "# Hier Code einfügen...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4599355a",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung anzeigen</b></summary>\n",
    "\n",
    "```python\n",
    "for tweet in df[\"tweet\"].head(3):\n",
    "    doc = nlp(tweet)\n",
    "    pos_tags = [(token.text, token.pos_) for token in doc]\n",
    "    print(pos_tags)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e4a29c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Aufgabe: Geben sie für die ersten 3 Tweets die Lemmas als List mit print() aus.\n",
    "# Beispiel: \"Ich habe Lust auf Pizza.\" -> [(\"Ich\", \"ich\"), (\"habe\", \"haben\"), (\"Lust\", \"Lust\"), (\"auf\", \"auf\"), (\"Pizza\", \"Pizza\")]\n",
    "\n",
    "# Hier Code einfügen...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9fd4a4",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung anzeigen</b></summary>\n",
    "\n",
    "```python\n",
    "for tweet in df[\"tweet\"].head(3):\n",
    "    doc = nlp(tweet)\n",
    "    lemmas = [(token.text, token.lemma_) for token in doc]\n",
    "    print(lemmas)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3cce81dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# 4.1 Aufgabe: Erstellen sie einen regulären Ausdruck, der alle Hashtags in einem Tweet findet. Nutzen Sie gerne ein Cheatsheet: https://web.mit.edu/hackl/www/lab/turkshop/slides/regex-cheatsheet.pdf\n",
    "text = \"Loving the new features in #Python3! #programming #NLP is fun. Visit us at https://example.com #AI\"\n",
    "\n",
    "# Ihre Lösung hier..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e71a8d6",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung anzeigen</b></summary>\n",
    "\n",
    "```python\n",
    "pattern_hashtag = r\"#\\w+\"\n",
    "hashtags = re.findall(pattern_hashtag, text)\n",
    "print(\"Gefundene Hashtags:\", hashtags)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "99b8a073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 Aufgabe: Der Vorname Maier. Erstellen sie einen regulären Ausdruck, der alle möglichen Schreibweisen des Vornamens \"Maier\" findet, z.B. \"Maier\", \"Meyer\", \"Meier\", \"Mayer\", \"Mayr\".\n",
    "text = \"Meyer, Maier, Meier, Mair, Meir, Mayr, Meyr\"\n",
    "\n",
    "# Ihre Lösung hier..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0a7261",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung anzeigen</b></summary>\n",
    "\n",
    "```python\n",
    "pattern_maier_variants = r\"\\bM[ae][iy]?[ae]?[iy]?r\\b\"\n",
    "maier_variants = re.findall(pattern_maier_variants, text)\n",
    "print(\"Gefundene Varianten von 'Maier':\", maier_variants)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "308dc4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 Wie lassen sich Datumsangaben in einem regulären Ausdruck zusammenfassen?\n",
    "text = \"1. Januar 1901 29. Februar 2099, 02. März 1234, 1. Oktober 2015\"\n",
    "\n",
    "# Ihre Lösung hier..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643ae4e7",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung anzeigen</b></summary>\n",
    "\n",
    "```python\n",
    "pattern_dates = r\"\\b\\d{1,2}\\. (?:Januar|Februar|März|April|Mai|Juni|Juli|August|September|Oktober|November|Dezember) \\d{4}\\b\"\n",
    "dates = re.findall(pattern_dates, text)\n",
    "print(\"Gefundene Datumsangaben:\", dates)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_nils_hellwig",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
