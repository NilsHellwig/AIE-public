{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "336666e5",
   "metadata": {},
   "source": [
    "# Einf√ºhrung in NLP f√ºr Python\n",
    "\n",
    "Dieses Notebook behandelt grundlegende Konzepte des NLP (Natural Language Processing) wie Tokenisierung, Stemming und Lemmatisierung. Diese Techniken sind entscheidend f√ºr die Verarbeitung nat√ºrlicher Sprache.\n",
    "\n",
    "Quelle: https://web.stanford.edu/~jurafsky/slp3/ed3book.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "aabe9761",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "# F√ºr dieses Projekt m√ºssen wir zun√§chst die folgenden Pakete installieren:\n",
    "!pip install spacy\n",
    "!pip install nltk\n",
    "!python -m spacy download de_core_news_sm\n",
    "!python -m spacy download en_core_web_sm\n",
    "!pip install email-validator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1d5aff",
   "metadata": {},
   "source": [
    "## Beispiele\n",
    "\n",
    "### Beispiel 1: Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7191ca",
   "metadata": {},
   "source": [
    "Wir haben bereits im Python-Notebook gelernt, wie wir Texte splitten k√∂nnen. Wiederholen wir das kurz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e45b54d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split nach Leerzeichen: ['Hallo', 'Welt!', 'Python', 'ist', 'eine', 'ziemlich', 'coole', 'Programmiersprache.', 'Ich', 'hoffe,', 'Sie', 'm√∂gen', 'sie', 'auch!']\n"
     ]
    }
   ],
   "source": [
    "text = \"Hallo Welt! Python ist eine ziemlich coole Programmiersprache. Ich hoffe, Sie m√∂gen sie auch!\"\n",
    "tokens_spaces = text.split()\n",
    "print(\"Split nach Leerzeichen:\", tokens_spaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acba1bab",
   "metadata": {},
   "source": [
    "Wie wir in der Ausgabe sehen, trennt die einfache `split()`-Methode W√∂rter, aber sie behandelt Satzzeichen nicht korrekt. Zum Beispiel wird \"Welt!\" als ein Token betrachtet, was in vielen NLP-Anwendungen nicht ideal ist. Daher verwenden wir spezialisierte **Tokenizer**, um dieses Problem zu l√∂sen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "35e439d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/nils_hellwig/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wir laden NLTK, eine Bibliothek f√ºr nat√ºrliche Sprachverarbeitung\n",
    "import nltk\n",
    "\n",
    "# Punkt-Tokenizer herunterladen, ein Package, dass wir f√ºr die Tokenisierung ben√∂tigen. Punkt enth√§lt Regeln f√ºr die Tokenisierung von W√∂rtern und S√§tzen.\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a42c3807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK Word Tokenize: ['Hallo', 'Welt', '!', 'Python', 'ist', 'eine', 'ziemlich', 'coole', 'Programmiersprache', '.', 'Ich', 'hoffe', ',', 'Sie', 'm√∂gen', 'sie', 'auch', '!']\n"
     ]
    }
   ],
   "source": [
    "# Um die Tokenisierung durchzuf√ºhren, importieren wir die word_tokenize-Funktion aus dem nltk.tokenize Modul.\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Wir verwenden die word_tokenize-Funktion, um den Text in W√∂rter zu zerlegen.\n",
    "tokens_nltk = word_tokenize(text)\n",
    "\n",
    "# Ausgabe der tokenisierten W√∂rter\n",
    "print(\"NLTK Word Tokenize:\", tokens_nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2694fc52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Satz-Tokenisierung: ['Hallo Welt!', 'Dies ist ein Test.', 'Hier ist noch ein Satz.']\n"
     ]
    }
   ],
   "source": [
    "# NLTK bietet auch eine Funktion zur Satz-Tokenisierung an.\n",
    "sentences = nltk.sent_tokenize(\"Hallo Welt! Dies ist ein Test. Hier ist noch ein Satz.\")\n",
    "print(\"Satz-Tokenisierung:\", sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8ddc36",
   "metadata": {},
   "source": [
    "### Beispiel 2: Part-of-Speech (POS) Tagging\n",
    "\n",
    "POS-Tagging erm√∂glicht es uns, die grammatikalische Rolle jedes Wortes in einem Satz zu identifizieren. Wir verwenden die `nltk`-Bibliothek, um dies zu demonstrieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e1a780c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK POS-Tagging (Englisch):\n",
      "[('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN'), ('.', '.')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /Users/nils_hellwig/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Definieren wir zun√§chst zwei Beispieltexte, einen auf Englisch und einen auf Deutsch.\n",
    "text_en = \"The quick brown fox jumps over the lazy dog.\"\n",
    "text_de = \"Der schnelle braune Fuchs springt √ºber den faulen Hund.\"\n",
    "\n",
    "# NLTK-Modelle herunterladen. averaged_perceptron_tagger ist ein vortrainiertes Modell f√ºr POS-Tagging.\n",
    "nltk.download(\"averaged_perceptron_tagger_eng\")\n",
    "\n",
    "# Tokenisieren und POS-Tagging (Englisch)\n",
    "tokens_en = nltk.word_tokenize(text_en)\n",
    "pos_tags_en = nltk.pos_tag(tokens_en)\n",
    "print(\"NLTK POS-Tagging (Englisch):\")\n",
    "print(pos_tags_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "77fb683d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "spaCy POS-Tagging (Englisch):\n",
      "The        DET        DT        \n",
      "quick      ADJ        JJ        \n",
      "brown      ADJ        JJ        \n",
      "fox        NOUN       NN        \n",
      "jumps      VERB       VBZ       \n",
      "over       ADP        IN        \n",
      "the        DET        DT        \n",
      "lazy       ADJ        JJ        \n",
      "dog        NOUN       NN        \n",
      ".          PUNCT      .         \n",
      "\n",
      "spaCy POS-Tagging (Deutsch):\n",
      "Der        DET        ART       \n",
      "schnelle   ADJ        ADJA      \n",
      "braune     ADJ        ADJA      \n",
      "Fuchs      NOUN       NN        \n",
      "springt    VERB       VVFIN     \n",
      "√ºber       ADP        APPR      \n",
      "den        DET        ART       \n",
      "faulen     ADJ        ADJA      \n",
      "Hund       NOUN       NN        \n",
      ".          PUNCT      $.        \n",
      "\n",
      "spaCy POS-Tagging (Deutsch):\n",
      "Der        DET        ART       \n",
      "schnelle   ADJ        ADJA      \n",
      "braune     ADJ        ADJA      \n",
      "Fuchs      NOUN       NN        \n",
      "springt    VERB       VVFIN     \n",
      "√ºber       ADP        APPR      \n",
      "den        DET        ART       \n",
      "faulen     ADJ        ADJA      \n",
      "Hund       NOUN       NN        \n",
      ".          PUNCT      $.        \n"
     ]
    }
   ],
   "source": [
    "# Auch mit spaCy k√∂nnen wir POS-Tagging durchf√ºhren. SpaCy (https://spacy.io/) ist eine sehr beliebte Bibliothek f√ºr NLP in Python, \n",
    "# da sie viele Tools und vortrainierte Modelle bietet f√ºr verschiedenste Anwendungen.\n",
    "import spacy\n",
    "\n",
    "# Laden wir zun√§chst die vortrainierten Modelle f√ºr Englisch.\n",
    "nlp_en = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Mit nlp_en k√∂nnen wir den Text in eine Liste von Tokens umwandeln.\n",
    "doc_en = nlp_en(text_en)\n",
    "\n",
    "# Tokens besitzen verschiedene Attribute, z.B. den Text und die Wortart (POS).\n",
    "print(\"\\nspaCy POS-Tagging (Englisch):\")\n",
    "for token in doc_en:\n",
    "    print(f\"{token.text:10} {token.pos_:10} {token.tag_:10}\") # :10 sorgt f√ºr eine feste Breite von 10 Zeichen\n",
    "\n",
    "# Deutsches Modell\n",
    "nlp_de = spacy.load(\"de_core_news_sm\")\n",
    "doc_de = nlp_de(text_de)\n",
    "print(\"\\nspaCy POS-Tagging (Deutsch):\")\n",
    "for token in doc_de:\n",
    "    print(f\"{token.text:10} {token.pos_:10} {token.tag_:10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb21251",
   "metadata": {},
   "source": [
    "### Beispiel 3: Lemmatization und Stemming\n",
    "\n",
    "Wie in der Vorlesung besprochen, ist es bei der Verarbeitung nat√ºrlicher Sprache eine Herausforderung, dass es viele verschiedene Formen eines Wortes gibt, diese aber die gleiche Bedeutung haben. Zum Beispiel sind \"running\", \"ran\" und \"runs\" alles Formen des Verbs \"run\". Um diese Herausforderung zu bew√§ltigen, verwenden wir Techniken wie **Lemmatisierung** und **Stemming**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "30918b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The          ‚Üí The\n",
      "striped      ‚Üí Striped\n",
      "bats         ‚Üí Bat\n",
      "were         ‚Üí were\n",
      "hanging      ‚Üí hanging\n",
      "on           ‚Üí --\n",
      "their        ‚Üí their\n",
      "feet         ‚Üí feet\n",
      "and          ‚Üí And\n",
      "ate          ‚Üí ate\n",
      "best         ‚Üí Best\n",
      "fishes       ‚Üí fish\n"
     ]
    }
   ],
   "source": [
    "# Beispieltext\n",
    "text = \"The striped bats were hanging on their feet and ate best fishes\"\n",
    "doc = nlp(text)\n",
    "\n",
    "# Lemmatization reduziert W√∂rter auf ihre Grundform (Lemma), unter Ber√ºcksichtigung von Wortart, Morphologie und Kontext.\n",
    "# Beispiel: \"ate\" ‚Üí \"eat\", \"feet\" ‚Üí \"foot\"\n",
    "for token in doc:\n",
    "    # Jedes token hat ein Attribut lemma_, das die Grundform des Wortes enth√§lt.\n",
    "    print(f\"{token.text:12} ‚Üí {token.lemma_}\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d2f216fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The          ‚Üí the\n",
      "striped      ‚Üí stripe\n",
      "bats         ‚Üí bat\n",
      "were         ‚Üí were\n",
      "hanging      ‚Üí hang\n",
      "on           ‚Üí on\n",
      "their        ‚Üí their\n",
      "feet         ‚Üí feet\n",
      "and          ‚Üí and\n",
      "ate          ‚Üí ate\n",
      "best         ‚Üí best\n",
      "fishes       ‚Üí fish\n"
     ]
    }
   ],
   "source": [
    "# NLTK bietet eine Schnittstelle f√ºr Stemming an. Wir verwenden den Porter Stemmer, einen der bekanntesten Stemmer (https://de.wikipedia.org/wiki/Porter-Stemmer-Algorithmus)\n",
    "# Stemming k√ºrzt W√∂rter auf einen Wortstamm durch heuristische Regeln.\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "for word in text.split():\n",
    "    print(f\"{word:12} ‚Üí {stemmer.stem(word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4957bd",
   "metadata": {},
   "source": [
    "### Beispiel 4: Regul√§re Ausdr√ºcke\n",
    "\n",
    "Regul√§re Ausdr√ºcke (RegEx) sind ein Werkzeug zur Textverarbeitung. Sie erm√∂glichen es uns, Muster in Texten zu erkennen und zu extrahieren. Hier sind einige Beispiele, wie wir RegEx in Python verwenden k√∂nnen, um spezifische Informationen aus einem Text zu extrahieren.\n",
    "\n",
    "Ich empfehle euch [RegExr.com](https://regexr.com/) zum Testen von regul√§ren Ausdr√ºcken. Au√üerdem wird dort ein guter √úberblick √ºber die RegEx-Syntax gegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "676e4f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speicher gefunden? True\n",
      "Gefundene Zahlen: ['45', '3', '100', '250', '1']\n",
      "Gefundene Speicherplatzangaben: ['GB', 'MB', 'MB', 'GB']\n",
      "Gefundene E-Mail-Adressen: ['mi@ur.de']\n",
      "G√ºltige E-Mail: mi@ur.de\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from email_validator import validate_email, EmailNotValidError\n",
    "\n",
    "text = \"Sie haben noch 45GB Speicher und Ihre E-Mail ist mi@ur.de und sie haben 3 Dateien mit 100MB, 250MB und 1GB.\"\n",
    "\n",
    "# Einfach: Wortsuche mit RegEx\n",
    "pattern_word = r\"\\bSpeicher\\b\"\n",
    "print(\"Speicher gefunden?\", bool(re.search(pattern_word, text)))\n",
    "\n",
    "# Zahlen extrahieren (RegEx)\n",
    "numbers = re.findall(r\"\\d+\", text)\n",
    "print(\"Gefundene Zahlen:\", numbers)\n",
    "\n",
    "# Angaben von Speicherplatz\n",
    "pattern_storage = r\"\\b\\d+\\s*(GB|MB|KB)\\b\"\n",
    "storage_matches = re.findall(pattern_storage, text)\n",
    "print(\"Gefundene Speicherplatzangaben:\", storage_matches)\n",
    "\n",
    "# E-Mail-Adresse mit RegEx validieren\n",
    "pattern_email = r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\"\n",
    "email_matches = re.findall(pattern_email, text)\n",
    "if email_matches:\n",
    "    print(\"Gefundene E-Mail-Adressen:\", email_matches)\n",
    "else:\n",
    "    print(\"Keine g√ºltige E-Mail-Adresse gefunden.\")\n",
    "\n",
    "# E-Mail-Adresse mit externer Library validieren\n",
    "try:\n",
    "    result = validate_email(\"mi@ur.de\")  # findet man z. B. aus dem Text\n",
    "    print(\"G√ºltige E-Mail:\", result.email)\n",
    "except EmailNotValidError as e:\n",
    "    print(\"Ung√ºltige E-Mail:\", e)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Erkl√§rung warum externe Packages sinnvoll sind:\n",
    "#\n",
    "# Komplexe Muster wie E-Mail-Adressen oder internationale Telefonnummern\n",
    "# lassen sich nur sehr schwer mit einfachen regul√§ren Ausdr√ºcken korrekt\n",
    "# und vollst√§ndig erfassen.\n",
    "#\n",
    "# Externe Libraries wie `email_validator` und `phonenumbers` sind\n",
    "# speziell darauf ausgelegt, Standards und viele Sonderf√§lle korrekt zu behandeln.\n",
    "# Sie validieren nicht nur das Format, sondern z.B. bei E-Mails auch die\n",
    "# Domain, bei Telefonnummern L√§ndercodes und Nummernl√§ngen.\n",
    "#\n",
    "# Das macht deinen Code robuster, wartbarer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c18332",
   "metadata": {},
   "source": [
    "### Beispiel 5: Embeddings und Vector Space Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8618b5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosinus-√Ñhnlichkeiten zwischen Wortpaaren:\n",
      "Dimensionen: (1, 96) (1, 96)\n",
      "'cat' vs. 'dog': 0.742\n",
      "Dimensionen: (1, 96) (1, 96)\n",
      "'car' vs. 'bike': 0.766\n",
      "Dimensionen: (1, 96) (1, 96)\n",
      "'cheesecake' vs. 'swimming': 0.299\n",
      "Dimensionen: (1, 96) (1, 96)\n",
      "'death' vs. 'google': 0.275\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import spacy\n",
    "\n",
    "# spaCy Modell laden (englisch, mit Vektoren)\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# W√∂rter f√ºr Vergleich\n",
    "word_pairs = [\n",
    "    (\"cat\", \"dog\"), # Beispiel mit √§hnlichen W√∂rtern\n",
    "    (\"car\", \"bike\"), # Beispiel mit √§hnlichen W√∂rtern\n",
    "    (\"cheesecake\", \"swimming\"), # Beispiel mit un√§hnlichen W√∂rtern\n",
    "    (\"death\", \"google\") # Beispiel mit un√§hnlichen W√∂rtern\n",
    "]\n",
    "\n",
    "print(\"Cosinus-√Ñhnlichkeiten zwischen Wortpaaren:\")\n",
    "\n",
    "for w1, w2 in word_pairs:\n",
    "    # 1. Wandeln wir die W√∂rter in Vektoren.\n",
    "    # Daf√ºr nutzen wir wieder das spaCy Modell und nutzen das Attribut .vector, das den Vektor/Embedding des Wortes zur√ºckgibt.\n",
    "    # 2. Da cosine_similarity 2D-Arrays erwartet, m√ºssen wir die Vektoren noch reshapen in 2D.\n",
    "    # cosine_similarity erwartet 2D-Arrays, da es prinzipiell auch f√ºr Matrizen-Vergleiche genutzt werden kann.\n",
    "    # .reshape(1, -1) sorgt daf√ºr, dass die Vektoren die Form (1, n) bekommen, also eine Zeile und n Spalten. -1 bedeutet, dass die Anzahl der Spalten automatisch bestimmt wird.\n",
    "    vec1 = nlp(w1).vector.reshape(1, -1)\n",
    "    vec2 = nlp(w2).vector.reshape(1, -1)\n",
    "    print(\"Dimensionen:\", vec1.shape, vec2.shape)\n",
    "    \n",
    "    # 3. Berechnen wir die Cosinus-√Ñhnlichkeit mit sklearns cosine_similarity Funktion.\n",
    "    # [0][0] am Ende extrahiert den Skalarwert aus dem 2D-Array, das zur√ºckgegeben wird.\n",
    "    cos_sim = cosine_similarity(vec1, vec2)[0][0]\n",
    "    print(f\"'{w1}' vs. '{w2}': {cos_sim:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d977ec",
   "metadata": {},
   "source": [
    "### üêº Einschub: Pandas Basics ‚Äì Arbeiten mit `sentiment_texts.csv`\n",
    "\n",
    "Da wir f√ºr die nachfolgenden Beispiele eine CSV-Datei mit Textdaten verwenden, hier ein kurzer Einschub zu `pandas`.\n",
    "Gerade, wenn man mit Textdaten arbeitet, sind Daten oft in Tabellenform gespeichert. Ein g√§ngiges Format ist CSV (Comma-Separated Values). In diesem Beispiel verwenden wir die Bibliothek `pandas`, um eine CSV-Datei zu laden und zu analysieren. \n",
    "\n",
    "Wir arbeiten mit der CSV-Datei `sentiment_texts.csv`, die Tweets umfasst und Annotationen f√ºr das Sentiment (positiv, negativ, neutral) enth√§lt. Es handelt sich um Tweets, bei denen Accounts von Politikern der 2021 im Bundestag vertretenen Parteien von Twitter-Nutzern erw√§hnt wurden mit einem `@`-Zeichen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1559e73d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source_account</th>\n",
       "      <th>source_party</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1459496838629839104</td>\n",
       "      <td>Beatrix_vStorch</td>\n",
       "      <td>AFD</td>\n",
       "      <td>@LisaLies12 @Beatrix_vStorch Ich habe NICHT be...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1366816957236977920</td>\n",
       "      <td>cducsubt</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@ChristianHirte @CDU @dieLinke @cducsubt Gewis...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1437742901186993920</td>\n",
       "      <td>_FriedrichMerz</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@PeterBofinger @_FriedrichMerz @handelsblatt @...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1352576248560706048</td>\n",
       "      <td>SWagenknecht</td>\n",
       "      <td>LINKE</td>\n",
       "      <td>@KunzlerManuel @DnielSchmlhofer @Stefan_Hajek ...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1439569370217340928</td>\n",
       "      <td>Alice_Weidel</td>\n",
       "      <td>AFD</td>\n",
       "      <td>@cem_oezdemir @ABaerbock Dachte erst Sie meine...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1868</th>\n",
       "      <td>1411004773126509056</td>\n",
       "      <td>CDU</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@Ruebenhorst @MenschgbMensch @CDU ist das Euer...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1869</th>\n",
       "      <td>1436672257682779904</td>\n",
       "      <td>Markus_Soeder</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@dcremer_ @Markus_Soeder @CSU Ohne g√∂ttliche I...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1870</th>\n",
       "      <td>1464183001588376064</td>\n",
       "      <td>Karl_Lauterbach</td>\n",
       "      <td>SPD</td>\n",
       "      <td>@Karl_Lauterbach das sieht schlecht aus. Da hi...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1871</th>\n",
       "      <td>1389635614975348992</td>\n",
       "      <td>CDU</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@MatthiasRieger3 @EskenSaskia @MEtzold @CDU ja...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1872</th>\n",
       "      <td>1400994841396456960</td>\n",
       "      <td>Markus_Soeder</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@GerdMll42564793 @Markus_Soeder Bestimmt</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1873 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id   source_account source_party  \\\n",
       "0     1459496838629839104  Beatrix_vStorch          AFD   \n",
       "1     1366816957236977920         cducsubt      CDU_CSU   \n",
       "2     1437742901186993920   _FriedrichMerz      CDU_CSU   \n",
       "3     1352576248560706048     SWagenknecht        LINKE   \n",
       "4     1439569370217340928     Alice_Weidel          AFD   \n",
       "...                   ...              ...          ...   \n",
       "1868  1411004773126509056              CDU      CDU_CSU   \n",
       "1869  1436672257682779904    Markus_Soeder      CDU_CSU   \n",
       "1870  1464183001588376064  Karl_Lauterbach          SPD   \n",
       "1871  1389635614975348992              CDU      CDU_CSU   \n",
       "1872  1400994841396456960    Markus_Soeder      CDU_CSU   \n",
       "\n",
       "                                                  tweet sentiment  \n",
       "0     @LisaLies12 @Beatrix_vStorch Ich habe NICHT be...  NEGATIVE  \n",
       "1     @ChristianHirte @CDU @dieLinke @cducsubt Gewis...   NEUTRAL  \n",
       "2     @PeterBofinger @_FriedrichMerz @handelsblatt @...   NEUTRAL  \n",
       "3     @KunzlerManuel @DnielSchmlhofer @Stefan_Hajek ...   NEUTRAL  \n",
       "4     @cem_oezdemir @ABaerbock Dachte erst Sie meine...   NEUTRAL  \n",
       "...                                                 ...       ...  \n",
       "1868  @Ruebenhorst @MenschgbMensch @CDU ist das Euer...  NEGATIVE  \n",
       "1869  @dcremer_ @Markus_Soeder @CSU Ohne g√∂ttliche I...   NEUTRAL  \n",
       "1870  @Karl_Lauterbach das sieht schlecht aus. Da hi...  NEGATIVE  \n",
       "1871  @MatthiasRieger3 @EskenSaskia @MEtzold @CDU ja...   NEUTRAL  \n",
       "1872           @GerdMll42564793 @Markus_Soeder Bestimmt   NEUTRAL  \n",
       "\n",
       "[1873 rows x 5 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importieren der Pandas-Bibliothek\n",
    "import pandas as pd\n",
    "\n",
    "# 1Ô∏è‚É£ CSV-Datei laden: Mit pd.read_csv() k√∂nnen wir Daten aus einer CSV-Datei in ein DataFrame laden.\n",
    "df = pd.read_csv(\"tweets.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0394612f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source_account</th>\n",
       "      <th>source_party</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1459496838629839104</td>\n",
       "      <td>Beatrix_vStorch</td>\n",
       "      <td>AFD</td>\n",
       "      <td>@LisaLies12 @Beatrix_vStorch Ich habe NICHT be...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1366816957236977920</td>\n",
       "      <td>cducsubt</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@ChristianHirte @CDU @dieLinke @cducsubt Gewis...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1437742901186993920</td>\n",
       "      <td>_FriedrichMerz</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@PeterBofinger @_FriedrichMerz @handelsblatt @...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1352576248560706048</td>\n",
       "      <td>SWagenknecht</td>\n",
       "      <td>LINKE</td>\n",
       "      <td>@KunzlerManuel @DnielSchmlhofer @Stefan_Hajek ...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1439569370217340928</td>\n",
       "      <td>Alice_Weidel</td>\n",
       "      <td>AFD</td>\n",
       "      <td>@cem_oezdemir @ABaerbock Dachte erst Sie meine...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id   source_account source_party  \\\n",
       "0  1459496838629839104  Beatrix_vStorch          AFD   \n",
       "1  1366816957236977920         cducsubt      CDU_CSU   \n",
       "2  1437742901186993920   _FriedrichMerz      CDU_CSU   \n",
       "3  1352576248560706048     SWagenknecht        LINKE   \n",
       "4  1439569370217340928     Alice_Weidel          AFD   \n",
       "\n",
       "                                               tweet sentiment  \n",
       "0  @LisaLies12 @Beatrix_vStorch Ich habe NICHT be...  NEGATIVE  \n",
       "1  @ChristianHirte @CDU @dieLinke @cducsubt Gewis...   NEUTRAL  \n",
       "2  @PeterBofinger @_FriedrichMerz @handelsblatt @...   NEUTRAL  \n",
       "3  @KunzlerManuel @DnielSchmlhofer @Stefan_Hajek ...   NEUTRAL  \n",
       "4  @cem_oezdemir @ABaerbock Dachte erst Sie meine...   NEUTRAL  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mit df.head() k√∂nnen wir die ersten 5 Zeilen des DataFrames bequem anzeigen.\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4fc567b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        AFD\n",
       "1    CDU_CSU\n",
       "2    CDU_CSU\n",
       "3      LINKE\n",
       "4        AFD\n",
       "5        FDP\n",
       "6        SPD\n",
       "7    CDU_CSU\n",
       "8        SPD\n",
       "9      LINKE\n",
       "Name: source_party, dtype: object"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wir k√∂nnen auch die Werte einer bestimmten Spalte ausw√§hlen, z.B. \"source_party\":\n",
    "df[\"source_party\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "abd0710a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source_account</th>\n",
       "      <th>source_party</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1347612879810425088</td>\n",
       "      <td>n_roettgen</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@n_roettgen auch mit Blick auf andere Aspekte ...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1471842111062429952</td>\n",
       "      <td>_FriedrichMerz</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@ToshimaDE @CDU @_FriedrichMerz Wie? Sitzt die...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1411032162929872896</td>\n",
       "      <td>ArminLaschet</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@steps0815 @Arndt_Klocke @MaAhl5 @Oliver_Krisc...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1382766358790868992</td>\n",
       "      <td>Karl_Lauterbach</td>\n",
       "      <td>SPD</td>\n",
       "      <td>@Karl_Lauterbach Ach na endlich!! Da kann ich ...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1346511916173304064</td>\n",
       "      <td>_FriedrichMerz</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@BorisNMoellers @_FriedrichMerz Ich √ºbrigens a...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1832</th>\n",
       "      <td>1473352625554963968</td>\n",
       "      <td>fdpbt</td>\n",
       "      <td>FDP</td>\n",
       "      <td>@Patrickweedmob @spdbt @GrueneBundestag @fdpbt...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841</th>\n",
       "      <td>1355126553882063104</td>\n",
       "      <td>Markus_Soeder</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@1xKlaudius @Markus_Soeder Mit Scheuer im Wahl...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1847</th>\n",
       "      <td>1411631133259973120</td>\n",
       "      <td>ArminLaschet</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@RadtkeMdEP 1.) Ein #guterplan #wegenmorgen w√§...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1850</th>\n",
       "      <td>1352647722801757952</td>\n",
       "      <td>ArminLaschet</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>#Herzlichen #Gl√ºckwunsch an alle #nun #offizie...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867</th>\n",
       "      <td>1408741244927365120</td>\n",
       "      <td>Alice_Weidel</td>\n",
       "      <td>AFD</td>\n",
       "      <td>@ASB_Anwohner @Alice_Weidel @Afd_emskirchen Bu...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id   source_account source_party  \\\n",
       "7     1347612879810425088       n_roettgen      CDU_CSU   \n",
       "10    1471842111062429952   _FriedrichMerz      CDU_CSU   \n",
       "25    1411032162929872896     ArminLaschet      CDU_CSU   \n",
       "34    1382766358790868992  Karl_Lauterbach          SPD   \n",
       "43    1346511916173304064   _FriedrichMerz      CDU_CSU   \n",
       "...                   ...              ...          ...   \n",
       "1832  1473352625554963968            fdpbt          FDP   \n",
       "1841  1355126553882063104    Markus_Soeder      CDU_CSU   \n",
       "1847  1411631133259973120     ArminLaschet      CDU_CSU   \n",
       "1850  1352647722801757952     ArminLaschet      CDU_CSU   \n",
       "1867  1408741244927365120     Alice_Weidel          AFD   \n",
       "\n",
       "                                                  tweet sentiment  \n",
       "7     @n_roettgen auch mit Blick auf andere Aspekte ...  POSITIVE  \n",
       "10    @ToshimaDE @CDU @_FriedrichMerz Wie? Sitzt die...  POSITIVE  \n",
       "25    @steps0815 @Arndt_Klocke @MaAhl5 @Oliver_Krisc...  POSITIVE  \n",
       "34    @Karl_Lauterbach Ach na endlich!! Da kann ich ...  POSITIVE  \n",
       "43    @BorisNMoellers @_FriedrichMerz Ich √ºbrigens a...  POSITIVE  \n",
       "...                                                 ...       ...  \n",
       "1832  @Patrickweedmob @spdbt @GrueneBundestag @fdpbt...  POSITIVE  \n",
       "1841  @1xKlaudius @Markus_Soeder Mit Scheuer im Wahl...  POSITIVE  \n",
       "1847  @RadtkeMdEP 1.) Ein #guterplan #wegenmorgen w√§...  POSITIVE  \n",
       "1850  #Herzlichen #Gl√ºckwunsch an alle #nun #offizie...  POSITIVE  \n",
       "1867  @ASB_Anwohner @Alice_Weidel @Afd_emskirchen Bu...  POSITIVE  \n",
       "\n",
       "[120 rows x 5 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Filterm√∂glichkeiten: Mit df[df[\"sentiment\"] == \"POSITIVE\"] k√∂nnen wir nur die Zeilen mit positivem Sentiment anzeigen. \n",
    "\n",
    "df[\"sentiment\"] w√§hlt die Spalte sentiment aus dem DataFrame df aus.\n",
    "Ergebnis: eine Series ‚Äì also eine eindimensionale, beschriftete Datenstruktur.\n",
    "'''\n",
    "df[df[\"sentiment\"] == \"POSITIVE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "022a2ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "NEGATIVE    976\n",
       "NEUTRAL     777\n",
       "POSITIVE    120\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mit .value_counts() k√∂nnen wir die H√§ufigkeit der einzigartigen Werte in der Spalte \"sentiment\" anzeigen.\n",
    "# Wir sehen beim Output, dass die Stimmung nicht ausgewogen ist: Es gibt deutlich mehr negative als positive Tweets, wobei fast so viele neutrale Tweets wie positive Tweets vorhanden sind.\n",
    "df[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fd2d8128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       @LISALIES12 @BEATRIX_VSTORCH ICH HABE NICHT BE...\n",
       "1       @CHRISTIANHIRTE @CDU @DIELINKE @CDUCSUBT GEWIS...\n",
       "2       @PETERBOFINGER @_FRIEDRICHMERZ @HANDELSBLATT @...\n",
       "3       @KUNZLERMANUEL @DNIELSCHMLHOFER @STEFAN_HAJEK ...\n",
       "4       @CEM_OEZDEMIR @ABAERBOCK DACHTE ERST SIE MEINE...\n",
       "                              ...                        \n",
       "1868    @RUEBENHORST @MENSCHGBMENSCH @CDU IST DAS EUER...\n",
       "1869    @DCREMER_ @MARKUS_SOEDER @CSU OHNE G√ñTTLICHE I...\n",
       "1870    @KARL_LAUTERBACH DAS SIEHT SCHLECHT AUS. DA HI...\n",
       "1871    @MATTHIASRIEGER3 @ESKENSASKIA @METZOLD @CDU JA...\n",
       "1872          @GERDMLL42564793 @MARKUS_SOEDER BESTIMMT!!!\n",
       "Name: shouted, Length: 1873, dtype: object"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mit .apply() k√∂nnen wir eine Funktion auf jede Zeile oder Spalte eines DataFrames anwenden.\n",
    "def shout(text):\n",
    "    return text.upper() + \"!!!\"\n",
    "\n",
    "df[\"shouted\"] = df[\"tweet\"].apply(shout)\n",
    "df[\"shouted\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "23bb03c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source_account</th>\n",
       "      <th>source_party</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>shouted</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>1389713588659625984</td>\n",
       "      <td>CDU</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>LG an @CDU und @CSU</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>LG AN @CDU UND @CSU!!!</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319</th>\n",
       "      <td>1377675573435191040</td>\n",
       "      <td>Die_Gruenen</td>\n",
       "      <td>GRUENE</td>\n",
       "      <td>@Die_Gruenen so schwarz.</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>@DIE_GRUENEN SO SCHWARZ.!!!</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1432400536498810880</td>\n",
       "      <td>CDU</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@CDU Was f√ºr ein Unsinn.</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>@CDU WAS F√úR EIN UNSINN.!!!</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>1424771876837024000</td>\n",
       "      <td>Die_Gruenen</td>\n",
       "      <td>GRUENE</td>\n",
       "      <td>@Die_Gruenen Zeit wirds!</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>@DIE_GRUENEN ZEIT WIRDS!!!!</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1409483299207122944</td>\n",
       "      <td>Karl_Lauterbach</td>\n",
       "      <td>SPD</td>\n",
       "      <td>@Karl_Lauterbach Ab wann?</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>@KARL_LAUTERBACH AB WANN?!!!</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>1389137005326618880</td>\n",
       "      <td>SWagenknecht</td>\n",
       "      <td>LINKE</td>\n",
       "      <td>@StimmederVernu9 @DerEchteGrubert @AlfredNeuma...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>@STIMMEDERVERNU9 @DERECHTEGRUBERT @ALFREDNEUMA...</td>\n",
       "      <td>523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>1399462761541911040</td>\n",
       "      <td>c_lindner</td>\n",
       "      <td>FDP</td>\n",
       "      <td>@chris_pyak @holgerkopp @HLiepelt @MartinWalth...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>@CHRIS_PYAK @HOLGERKOPP @HLIEPELT @MARTINWALTH...</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>1442227712869940992</td>\n",
       "      <td>cem_oezdemir</td>\n",
       "      <td>GRUENE</td>\n",
       "      <td>@GGahnt @CartmanTB2 @Andrew1023054 @NurZoabe @...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>@GGAHNT @CARTMANTB2 @ANDREW1023054 @NURZOABE @...</td>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>1345808822544326912</td>\n",
       "      <td>CDU</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@cat_spass @Abtreibpranger @Peacecakex @nelson...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>@CAT_SPASS @ABTREIBPRANGER @PEACECAKEX @NELSON...</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>1376307200797344000</td>\n",
       "      <td>hubertus_heil</td>\n",
       "      <td>SPD</td>\n",
       "      <td>@Detlef66138495 @BVG_Kampagne @goethe_jw @4tti...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>@DETLEF66138495 @BVG_KAMPAGNE @GOETHE_JW @4TTI...</td>\n",
       "      <td>746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1873 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id   source_account source_party  \\\n",
       "1724  1389713588659625984              CDU      CDU_CSU   \n",
       "1319  1377675573435191040      Die_Gruenen       GRUENE   \n",
       "32    1432400536498810880              CDU      CDU_CSU   \n",
       "351   1424771876837024000      Die_Gruenen       GRUENE   \n",
       "189   1409483299207122944  Karl_Lauterbach          SPD   \n",
       "...                   ...              ...          ...   \n",
       "575   1389137005326618880     SWagenknecht        LINKE   \n",
       "1657  1399462761541911040        c_lindner          FDP   \n",
       "635   1442227712869940992     cem_oezdemir       GRUENE   \n",
       "804   1345808822544326912              CDU      CDU_CSU   \n",
       "1361  1376307200797344000    hubertus_heil          SPD   \n",
       "\n",
       "                                                  tweet sentiment  \\\n",
       "1724                                LG an @CDU und @CSU  POSITIVE   \n",
       "1319                           @Die_Gruenen so schwarz.   NEUTRAL   \n",
       "32                             @CDU Was f√ºr ein Unsinn.  NEGATIVE   \n",
       "351                            @Die_Gruenen Zeit wirds!   NEUTRAL   \n",
       "189                           @Karl_Lauterbach Ab wann?   NEUTRAL   \n",
       "...                                                 ...       ...   \n",
       "575   @StimmederVernu9 @DerEchteGrubert @AlfredNeuma...  NEGATIVE   \n",
       "1657  @chris_pyak @holgerkopp @HLiepelt @MartinWalth...  NEGATIVE   \n",
       "635   @GGahnt @CartmanTB2 @Andrew1023054 @NurZoabe @...  NEGATIVE   \n",
       "804   @cat_spass @Abtreibpranger @Peacecakex @nelson...   NEUTRAL   \n",
       "1361  @Detlef66138495 @BVG_Kampagne @goethe_jw @4tti...   NEUTRAL   \n",
       "\n",
       "                                                shouted  text_length  \n",
       "1724                             LG AN @CDU UND @CSU!!!           19  \n",
       "1319                        @DIE_GRUENEN SO SCHWARZ.!!!           24  \n",
       "32                          @CDU WAS F√úR EIN UNSINN.!!!           24  \n",
       "351                         @DIE_GRUENEN ZEIT WIRDS!!!!           24  \n",
       "189                        @KARL_LAUTERBACH AB WANN?!!!           25  \n",
       "...                                                 ...          ...  \n",
       "575   @STIMMEDERVERNU9 @DERECHTEGRUBERT @ALFREDNEUMA...          523  \n",
       "1657  @CHRIS_PYAK @HOLGERKOPP @HLIEPELT @MARTINWALTH...          566  \n",
       "635   @GGAHNT @CARTMANTB2 @ANDREW1023054 @NURZOABE @...          570  \n",
       "804   @CAT_SPASS @ABTREIBPRANGER @PEACECAKEX @NELSON...          655  \n",
       "1361  @DETLEF66138495 @BVG_KAMPAGNE @GOETHE_JW @4TTI...          746  \n",
       "\n",
       "[1873 rows x 7 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mit .sort_values() k√∂nnen wir den DataFrame nach einer bestimmten Spalte sortieren.\n",
    "def text_length(text):\n",
    "    return len(text)\n",
    "\n",
    "df[\"text_length\"] = df[\"tweet\"].apply(text_length)\n",
    "df = df.sort_values(by=\"text_length\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c74524fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "NEGATIVE    26.861680\n",
       "NEUTRAL     19.772201\n",
       "POSITIVE    19.016667\n",
       "Name: word_count, dtype: float64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mit .mean() k√∂nnen wir den Durchschnitt einer Spalte berechnen.\n",
    "def word_count(text):\n",
    "    return len(text.split())\n",
    "\n",
    "df[\"word_count\"] = df[\"tweet\"].apply(word_count)\n",
    "\n",
    "# Mit .groupby() k√∂nnen wir den DataFrame nach einer bestimmten Spalte gruppieren.\n",
    "# df.groupby(\"sentiment\")[\"word_count\"] gibt uns eine SeriesGroupBy-Objekt zur√ºck, das die Wortanzahl f√ºr jede Sentiment-Kategorie gruppiert.\n",
    "# Mit .mean() berechnen wir den Durchschnitt der Wortanzahl f√ºr jede Sentiment-Kategorie.\n",
    "df.groupby(\"sentiment\")[\"word_count\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b0c508ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source_account</th>\n",
       "      <th>source_party</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>shouted</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>1464916983108062976</td>\n",
       "      <td>MiKellner</td>\n",
       "      <td>GRUENE</td>\n",
       "      <td>@MonikaHerrmann1 @MiKellner @ABaerbock Wieder ...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>@MONIKAHERRMANN1 @MIKELLNER @ABAERBOCK WIEDER ...</td>\n",
       "      <td>61</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>1363624003278151936</td>\n",
       "      <td>PaulZiemiak</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@PaulZiemiak @BerlinReporter Keine Aufregung. ...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>@PAULZIEMIAK @BERLINREPORTER KEINE AUFREGUNG. ...</td>\n",
       "      <td>98</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1781</th>\n",
       "      <td>1362817043549069056</td>\n",
       "      <td>CDU</td>\n",
       "      <td>CDU_CSU</td>\n",
       "      <td>@GirkeHanjo @BerlinReporter @MIT_bund @christo...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>@GIRKEHANJO @BERLINREPORTER @MIT_BUND @CHRISTO...</td>\n",
       "      <td>107</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id source_account source_party  \\\n",
       "872   1464916983108062976      MiKellner       GRUENE   \n",
       "1725  1363624003278151936    PaulZiemiak      CDU_CSU   \n",
       "1781  1362817043549069056            CDU      CDU_CSU   \n",
       "\n",
       "                                                  tweet sentiment  \\\n",
       "872   @MonikaHerrmann1 @MiKellner @ABaerbock Wieder ...   NEUTRAL   \n",
       "1725  @PaulZiemiak @BerlinReporter Keine Aufregung. ...  NEGATIVE   \n",
       "1781  @GirkeHanjo @BerlinReporter @MIT_bund @christo...  POSITIVE   \n",
       "\n",
       "                                                shouted  text_length  \\\n",
       "872   @MONIKAHERRMANN1 @MIKELLNER @ABAERBOCK WIEDER ...           61   \n",
       "1725  @PAULZIEMIAK @BERLINREPORTER KEINE AUFREGUNG. ...           98   \n",
       "1781  @GIRKEHANJO @BERLINREPORTER @MIT_BUND @CHRISTO...          107   \n",
       "\n",
       "      word_count  \n",
       "872            7  \n",
       "1725          10  \n",
       "1781          13  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def has_berlin(text):\n",
    "    return \"Berlin\" in text\n",
    "\n",
    "# Zeilen filtern\n",
    "df_berlin = df[df[\"tweet\"].apply(has_berlin)]\n",
    "df_berlin.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2394153b",
   "metadata": {},
   "source": [
    "### üî¢ Einschub: NumPy Basics ‚Äì Arbeiten mit Arrays\n",
    "\n",
    "NumPy (Numerical Python) ist die grundlegende Bibliothek f√ºr wissenschaftliches Rechnen in Python. Es bietet ein m√§chtiges N-dimensionales Array-Objekt und Funktionen f√ºr deren Bearbeitung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f2006801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy Array: [1 2 3 4 5]\n",
      "Typ: <class 'numpy.ndarray'>\n",
      "Shape (Form): (5,)\n",
      "Data Type: int64\n"
     ]
    }
   ],
   "source": [
    "# Importieren der NumPy-Bibliothek\n",
    "import numpy as np\n",
    "\n",
    "# 1Ô∏è‚É£ Arrays erstellen: Mit np.array() k√∂nnen wir Listen in NumPy Arrays umwandeln.\n",
    "numbers = [1, 2, 3, 4, 5]\n",
    "arr = np.array(numbers)\n",
    "print(\"NumPy Array:\", arr)\n",
    "print(\"Typ:\", type(arr))\n",
    "print(\"Shape (Form):\", arr.shape)\n",
    "print(\"Data Type:\", arr.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2ac6faee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D Array:\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "Shape: (3, 3)\n",
      "\n",
      "Zeros Array:\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "\n",
      "Ones Array:\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# 2Ô∏è‚É£ Zweidimensionale Arrays: Mit np.array() k√∂nnen wir auch 2D-Arrays (Matrizen) erstellen.\n",
    "matrix = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(\"2D Array:\")\n",
    "print(matrix)\n",
    "print(\"Shape:\", matrix.shape)  # (3, 3) bedeutet 3 Zeilen, 3 Spalten\n",
    "\n",
    "# Arrays mit bestimmten Werten erstellen\n",
    "zeros = np.zeros((2, 3))  # 2x3 Array mit Nullen\n",
    "ones = np.ones((2, 3))    # 2x3 Array mit Einsen\n",
    "print(\"\\nZeros Array:\")\n",
    "print(zeros)\n",
    "print(\"\\nOnes Array:\")\n",
    "print(ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d3e17e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Array: [10 20 30 40 50]\n",
      "Erstes Element: 10\n",
      "Letztes Element: 50\n",
      "Slice [1:4]: [20 30 40]\n",
      "\n",
      "2D Array:\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "Element [0,0]: 1\n",
      "Element [1,2]: 6\n",
      "Erste Zeile: [1 2 3]\n",
      "Erste Spalte: [1 4 7]\n"
     ]
    }
   ],
   "source": [
    "# 3Ô∏è‚É£ Array-Indexierung und Slicing: √Ñhnlich wie bei Python-Listen\n",
    "arr = np.array([10, 20, 30, 40, 50])\n",
    "print(\"Original Array:\", arr)\n",
    "print(\"Erstes Element:\", arr[0])      # Index 0\n",
    "print(\"Letztes Element:\", arr[-1])    # Index -1\n",
    "print(\"Slice [1:4]:\", arr[1:4])       # Elemente von Index 1 bis 3\n",
    "\n",
    "# 2D Array Indexierung\n",
    "matrix = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(\"\\n2D Array:\")\n",
    "print(matrix)\n",
    "print(\"Element [0,0]:\", matrix[0, 0])  # Erste Zeile, erste Spalte\n",
    "print(\"Element [1,2]:\", matrix[1, 2])  # Zweite Zeile, dritte Spalte\n",
    "print(\"Erste Zeile:\", matrix[0, :])    # Ganze erste Zeile\n",
    "print(\"Erste Spalte:\", matrix[:, 0])   # Ganze erste Spalte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "534bf291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array 1: [1 2 3 4]\n",
      "Array 2: [10 20 30 40]\n",
      "Addition: [11 22 33 44]\n",
      "Subtraktion: [ -9 -18 -27 -36]\n",
      "Multiplikation: [ 10  40  90 160]\n",
      "Division: [10. 10. 10. 10.]\n",
      "\n",
      "Array * 2: [2 4 6 8]\n",
      "Array + 10: [11 12 13 14]\n"
     ]
    }
   ],
   "source": [
    "# 4Ô∏è‚É£ Mathematische Operationen: NumPy macht Berechnungen sehr effizient\n",
    "arr1 = np.array([1, 2, 3, 4])\n",
    "arr2 = np.array([10, 20, 30, 40])\n",
    "\n",
    "print(\"Array 1:\", arr1)\n",
    "print(\"Array 2:\", arr2)\n",
    "\n",
    "# Element-weise Operationen\n",
    "print(\"Addition:\", arr1 + arr2)\n",
    "print(\"Subtraktion:\", arr1 - arr2)\n",
    "print(\"Multiplikation:\", arr1 * arr2)\n",
    "print(\"Division:\", arr2 / arr1)\n",
    "\n",
    "# Operationen mit Skalaren\n",
    "print(\"\\nArray * 2:\", arr1 * 2)\n",
    "print(\"Array + 10:\", arr1 + 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0c0db0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: [1 5 2 8 3 7 4 6]\n",
      "Summe: 36\n",
      "Mittelwert: 4.5\n",
      "Median: 4.5\n",
      "Standardabweichung: 2.29128784747792\n",
      "Minimum: 1\n",
      "Maximum: 8\n",
      "Index des Minimums: 0\n",
      "Index des Maximums: 3\n",
      "Sortiert: [1 2 3 4 5 6 7 8]\n"
     ]
    }
   ],
   "source": [
    "# 5Ô∏è‚É£ N√ºtzliche NumPy-Funktionen f√ºr statistische Berechnungen\n",
    "data = np.array([1, 5, 2, 8, 3, 7, 4, 6])\n",
    "print(\"Data:\", data)\n",
    "\n",
    "print(\"Summe:\", np.sum(data))\n",
    "print(\"Mittelwert:\", np.mean(data))\n",
    "print(\"Median:\", np.median(data))\n",
    "print(\"Standardabweichung:\", np.std(data))\n",
    "print(\"Minimum:\", np.min(data))\n",
    "print(\"Maximum:\", np.max(data))\n",
    "\n",
    "# Index des Minimums/Maximums\n",
    "print(\"Index des Minimums:\", np.argmin(data))\n",
    "print(\"Index des Maximums:\", np.argmax(data))\n",
    "\n",
    "# Array sortieren\n",
    "print(\"Sortiert:\", np.sort(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "78db9189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Array: [1 2 3 4 5 6]\n",
      "Shape: (6,)\n",
      "\n",
      "Reshape zu 2x3:\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "Shape: (2, 3)\n",
      "\n",
      "Reshape zu 3x2:\n",
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n",
      "\n",
      "Auto-Reshape (-1, 2):\n",
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n",
      "Shape: (3, 2)\n"
     ]
    }
   ],
   "source": [
    "# 6Ô∏è‚É£ Array-Reshaping: Die Form von Arrays √§ndern\n",
    "arr = np.array([1, 2, 3, 4, 5, 6])\n",
    "print(\"Original Array:\", arr)\n",
    "print(\"Shape:\", arr.shape)\n",
    "\n",
    "# Zu 2x3 Matrix umformen\n",
    "reshaped = arr.reshape(2, 3)\n",
    "print(\"\\nReshape zu 2x3:\")\n",
    "print(reshaped)\n",
    "print(\"Shape:\", reshaped.shape)\n",
    "\n",
    "# Zu 3x2 Matrix umformen\n",
    "reshaped2 = arr.reshape(3, 2)\n",
    "print(\"\\nReshape zu 3x2:\")\n",
    "print(reshaped2)\n",
    "\n",
    "# Automatische Dimensionsbestimmung mit -1\n",
    "auto_reshape = arr.reshape(-1, 2)  # -1 bedeutet: bestimme automatisch\n",
    "print(\"\\nAuto-Reshape (-1, 2):\")\n",
    "print(auto_reshape)\n",
    "print(\"Shape:\", auto_reshape.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29931ef",
   "metadata": {},
   "source": [
    "## üë©üèº‚Äçüíª Aufgaben "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "92b7df56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Aufgabe: Gebe f√ºr die ersten 3 Tweets die Tokens als List mit print() aus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c027790",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>L√∂sung anzeigen</b></summary>\n",
    "\n",
    "```python\n",
    "for tweet in df[\"tweet\"].head(3):\n",
    "    tokens = tweet.split(\" \")\n",
    "    print(tokens)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f20450ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Aufgabe: Geben sie f√ºr die ersten 3 Tweets die POS-Tags als List mit print() aus.\n",
    "# Beispiel: \"Ich habe Lust auf Pizza.\" -> [(\"Ich\", \"PRON\"), (\"habe\", \"VERB\"), (\"Lust\", \"NOUN\"), (\"auf\", \"ADP\"), (\"Pizza\", \"NOUN\")]\n",
    "import spacy\n",
    "nlp = spacy.load(\"de_core_news_sm\")  # Deutsches Modell laden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4599355a",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>L√∂sung anzeigen</b></summary>\n",
    "\n",
    "```python\n",
    "for tweet in df[\"tweet\"].head(3):\n",
    "    doc = nlp(tweet)\n",
    "    pos_tags = [(token.text, token.pos_) for token in doc]\n",
    "    print(pos_tags)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e4a29c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Aufgabe: Geben sie f√ºr die ersten 3 Tweets die Lemmas als List mit print() aus.\n",
    "# Beispiel: \"Ich habe Lust auf Pizza.\" -> [(\"Ich\", \"ich\"), (\"habe\", \"haben\"), (\"Lust\", \"Lust\"), (\"auf\", \"auf\"), (\"Pizza\", \"Pizza\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9fd4a4",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>L√∂sung anzeigen</b></summary>\n",
    "\n",
    "```python\n",
    "for tweet in df[\"tweet\"].head(3):\n",
    "    doc = nlp(tweet)\n",
    "    lemmas = [(token.text, token.lemma_) for token in doc]\n",
    "    print(lemmas)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740de475",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5046c372",
   "metadata": {},
   "source": [
    "## Aufgabe 4 / Was ist TF-IDF?\n",
    "\n",
    "**TF-IDF** steht f√ºr **Term Frequency ‚Äì Inverse Document Frequency**.  \n",
    "Es ist ein Verfahren aus der Textanalyse, um herauszufinden, wie wichtig ein Wort in einem Text ist ‚Äì nicht nur innerhalb dieses Textes, sondern auch im Vergleich zu allen anderen Texten in einer Sammlung (z. B. Tweets).\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Term Frequency (TF)\n",
    "Die **Term Frequency** misst, wie oft ein Wort \\( w \\) in einem Dokument \\( d \\) vorkommt, im Verh√§ltnis zur Gesamtl√§nge des Dokuments.\n",
    "\n",
    "$$\n",
    "TF(w, d) = \\frac{\\text{Anzahl der Vorkommen von } w \\text{ in } d}{\\text{Gesamtanzahl der W√∂rter in } d}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Inverse Document Frequency (IDF)\n",
    "Die **Inverse Document Frequency** misst, wie selten ein Wort in allen Dokumenten ist.  \n",
    "Sei \\( N \\) die Gesamtanzahl der Dokumente und \\( df(w) \\) die Anzahl der Dokumente, in denen das Wort \\( w \\) vorkommt:\n",
    "\n",
    "$$\n",
    "IDF(w) = \\log \\left( \\frac{N}{1 + df(w)} \\right)\n",
    "$$\n",
    "\n",
    "(Das **+1** im Nenner verhindert eine Division durch Null.)\n",
    "\n",
    "üëâ **Warum der Logarithmus?**  \n",
    "Ohne den Logarithmus w√ºrden sehr seltene W√∂rter extrem hohe Werte bekommen.  \n",
    "Der Logarithmus **gl√§ttet** diesen Effekt:  \n",
    "- H√§ufige W√∂rter bleiben nahe bei 0  \n",
    "- Sehr seltene W√∂rter bekommen h√∂here Werte, aber nicht unendlich gro√ü\n",
    "\n",
    "---\n",
    "\n",
    "### 3. TF-IDF\n",
    "Die Kombination ergibt den endg√ºltigen Wert:\n",
    "\n",
    "$$\n",
    "TF\\text{-}IDF(w, d) = TF(w, d) \\times IDF(w)\n",
    "$$\n",
    "\n",
    "- W√∂rter, die **h√§ufig in einem Dokument** vorkommen (hoher TF)  \n",
    "  und **selten in anderen Dokumenten** (hoher IDF) haben einen gro√üen TF-IDF-Wert.  \n",
    "- H√§ufige W√∂rter wie ‚Äûist‚Äú oder ‚Äûder‚Äú haben dagegen niedrige Werte, weil ihr IDF gering ist.\n",
    "\n",
    "---\n",
    "\n",
    "So kann man Texte in Zahlenform umwandeln und mit diesen Vektoren z. B. **√Ñhnlichkeiten** zwischen Tweets berechnen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09bf4a0",
   "metadata": {},
   "source": [
    "### Aufgabe\n",
    "\n",
    "Gegeben ist eine Liste von Tweets (`tweets`) und ein einzelner Text (`text`).  \n",
    "Finde die **10 Tweets**, die dem gegebenen Text am √§hnlichsten sind, basierend auf **TF-IDF und Kosinus-√Ñhnlichkeit**.  \n",
    "\n",
    "Zugegeben, die Aufgabe ist etwas komplexer, versucht sie schrittweise zu l√∂sen und zweifelt nicht, unten einen Blick in die L√∂sung zu werfen üòâ.\n",
    "\n",
    "**Tipps:**\n",
    "- Schreibe eine Funktion `tokenize()` zum Aufteilen der Texte in W√∂rter.  \n",
    "- Berechne TF und IDF f√ºr alle Tweets, erstelle TF-IDF-Vektoren.  \n",
    "- Verwende `cosine_similarity` von `sklearn.metrics.pairwise` f√ºr die √Ñhnlichkeit.  \n",
    "- `np.array(...).reshape(1, -1)` wandelt einen 1D-Vektor in 2D um.  \n",
    "- `np.argsort(similarities)[::-1]` sortiert die Tweets nach √Ñhnlichkeit absteigend.  \n",
    "- Gib die Tweets zusammen mit dem √Ñhnlichkeitswert aus.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f67da728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# math ist eine eingebaute Python-Bibliothek, die mathematische Funktionen bereitstellt.\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# convert df[\"tweet\"] to a list of strings\n",
    "tweets = df[\"tweet\"].tolist()\n",
    "\n",
    "# Text, zu dem wir √§hnliche Tweets finden wollen\n",
    "text = \"Corona und Impfstoff\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "6416d012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Tokenisieren ---\n",
    "\n",
    "# --- 2. TF berechnen ---\n",
    "\n",
    "# --- 3. IDF berechnen ---\n",
    "\n",
    "# --- 4. TF-IDF Vektor erstellen ---\n",
    "\n",
    "# --- 5. √Ñhnlichkeit berechnen ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab260e5",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>L√∂sung anzeigen</b></summary>\n",
    "\n",
    "```python\n",
    "# --- 1. Tokenisieren ---\n",
    "def tokenize(s):\n",
    "    return s.lower().split()\n",
    "\n",
    "tokenized_tweets = [tokenize(t) for t in tweets]\n",
    "tokenized_text = tokenize(text)\n",
    "\n",
    "# --- 2. TF berechnen ---\n",
    "def term_frequency(words):\n",
    "    tf = {}\n",
    "    total = len(words)\n",
    "    for w in words:\n",
    "        tf[w] = tf.get(w, 0) + 1\n",
    "    for w in tf:\n",
    "        tf[w] /= total\n",
    "    return tf\n",
    "\n",
    "tf_tweets = [term_frequency(t) for t in tokenized_tweets]\n",
    "tf_text = term_frequency(tokenized_text)\n",
    "\n",
    "# --- 3. IDF berechnen ---\n",
    "N = len(tweets)\n",
    "all_words = set([w for tweet in tokenized_tweets for w in tweet])\n",
    "\n",
    "idf = {}\n",
    "for w in all_words:\n",
    "    # Nun z√§hlen wir, in wie vielen Dokumenten (Tweets) das Wort vorkommt\n",
    "    doc_f = 0\n",
    "    for t in tokenized_tweets:\n",
    "        if w in t:\n",
    "            doc_f += 1\n",
    "    # F√ºr ein Wort w berechnen wir den IDF-Wert basierend auf der Anzahl der Dokumente N und der Anzahl der Dokumente, in denen das Wort vorkommt (doc_f).\n",
    "    idf[w] = math.log(N / (1 + doc_f))\n",
    "\n",
    "# --- 4. TF-IDF Vektor erstellen ---\n",
    "def tfidf_vector(tf, idf):\n",
    "    vector = []\n",
    "    for w in sorted(idf.keys()): \n",
    "        tf_value = tf.get(w, 0)  # TF-Wert f√ºr das Wort (0 falls nicht vorhanden)\n",
    "        idf_value = idf[w]       # IDF-Wert f√ºr das Wort\n",
    "        tfidf_value = tf_value * idf_value\n",
    "        vector.append(tfidf_value)\n",
    "    return vector\n",
    "\n",
    "tfidf_tweets = [tfidf_vector(tf, idf) for tf in tf_tweets]\n",
    "tfidf_text = tfidf_vector(tf_text, idf)\n",
    "\n",
    "# --- 5. √Ñhnlichkeit berechnen ---\n",
    "# Convert to numpy arrays and reshape for cosine_similarity\n",
    "tfidf_text_reshaped = np.array(tfidf_text).reshape(1, -1)\n",
    "tfidf_tweets_array = np.array(tfidf_tweets) # tfidf_tweets_array.shape ist (anzahl_tweets, anzahl an einzigartigen W√∂rtern)\n",
    "\n",
    "# Erkl√§rung: Numpy ist eine Bibliothek f√ºr effiziente mathematische Operationen mit Arrays.\n",
    "# Die reshape(1, -1) Operation wandelt den 1D-Vektor in eine 2D-Matrix um:\n",
    "# - Die \"1\" bedeutet: eine Zeile\n",
    "# - Das \"-1\" bedeutet: \"automatisch berechnen\" f√ºr die Anzahl der Spalten\n",
    "# cosine_similarity erwartet 2D-Arrays als Eingabe, daher die Umformung.\n",
    "\n",
    "similarities = cosine_similarity(tfidf_text_reshaped, tfidf_tweets_array)[0]\n",
    "\n",
    "# Ergebnisse anzeigen\n",
    "# Sortiere tweets nach √§hnlichkeit (h√∂chste zuerst) und zeige die top 10\n",
    "# [::-1] kehrt die Reihenfolge um\n",
    "# Jetzt sind die Indizes vom gr√∂√üten zum kleinsten Wert, also absteigend sortiert.\n",
    "sorted_indices = np.argsort(similarities)[::-1]\n",
    "for i in sorted_indices[:10]:\n",
    "    print(f\"√Ñhnlichkeit: {similarities[i]:.3f} -> {tweets[i]}\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_nils_hellwig",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
